<!doctype html><html lang=zh class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href=../%E8%80%83%E8%AF%95%E8%AF%B4%E6%98%8E/ rel=prev><link href=../../../%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/git/ rel=next><link rel=icon href=../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.5.3, mkdocs-material-9.5.2"><title>题型梳理 - Whu-Summu77</title><link rel=stylesheet href=../../../assets/stylesheets/main.50c56a3b.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><link rel=stylesheet href=../../../assets/stylesheets/custom.00c04c01.min.css></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#_1 class=md-skip> 跳转至 </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label=不再显示此消息> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> For updates contact <strong>@summu77</strong> on <strong>1875418876@qq.com</strong> </div> <script>var content,el=document.querySelector("[data-md-component=announce]");el&&(content=el.querySelector(".md-typeset"),__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0))</script> </aside> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=页眉> <a href=../../.. title=Whu-Summu77 class="md-header__button md-logo" aria-label=Whu-Summu77 data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Whu-Summu77 </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 题型梳理 </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg> </label> </form> <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=搜索 placeholder=搜索 autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=查找> <a href=javascript:void(0) class="md-search__icon md-icon" title=分享 aria-label=分享 data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=清空当前内容 aria-label=清空当前内容 tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 正在初始化搜索引擎 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=标签 data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> 主页 </a> </li> <li class=md-tabs__item> <a href=../../../%E5%85%B3%E4%BA%8E%E6%88%91/Aboutme/ class=md-tabs__link> 关于我 </a> </li> <li class=md-tabs__item> <a href=../../../%E8%AF%BE%E7%A8%8B%E4%BD%9C%E4%B8%9A/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8/CVE-2023-21839%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/ class=md-tabs__link> 课程作业 </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC%E4%B8%80%E7%AB%A0/ class=md-tabs__link> 课程复习 </a> </li> <li class=md-tabs__item> <a href=../../../%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/git/ class=md-tabs__link> 工具学习 </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=导航栏 data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title=Whu-Summu77 class="md-nav__button md-logo" aria-label=Whu-Summu77 data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg> </a> Whu-Summu77 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> 主页 </span> </a> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex> <span class=md-ellipsis> 关于我 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> 关于我 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E5%85%B3%E4%BA%8E%E6%88%91/Aboutme/ class=md-nav__link> <span class=md-ellipsis> 简介 </span> </a> </li> <li class=md-nav__item> <a href=../../../%E5%85%B3%E4%BA%8E%E6%88%91/%E8%BE%A9%E8%AE%BA/ class=md-nav__link> <span class=md-ellipsis> 辩论经历 </span> </a> </li> <li class=md-nav__item> <a href=../../../%E5%85%B3%E4%BA%8E%E6%88%91/%E6%88%91%E7%9A%84%E5%A4%A7%E5%AD%A6/ class=md-nav__link> <span class=md-ellipsis> 我的大学 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> 课程作业 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> 课程作业 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex> <span class=md-ellipsis> 信息系统安全 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> 信息系统安全 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E8%AF%BE%E7%A8%8B%E4%BD%9C%E4%B8%9A/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8/CVE-2023-21839%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/ class=md-nav__link> <span class=md-ellipsis> CVE-2023-21839 漏洞复现 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex> <span class=md-ellipsis> 操作系统实践 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> 操作系统实践 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E8%AF%BE%E7%A8%8B%E4%BD%9C%E4%B8%9A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%A4%A7%E4%BD%9C%E4%B8%9A/ class=md-nav__link> <span class=md-ellipsis> 操作系统实践大作业 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex> <span class=md-ellipsis> 课程复习 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> 课程复习 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_1> <label class=md-nav__link for=__nav_4_1 id=__nav_4_1_label tabindex> <span class=md-ellipsis> 计算机网络 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_1_label aria-expanded=false> <label class=md-nav__title for=__nav_4_1> <span class="md-nav__icon md-icon"></span> 计算机网络 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC%E4%B8%80%E7%AB%A0/ class=md-nav__link> <span class=md-ellipsis> 1-基础概要复习 </span> </a> </li> <li class=md-nav__item> <a href=../../%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC%E4%BA%8C%E7%AB%A0/ class=md-nav__link> <span class=md-ellipsis> 2-物理层复习 </span> </a> </li> <li class=md-nav__item> <a href=../../%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC%E4%B8%89%E7%AB%A0/ class=md-nav__link> <span class=md-ellipsis> 3-链路层复习 </span> </a> </li> <li class=md-nav__item> <a href=../../%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC%E5%9B%9B%E7%AB%A0/ class=md-nav__link> <span class=md-ellipsis> 4-网络层复习 </span> </a> </li> <li class=md-nav__item> <a href=../../%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC%E4%BA%94%E7%AB%A0/ class=md-nav__link> <span class=md-ellipsis> 5-传输层复习 </span> </a> </li> <li class=md-nav__item> <a href=../../%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC%E5%85%AD%E7%AB%A0/ class=md-nav__link> <span class=md-ellipsis> 6-应用层复习 </span> </a> </li> <li class=md-nav__item> <a href=../../%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%A2%84%E6%B5%8B/ class=md-nav__link> <span class=md-ellipsis> 试卷分析 </span> </a> </li> <li class=md-nav__item> <a href=../../%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E4%BA%8C%E8%BD%AE%E5%A4%8D%E4%B9%A0/ class=md-nav__link> <span class=md-ellipsis> 二轮复习 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2 checked> <label class=md-nav__link for=__nav_4_2 id=__nav_4_2_label tabindex> <span class=md-ellipsis> 自然语言处理 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=true> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> 自然语言处理 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../%E8%80%83%E8%AF%95%E8%AF%B4%E6%98%8E/ class=md-nav__link> <span class=md-ellipsis> 考试说明 </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> 题型梳理 </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 题型梳理 </span> </a> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_2 class=md-nav__link> <span class=md-ellipsis> 重要的模型！ </span> </a> <nav class=md-nav aria-label=重要的模型！> <ul class=md-nav__list> <li class=md-nav__item> <a href=#word2vec class=md-nav__link> <span class=md-ellipsis> Word2vec模型 </span> </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 前馈神经网络 </span> </a> </li> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> 卷积神经网络 </span> </a> </li> <li class=md-nav__item> <a href=#rnn-lstm-gru class=md-nav__link> <span class=md-ellipsis> RNN LSTM GRU模型 </span> </a> </li> <li class=md-nav__item> <a href=#transformer class=md-nav__link> <span class=md-ellipsis> Transformer的架构 </span> </a> </li> <li class=md-nav__item> <a href=#bert class=md-nav__link> <span class=md-ellipsis> BERT的架构 </span> </a> </li> <li class=md-nav__item> <a href=#gpt-1 class=md-nav__link> <span class=md-ellipsis> GPT-1的架构 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> <span class=md-ellipsis> 名词解释题 </span> </a> </li> <li class=md-nav__item> <a href=#_6 class=md-nav__link> <span class=md-ellipsis> 简答题 </span> </a> <nav class=md-nav aria-label=简答题> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_7 class=md-nav__link> <span class=md-ellipsis> 句法成分树 </span> </a> </li> <li class=md-nav__item> <a href=#_8 class=md-nav__link> <span class=md-ellipsis> 依存树(图) </span> </a> </li> <li class=md-nav__item> <a href=#rst class=md-nav__link> <span class=md-ellipsis> 修辞结构理论(RST) </span> </a> </li> <li class=md-nav__item> <a href=#_9 class=md-nav__link> <span class=md-ellipsis> 注意力机制 </span> </a> </li> <li class=md-nav__item> <a href=#_10 class=md-nav__link> <span class=md-ellipsis> 其他部分 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_11 class=md-nav__link> <span class=md-ellipsis> 算法题 </span> </a> <nav class=md-nav aria-label=算法题> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_12 class=md-nav__link> <span class=md-ellipsis> 分词算法(最大匹配、最大概率) </span> </a> </li> <li class=md-nav__item> <a href=#hmm class=md-nav__link> <span class=md-ellipsis> HMM算法 / 维特比算法 </span> </a> </li> <li class=md-nav__item> <a href=#_13 class=md-nav__link> <span class=md-ellipsis> 解码算法 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_14 class=md-nav__link> <span class=md-ellipsis> 设计题 </span> </a> <nav class=md-nav aria-label=设计题> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_15 class=md-nav__link> <span class=md-ellipsis> 关系抽取 </span> </a> </li> <li class=md-nav__item> <a href=#_16 class=md-nav__link> <span class=md-ellipsis> 命名实体识别 </span> </a> </li> <li class=md-nav__item> <a href=#_17 class=md-nav__link> <span class=md-ellipsis> 主题情感分类 </span> </a> </li> <li class=md-nav__item> <a href=#_18 class=md-nav__link> <span class=md-ellipsis> 摘要系统 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex> <span class=md-ellipsis> 工具学习 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> 工具学习 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/git/ class=md-nav__link> <span class=md-ellipsis> git </span> </a> </li> <li class=md-nav__item> <a href=../../../%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/markdown/ class=md-nav__link> <span class=md-ellipsis> markdown </span> </a> </li> <li class=md-nav__item> <a href=../../../%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/mkdocs/ class=md-nav__link> <span class=md-ellipsis> mkdocs </span> </a> </li> <li class=md-nav__item> <a href=../../../%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/javaScript/ class=md-nav__link> <span class=md-ellipsis> javaScript与css与html </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_2 class=md-nav__link> <span class=md-ellipsis> 重要的模型！ </span> </a> <nav class=md-nav aria-label=重要的模型！> <ul class=md-nav__list> <li class=md-nav__item> <a href=#word2vec class=md-nav__link> <span class=md-ellipsis> Word2vec模型 </span> </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 前馈神经网络 </span> </a> </li> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> 卷积神经网络 </span> </a> </li> <li class=md-nav__item> <a href=#rnn-lstm-gru class=md-nav__link> <span class=md-ellipsis> RNN LSTM GRU模型 </span> </a> </li> <li class=md-nav__item> <a href=#transformer class=md-nav__link> <span class=md-ellipsis> Transformer的架构 </span> </a> </li> <li class=md-nav__item> <a href=#bert class=md-nav__link> <span class=md-ellipsis> BERT的架构 </span> </a> </li> <li class=md-nav__item> <a href=#gpt-1 class=md-nav__link> <span class=md-ellipsis> GPT-1的架构 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> <span class=md-ellipsis> 名词解释题 </span> </a> </li> <li class=md-nav__item> <a href=#_6 class=md-nav__link> <span class=md-ellipsis> 简答题 </span> </a> <nav class=md-nav aria-label=简答题> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_7 class=md-nav__link> <span class=md-ellipsis> 句法成分树 </span> </a> </li> <li class=md-nav__item> <a href=#_8 class=md-nav__link> <span class=md-ellipsis> 依存树(图) </span> </a> </li> <li class=md-nav__item> <a href=#rst class=md-nav__link> <span class=md-ellipsis> 修辞结构理论(RST) </span> </a> </li> <li class=md-nav__item> <a href=#_9 class=md-nav__link> <span class=md-ellipsis> 注意力机制 </span> </a> </li> <li class=md-nav__item> <a href=#_10 class=md-nav__link> <span class=md-ellipsis> 其他部分 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_11 class=md-nav__link> <span class=md-ellipsis> 算法题 </span> </a> <nav class=md-nav aria-label=算法题> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_12 class=md-nav__link> <span class=md-ellipsis> 分词算法(最大匹配、最大概率) </span> </a> </li> <li class=md-nav__item> <a href=#hmm class=md-nav__link> <span class=md-ellipsis> HMM算法 / 维特比算法 </span> </a> </li> <li class=md-nav__item> <a href=#_13 class=md-nav__link> <span class=md-ellipsis> 解码算法 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_14 class=md-nav__link> <span class=md-ellipsis> 设计题 </span> </a> <nav class=md-nav aria-label=设计题> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_15 class=md-nav__link> <span class=md-ellipsis> 关系抽取 </span> </a> </li> <li class=md-nav__item> <a href=#_16 class=md-nav__link> <span class=md-ellipsis> 命名实体识别 </span> </a> </li> <li class=md-nav__item> <a href=#_17 class=md-nav__link> <span class=md-ellipsis> 主题情感分类 </span> </a> </li> <li class=md-nav__item> <a href=#_18 class=md-nav__link> <span class=md-ellipsis> 摘要系统 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=_1>题型考点梳理</h1> <blockquote> <p>之前是按照知识点进行整理，自己没心情看了...感觉非常冗余</p> <p>现在按照题型进行知识梳理</p> <p>第一版：2024年1月9日18:06:05</p> </blockquote> <h2 id=_2>重要的模型！</h2> <h3 id=word2vec>Word2vec模型</h3> <p>Word2vec 可以利用两种架构来生成：<strong>Continuous bag-of-words(CBOW)</strong> 和 <strong>Continuous skip-gram</strong> 。其核心思想是利用到了滑动窗口，每个窗口中的中间词称之为target word，而左右两侧的词称之为context word，前者使用的是上下文词来预测目标词，后者则是利用目标词来预测上下文词。</p> <div style="display: flex; justify-content: space-between;"> <figure class=figure-image style="text-align: center; width: 46%;"> <img src=../image-7.png alt="An image caption" style="width: 100%; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <figure class=figure-image style="text-align: center; width: 47%;"> <img src=../image-9.png alt="An image caption" style="width: 100%; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> </div> <blockquote> <p>负采样：不对全部的词表进行softmax，而是采样一些词进行softmax大大减少计算量</p> <p>非固定滑动窗口：实际上滑动窗口的大小是随机采样得到的，这样可以更好地利用离target更近的词</p> <p>sub-sampling ：认为低概率的词语义信息更加丰富，用策略去掉一些高概率词</p> </blockquote> <h3 id=_3>前馈神经网络</h3> <figure class=figure-image style="text-align: center;"> <img src=../image-14.png alt="An image caption" style="width: 120%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <blockquote> <p>训练目标：最小化代价函数 J ( W , b )，其中 W 和 b 分别表示网络中的权重矩阵和偏置向量</p> <p>参数更新：通过反向传播，一般使用梯度下降法(批梯度下降、随机梯度下降等)</p> </blockquote> <h3 id=_4>卷积神经网络</h3> <figure class=figure-image style="text-align: center;"> <img src=../image-21.png alt="An image caption" style="width: 70%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <blockquote> <p>优点：卷积层级之间的神经元是<strong>局部连接和权值共享</strong>，这样的设计大大减少了(w,b)的数量，加快了训练。</p> <p>卷积操作：从输入图像中提取特征，如边缘、纹理、颜色等，同时可以捕捉到平移不变性</p> <p>池化操作：降低卷积层的输出维度，减少计算复杂性，有助于保留显著的特征降低噪声的影响。</p> <p>文本卷积：使用的<strong>卷积核通常是一维的</strong>。这与用于图像处理的二维卷积核不同。卷积核的一维结构更适合处理线性排列的词向量序列。</p> </blockquote> <h3 id=rnn-lstm-gru>RNN LSTM GRU模型</h3> <blockquote> <p>参考资料：<a href="https://www.bilibili.com/video/BV1YK411F7Tg/?spm_id_from=333.337.search-card.all.click&vd_source=ae67b970bd4a0665fa92195df95aa1f3">数之道 09 RNN LSTM GRU</a></p> </blockquote> <figure class=figure-image style="text-align: center;"> <img src=../image-24.png alt="An image caption" style="width: 70%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <blockquote> <p>RNN 会产生梯度消失和梯度爆炸的问题</p> </blockquote> <figure class=figure-image style="text-align: center;"> <img src=../image-28.png alt="An image caption" style="width: 70%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <blockquote> <p>依次是：遗忘门、输入门、输出门， C 和 H 会流向下一个单元</p> </blockquote> <figure class=figure-image style="text-align: center;"> <img src=../image-29.png alt="An image caption" style="width: 70%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <figure class=figure-image style="text-align: center;"> <img src=../image-27.png alt="An image caption" style="width: 90%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <blockquote> <p>更新门（update gate），控制了新信息被加入到细胞状态的程度、重置门（reset gate），控制了过去的记忆信息被遗忘的程度，这个详细的原理之后再看</p> </blockquote> <h3 id=transformer>Transformer的架构</h3> <blockquote> <p>参考资料 ：清华刘知远老师的大模型课程自行整理，这个笔记为两个月前的，但是够用了</p> </blockquote> <figure class=figure-image style="text-align: center;"> <img src=../image.jpg alt="An image caption" style="width: 70%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <figure class=figure-image style="text-align: center;"> <img src=../image-22.png alt="An image caption" style="width: 70%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <blockquote> <p>Layer Normalization：批归一化适用于深度神经网络如CNN，层归一化更合适RNN和transformer</p> <p><strong>Multihead Attention：</strong>每个头学习序列的不同方面，增加了模型的表达能力，<strong>允许模型同时关注序列的不同特征</strong>，如语法和语义层面。和多卷积核在图像上的作用类似。</p> </blockquote> <h3 id=bert>BERT的架构</h3> <blockquote> <p>参考资料：<a href="https://www.bilibili.com/video/BV1ca411375k/?spm_id_from=333.788&vd_source=ae67b970bd4a0665fa92195df95aa1f3">水论文的程序猿: BERT与GPT</a></p> <p>BERT和transformer的encoder部分基本一样，但是层数变成了12或24层，输入层多了一个segmnet embedding，同时预训练任务变成了MLM和NSP。其最大的优点是<strong>上下文感知性</strong>！</p> <p>注意：ELMo虽然也是双向编码的，但是它在感知上文时不能感知下文，感知下文时不能感知上文</p> <p>和GPT一样，BERT也采用<strong>二段式训练</strong>方法：第一阶段：使用易获取的大规模无标签语料，来训练基础语言模型（即MLM和NSP）；第二阶段：根据指定任务的少量带标签训练数据进行微调训练。(包括但不限于各种文本分类或序列标记任务)</p> </blockquote> <p><strong>MLM</strong>：每个序列中 15% 的单词被替换为 [MASK] 标记。然后，该模型尝试根据序列中其他非掩码单词提供的上下文来预测掩码单词的原始值。</p> <p><strong>NSP</strong>：接收成对的句子作为输入，学习预测该对中的第二个句子是否是第一个句子的后续句子。其目的是为了获得句子的语义联系，毕竟MLM只能学到词与词之间联系的。</p> <p><strong>输入层</strong>：比transformer的输入层多出一个segmnet embedding层，具体如下所示：</p> <figure class=figure-image style="text-align: center;"> <img src=../image-18.png alt="An image caption" style="width: 70%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <blockquote> <p>BERT本质是提取文本的特征，可以用于构建各种模型，完成各种任务！非常重要！</p> <p>模型设计甚至全都可以采取的思路：将BERT和其他简单模型组合</p> <p>拓展资料 ：<a href=https://www.cnblogs.com/nickchen121/p/15114385.html#%E5%8D%81%E4%B8%80bert-%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1%E6%94%B9%E9%80%A0>BERT 下游任务改造</a> ，<a href="https://www.bilibili.com/video/BV1se411V713/?spm_id_from=333.788&vd_source=ae67b970bd4a0665fa92195df95aa1f3">BERT 下游任务改造 视频版</a></p> </blockquote> <h3 id=gpt-1>GPT-1的架构</h3> <figure class=figure-image style="text-align: center;"> <img src=../image-19.png alt="An image caption" style="width: 70%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <p>GPT-1的训练：</p> <ol> <li>基于<strong>无监督学习</strong>，在训练过程中，GPT-1尝试预测给定文本序列中的下一个单词，通过阅读大量文本数据来学习语言的统计规律。</li> <li>进行<strong>有监督微调</strong>来提高其在特定任务上的性能，使用了一系列有标签的任务来微调模型，包括文本分类、命名实体识别、情感分析等。</li> </ol> <h2 id=_5>名词解释题</h2> <table> <thead> <tr> <th>名词</th> <th>解释</th> <th>是否考过</th> </tr> </thead> <tbody> <tr> <td>分词</td> <td>将文本分割成更小的语言单位（如单词、短语或符号）的过程。在不同语言中，分词的方法和难度各不相同。在英语中通常是按空格和标点分割，而在汉语中由于没有明显的词界标记，分词更为复杂。</td> <td>✔️ ✔️</td> </tr> <tr> <td>词性标注</td> <td>为文本中的每个单词（或词语）标注词性（如名词、动词、形容词等）。这有助于了解词语在句子中的语法作用和意义。</td> <td>✔️</td> </tr> <tr> <td>词义排歧</td> <td>确定多义词在特定上下文中的准确意义的过程，对于理解句子的意义很重要。</td> <td></td> </tr> <tr> <td>词向量</td> <td>将词语表示为多维空间中的向量的技术。这些向量能够捕捉词语之间的语义和语法关系，使计算机能够理解和处理自然语言。</td> <td>✔️ ✔️</td> </tr> <tr> <td>语言模型</td> <td>用来预测文本序列中的下一个词或词组的模型。这些模型基于大量语料库学习如何构建语言结构，用于各种自然语言处理任务，如文本生成、机器翻译等。</td> <td>✔️ ✔️</td> </tr> <tr> <td>关系抽取</td> <td>从文本中识别并提取实体之间的关系的过程。</td> <td></td> </tr> <tr> <td>实体识别</td> <td>从文本中识别出特定类型的实体（如人名、地点、组织名等）。</td> <td>✔️</td> </tr> <tr> <td>Aspect情感分析</td> <td>识别文本中特定方面或属性的情感倾向。例如评价一个餐厅时，分别分析对于“食物”、“服务”、“环境”的情感倾向。</td> <td></td> </tr> <tr> <td>预训练</td> <td>指在自然语言处理模型开始执行特定任务之前，首先在大规模的通用语料库上训练模型。这一阶段模型学习语言的基础知识，例如词汇、语法和常见的句子结构,帮助模型建立对语言的基本理解。</td> <td></td> </tr> <tr> <td>精调</td> <td>指在预训练之后在特定任务的数据集上进行进一步训练,使得模型能够适应特定任务的需求，如文本分类、情感分析等。</td> <td></td> </tr> <tr> <td>prompt</td> <td>prompt是指引导模型生成特定回应的输入文本，可以是一个问题、命令或任何其他形式的语句，用于激发模型按照某种特定方式响应。</td> <td></td> </tr> <tr> <td>instruction tuning</td> <td>指令调优是一种训练模型以更好地理解和遵循人类指令的方法。这涉及在模型训练中使用明确的指令，以提高其在执行特定任务时的准确性和效率。</td> <td></td> </tr> <tr> <td>chain-of-thought</td> <td>链式思考是指模型在生成回答时展示其思考过程的方法。这种方式可以帮助理解模型是如何从问题到答案的过程，提高结果的可解释性，同时提高答案的准确性和质量。</td> <td></td> </tr> <tr> <td>RLHF</td> <td>通过人类反馈来进行强化学习的方法，帮助模型更好地理解适应人类的偏好。</td> <td></td> </tr> <tr> <td>hallucination</td> <td>模型生成与现实不符或完全虚构的信息，这通常发生在模型对现实情况理解不足或处理能力有限时。</td> <td></td> </tr> <tr> <td>in-context learning</td> <td>模型能够根据给定的上下文信息来进行学习和预测，让模型根据上下文中的提示自我调整以适应新的任务或数据。</td> <td></td> </tr> <tr> <td>价值观对齐</td> <td>使模型的行为和决策与人类的伦理标准和价值观保持一致，确保模型的输出不会传播有害的内容，反映社会多元化的价值观，并尊重用户的隐私和偏好。</td> <td></td> </tr> <tr> <td>文本蕴含</td> <td>确定一个文本片段（前提）是否逻辑上蕴含或支持另一个文本片段（假设）的过程。如果从前提中可以推理出假设，则认为蕴含关系成立。</td> <td>✔️</td> </tr> <tr> <td>注意力机制</td> <td>是一种在神经网络中用于增强模型对特定部分输入数据的“关注”的技术，它允许模型在处理信息时更加集中于输入序列的某些重要部分</td> <td>✔️</td> </tr> <tr> <td>自然语言</td> <td>是人类用于日常沟通和表达的语言。</td> <td>✔️</td> </tr> <tr> <td>循环神经网络</td> <td>用于处理序列数据（如文本或时间序列数据）的神经网络，将先前的输出作为当前步骤输入的一部分，使它能够存储和利用历史信息更好地处理序列数据。</td> <td>✔️</td> </tr> </tbody> </table> <h2 id=_6>简答题</h2> <figure class=figure-image style="text-align: center;"> <img src=../image-11.png alt="An image caption" style="width: 60%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <hr> <h3 id=_7>句法成分树</h3> <ul> <li>句法成分树中节点是什么、边代表什么意思</li> </ul> <p>句法成分树用于表示句子的成分结构，其中节点代表成分，边代表成分之间的关系。</p> <blockquote> <p>从S开始，化为NP和VP，然后再化为pro verb det noun prep，最后化为词。</p> </blockquote> <p>举例1：主谓关系</p> <p>句子：她跳舞。 成分树：(S (NP 她) (VP (V 跳舞))) 在这个例子中，"她"是名词短语（NP）的一部分，"跳舞"是动词短语（VP）的一部分，表示了主谓关系。</p> <p>举例2：修饰关系</p> <p>句子：大狗追小猫。 成分树：(S (NP (Adj 大) (N 狗)) (VP (V 追) (NP (Adj 小) (N 猫)))) 这个例子中，"大"修饰"狗"，"小"修饰"猫"，表示了名词与形容词之间的修饰关系。</p> <p>举例3：从属从句关系</p> <p>句子：我喜欢吃巧克力的人。 成分树：(S (NP 我) (VP (V 喜欢) (S (VP (V 吃) (NP (N 巧克力) (的 (N 人))))))) 在这个例子中，"吃巧克力的人"是一个从属从句，它从属于主句"我喜欢"，表示了主句和从句之间的关系。</p> <hr> <h3 id=_8>依存树(图)</h3> <ul> <li>依存树(图)中节点是什么、边代表什么意思</li> </ul> <p>依存树用于表示句子中单词之间的依存关系，其中节点代表单词，边代表单词之间的依存关系。</p> <p>举例1：主谓关系</p> <p>"The cat chased the mouse"（"猫追逐老鼠"）中，"cat"依赖于"chased"</p> <p>举例2：动宾关系</p> <p>"She ate an apple"（"她吃了一个苹果"）中，"ate"依赖于"apple"</p> <p>举例3：形容词修饰名词关系</p> <p>"The big house"（"那座大房子"）中，"big"依赖于"house"</p> <p>举例4：副词修饰动词关系</p> <p>"She sings beautifully"（"她唱得美丽"）中，"beautifully"依赖于"sings"</p> <p>举例5：从属从句关系</p> <p>"I know that he is coming"（"我知道他要来了"）中，"he"依赖于"know"</p> <hr> <h3 id=rst>修辞结构理论(RST)</h3> <ul> <li>修辞结构理论(RST)是如何表示篇章的，其中基础语篇单位(Elementary DiscourseUnit/EDU)、核心nucleus和卫星satellite 指什么</li> </ul> <p>修辞结构理论认为，连贯的篇章由不同层次的修辞关系组成，并且可以表示为一种树形结构。在 RST Tree 中，每一个修辞关系都包括一个 Nucleus 和一个或多个 Satellite。</p> <p>通过描述各部分的修辞关系来分析篇章的结构和功能，大小不一的部分被称为结构段（text span）或者<strong>基础语篇单位(Elementary Discourse Unit/EDU)</strong>；text span由多个EDU组成</p> <p>核心是篇章最重要的部分，表示<strong>中心信息的单元，具有相对完整的语义</strong>。</p> <p>卫星是<strong>传达支撑信息的其他单元，用于补充说明核心部分</strong>，脱离核心的卫星部分通常是没有意义的。</p> <p>篇章分析的几个步骤：</p> <ol> <li>篇章分成基础语篇单位EDU</li> <li>判断每个EDU是核心还是卫星</li> <li>根据核心和卫星的特征来判断修辞关系，特征可以是词性，依存关系等</li> <li>构建篇章结构树</li> </ol> <hr> <h3 id=_9>注意力机制</h3> <ul> <li>注意力的运算过程</li> </ul> <blockquote> <p>参考资料 ：<a href=https://zhuanlan.zhihu.com/p/612036724>知乎：注意力机制详解</a></p> </blockquote> <p>如何得到注意力分布，可以理解为注意力分数：</p> <figure class=figure-image style="text-align: center;"> <img src=../image-15.png alt="An image caption" style="width: 70%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <p>其中的s( )函数有多种计算方式：</p> <figure class=figure-image style="text-align: center;"> <img src=../image-16.png alt="An image caption" style="width: 70%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <p>接下来介绍最重要的自注意机制，其中的Q K V都是通过h线性变换得到的：</p> <figure class=figure-image style="text-align: center;"> <img src=../image-17.png alt="An image caption" style="width: 70%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <blockquote> <p>解释为什么叫自注意机制：<strong>查询向量</strong>也可以使用输入信息进行生成，而不是选择一个上述任务相关的查询向量。相当于模型读到输入信息后，根据输入信息本身决定当前最重要的信息。</p> </blockquote> <hr> <h3 id=_10>其他部分</h3> <ul> <li>Word2vec模型架构、训练词向量的原理</li> <li>前馈神经网络、卷积神经网络、循环神经网络、LSTM的模型架构</li> <li>Transformer的架构搞清楚:self-attention，cross-attention，multihead，layer-norm，残差，位置编码</li> <li>BERT的架构，预训练任务、什么是精调</li> <li>GPT-1的架构，预训练任务</li> </ul> <blockquote> <p>见重要模型部分内容即可</p> </blockquote> <h2 id=_11>算法题</h2> <h3 id=_12>分词算法(最大匹配、最大概率)</h3> <ul> <li>最大匹配法</li> </ul> <p>最大匹配法主要包括正向最大匹配法（FMM，Forward Maximum Matching）、反向最大匹配法（BMM, Backward Maximum Matching）和双向最大匹配法，均是基于词典的。 </p> <ol> <li>从左向右取待切分汉语句的m个字符作为匹配字段， m为机器词典中最长词条的字符数。</li> <li>查找机器词典并进行匹配。<ol> <li>若匹配成功，则将这个匹配字段作为一个词切分出来。</li> <li>若匹配不成功，则将这个匹配字段的最后一个字去掉，剩下的字符串作为新的匹配字段，进行再次匹配。 </li> <li>重复以上过程，直到切分出所有词为止。</li> </ol> </li> </ol> <blockquote> <p>关于AC自动机、前缀树、失配指针等相关知识略</p> </blockquote> <ul> <li>最大概率法</li> </ul> <figure class=figure-image style="text-align: center;"> <img src=../image-4.png alt="An image caption" style="width: 80%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <h3 id=hmm>HMM算法 / 维特比算法</h3> <ul> <li>基于隐马尔可夫HMM的词性标注算法</li> </ul> <blockquote> <p>词性标注可以看作给定观察值（词），求隐状态（词性）的问题</p> <p><strong>发射概率（Emission Probability）</strong>表示在已知某个词性的情况下，观察到某个具体单词的概率。它告诉我们一个词语在特定词性下出现的可能性有多大。</p> <p><strong>转移概率（Transition Probability）</strong>表示了词性之间的转换概率。它告诉我们在一个句子中，一个词性转移到另一个词性的可能性有多大。</p> <p><strong>初始概率（Initial Probability）</strong>：这表示句子中第一个词性状态的概率分布。初始概率告诉模型在句子开始时，每种词性的可能性有多大。</p> </blockquote> <figure class=figure-image style="text-align: center;"> <img src=../image-5.png alt="An image caption" style="width: 80%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <blockquote> <p>维特比算法等同于计算无环有向图的最优(最大、最小)路径问题</p> </blockquote> <h3 id=_13>解码算法</h3> <ul> <li>生成模型的解码算法: beam-search、Top-k采样、Top-p采样</li> </ul> <blockquote> <p>参考资料：<a href="https://www.bilibili.com/video/BV1Rb411M77p/?spm_id_from=333.337.search-card.all.click&vd_source=ae67b970bd4a0665fa92195df95aa1f3">Beam Search 束搜索与误差分析</a></p> </blockquote> <figure class=figure-image style="text-align: center;"> <img src=../image-33.png alt="An image caption" style="width: 80%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <blockquote> <p>beamsearch相当于是greedy算法的扩展，num_beams=1时其实就是greedy算法。</p> </blockquote> <p>Top-k 采样是一种生成策略，它在每个时间步骤中从词汇表中选择概率最高的k个单词或标记，然后从这k个选项中随机选择一个作为下一个词。这种方法可以增加多样性，因为它不会简单地选择最可能的单词，而是考虑了多个高概率选项。但是，它仍然受限于提前定义的k值。</p> <p>Top-p 采样是一种生成策略，它在每个时间步骤中按概率排名选择词汇表中的单词，直到累积概率达到或超过一个阈值p。这样，模型会考虑在累积概率阈值内的所有可能词汇，而不仅仅是前几个高概率选项。Top-p 采样可以提供更多的多样性，因为它允许模型选择概率分布中的较低概率词汇。</p> <blockquote> <p>Beam Search用于生成高质量的、连贯的序列，而Top-k和Top-p则用于在生成中引入随机性和多样性。</p> </blockquote> <h2 id=_14>设计题</h2> <blockquote> <p>这些NLP任务全部可以基于BERT实现！损失函数都是交叉熵损失函数！</p> </blockquote> <ul> <li>会用神经网络构建关系抽取系统</li> <li>会用神经网络构建实体识别系统</li> <li>会用神经网络构建情感分析系统</li> </ul> <blockquote> <p>以上NLP任务的的评估指标 : 精确度（Precision，P）、召回率（Recall，R）和F1分数（F1 Score）</p> </blockquote> <ul> <li>会用神经网络构建文本生成系统 （摘要系统、机器翻译系统、对话系统）</li> </ul> <blockquote> <p>生成任务的评估指标 : BLEU、ROUGE</p> <p>参考资料：<a href="https://www.bilibili.com/video/BV1am4y177PC/?spm_id_from=333.337.search-card.all.click&vd_source=ae67b970bd4a0665fa92195df95aa1f3">自然语言生成（NLG）任务主客观评价指标汇总</a></p> </blockquote> <h3 id=_15>关系抽取</h3> <p>常见的关系抽取结果可以用SPO结构的三元组来表示，即（Subject, Predication, Object）如：中国的首都是北京==&gt; (中国，首都，北京)。思路一：分两个任务先抽取实体再判断实体之间的关系，思路二：同时进行实体抽取和关系抽取。</p> <ul> <li>思路一 ：BERT - FNN/Attention</li> </ul> <p>思路一很简单，把BERT的输入改成实体1、实体2、文本，输出改为多分类的全连接层即可。更复杂一点话呢可以像情感分类一样加入attension机制，以增加模型对实体1和实体2的理解和使用。之前做过实验了，可以说和主题情感分析一毛一样，不过把LSTM换成了BERT。</p> <ul> <li>思路二 ：BERT - CasRel</li> </ul> <blockquote> <p>《A Novel Cascade Binary Tagging Framework for Relational Triple Extraction》</p> <p>论文链接：https://aclanthology.org/2020.acl-main.136.pdf</p> <p>代码地址：https://github.com/weizhepei/CasRel</p> </blockquote> <figure class=figure-image style="text-align: center;"> <img src=../image-31.png alt="An image caption" style="width: 80%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <h3 id=_16>命名实体识别</h3> <ul> <li>BERT - BILSTM - CRF</li> </ul> <figure class=figure-image style="text-align: center;"> <img src=../image-23.png alt="An image caption" style="width: 90%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <h3 id=_17>主题情感分类</h3> <ul> <li>BERT - Attention</li> </ul> <figure class=figure-image style="text-align: center;"> <img src=../image-32.png alt="An image caption" style="width: 70%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <blockquote> <p>把LSTM换成BERT</p> </blockquote> <h3 id=_18>摘要系统</h3> <ul> <li>BERT - Transformer</li> </ul> <blockquote> <p>很牛的PEGASUS其实可以理解为Transformer - Transformer，思路差不多，不过设计了一个近似的无监督摘要任务，这样就不需要很多标注数据咯...</p> </blockquote> <p>文本摘要可分为抽取式摘要和生成式摘要：抽取式摘要从源文档中抽取关键句和关键词组成摘要，摘要信息全部来源于原。<strong>生成式摘要</strong>(NLG, Natural Language Generation)根据原文，允许生成新的词语、短语来组成摘要。生成式摘要也称为抽象式摘要。BERT两者都能实现。</p> <figure class=figure-image style="text-align: center;"> <img src=../image-20.png alt="An image caption" style="width: 60%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> <blockquote> <p>编码器用于提取重要的文本特征，解码器用于生成摘要。编码器使用预训练好的bert， 解码器直接使用transformer的解码器并随机初始化，用标注数据训练</p> </blockquote> <figure class=figure-image style="text-align: center;"> <img src=../image-1.jpg alt="An image caption" style="width: 60%; display: block; margin: 0 auto; border: 2px solid #000080; border-radius: 10px; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.5);"> </figure> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg> 回到页面顶部 </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=页脚> <a href=../%E8%80%83%E8%AF%95%E8%AF%B4%E6%98%8E/ class="md-footer__link md-footer__link--prev" aria-label="上一页: 考试说明"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> 上一页 </span> <div class=md-ellipsis> 考试说明 </div> </div> </a> <a href=../../../%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/git/ class="md-footer__link md-footer__link--next" aria-label="下一页: git"> <div class=md-footer__title> <span class=md-footer__direction> 下一页 </span> <div class=md-ellipsis> git </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright © 2024 Whu-NS </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/Summu77 target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["navigation.tabs", "announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.tooltips", "navigation.footer", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script> <script src=../../../assets/javascripts/bundle.d7c377c4.min.js></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=../../../assets/javascripts/custom.2340dcd7.min.js></script> </body> </html>