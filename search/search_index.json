{"config":{"lang":["en"],"separator":"[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+","pipeline":["stemmer"]},"docs":[{"location":"","title":"My Website","text":"<p>Welcome to my website!</p>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/DDIM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/","title":"Denoising Diffusion Implicit Models","text":"<p>code: nn.labml.ai: Denoising Diffusion Implicit Models</p> <p>paper: Denoising Diffusion Implicit Models</p> <p>DDPM\u5230DDIM\u6211\u4e4b\u524d\u5728\u53e6\u4e00\u7bc7\u7b14\u8bb0\u4e2d\u5df2\u7ecf\u5f88\u8be6\u7ec6\u7684\u5206\u6790\u8fc7\u4e86\uff0c\u4e0b\u9762\u76f4\u63a5\u7ed9DDIM\u8868\u8fbe\u5f0f\uff1a</p> <p>DDPM\u4ee3\u7801\u6211\u4e5f\u5728\u5176\u4ed6\u7b14\u8bb0\u4e2d\u8be6\u7ec6\u5206\u6790\u8fc7\u4e86\uff0c\u56e0\u6b64\u53ea\u9610\u8ff0\u4ee3\u7801\u7684\u6838\u5fc3\u4e0d\u540c\u70b9\u3002</p> <p>\u672c\u8d28\u4e0a\u6765\u8bf4\uff0cDDIM\u5c31\u662f\u65b0\u7684\u4e00\u79cd\u91c7\u6837\u65b9\u5f0f\uff0c\u4f46\u662f\u6a21\u578b\u53ef\u4ee5\u548cDDPM\u4e00\u6a21\u4e00\u6837\uff01</p> <p>DDIM\u53ea\u9700\u898150\u6b65\u5c31\u80fd\u63a5\u8fd1DDPM1000\u6b65\u7684\u6548\u679c\uff01</p>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/DDIM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#_1","title":"\u79bb\u6563\u5316\u91c7\u6837","text":"<pre><code>self.n_steps = model.n_steps\n# \u5747\u5300\u79bb\u6563\u5316\nif ddim_discretize == 'uniform':\n    c = self.n_steps // n_steps\n    self.time_steps = np.asarray(list(range(0, self.n_steps, c))) + 1\n# \u5e73\u65b9\u79bb\u6563\u5316\nelif ddim_discretize == 'quad':\n    self.time_steps = ((np.linspace(0, np.sqrt(self.n_steps * .8), n_steps)) ** 2).astype(int) + 1\nelse:\n    raise NotImplementedError(ddim_discretize)\n</code></pre> <ul> <li>\u5747\u5300\u79bb\u6563\u5316\uff08uniform\uff09\uff1a\u751f\u6210\u65f6\u95f4\u6b65\u95f4\u9694\u56fa\u5b9a\uff0c\u9002\u7528\u4e8e\u5bf9\u6240\u6709\u65f6\u95f4\u6b65\u8981\u6c42\u4e00\u81f4\u7684\u60c5\u51b5\u3002</li> <li>\u5e73\u65b9\u79bb\u6563\u5316\uff08quad\uff09\uff1a\u751f\u6210\u524d\u671f\u5bc6\u96c6\u3001\u540e\u671f\u7a00\u758f\u7684\u65f6\u95f4\u6b65\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u5728\u751f\u6210\u65e9\u671f\u5feb\u901f\u53bb\u566a\uff0c\u800c\u5728\u751f\u6210\u540e\u671f\u4fdd\u6301\u66f4\u591a\u7ec6\u8282\uff0c\u63d0\u9ad8\u751f\u6210\u56fe\u50cf\u7684\u8d28\u91cf\u3002</li> </ul>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/DDIM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#sample","title":"\u91c7\u6837Sample\uff08\u53bb\u566a\u8fc7\u7a0b\uff09","text":"<p>\u5f97\u76ca\u4e8e\u79bb\u6563\u5316\u548c\u975e\u9a6c\u5c14\u79d1\u592b\u6027\u8d28\uff0cDDIM\u91c7\u6837\u6709\u591a\u597d\u5904\uff1a</p> <ul> <li>\u751f\u6210\u8fc7\u7a0b\u5177\u6709\u4e00\u81f4\u6027\uff1aDDIM\u7684\u751f\u6210\u8fc7\u7a0b\u662f\u786e\u5b9a\u6027\u7684\uff0c\u8fd9\u610f\u5473\u7740\u5728\u76f8\u540c\u7684\u6f5c\u5728\u53d8\u91cf\u6761\u4ef6\u4e0b\uff0c\u751f\u6210\u7684\u591a\u4e2a\u6837\u672c\u5e94\u8be5\u5177\u6709\u76f8\u4f3c\u7684\u9ad8\u5c42\u6b21\u7279\u5f81\u3002\u8fd9\u4f7f\u5176\u751f\u6210\u6837\u672c\u65f6\u8868\u73b0\u66f4\u7a33\u5b9a\u4e00\u81f4\u3002</li> <li>\u8bed\u4e49\u63d2\u503c\uff1a\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u63d2\u503c\u4e24\u4e2a\u4e0d\u540c\u7684\u6f5c\u5728\u53d8\u91cf\uff0cDDIM\u751f\u6210\u7684\u4e2d\u95f4\u6837\u672c\u80fd\u591f\u5728\u8bed\u4e49\u4e0a\u9010\u6e10\u8fc7\u6e21\u3002\u8fd9\u4f7f\u5f97DDIM\u5728\u56fe\u50cf\u751f\u6210\u3001\u56fe\u50cf\u7f16\u8f91\u548c\u56fe\u50cf\u8f6c\u6362\u7b49\u4efb\u52a1\u4e2d\u5177\u6709\u5f88\u5927\u7684\u5e94\u7528\u6f5c\u529b\u3002</li> </ul> <p>\u4f53\u73b0\u5728\u4ee3\u7801\u4e0a\uff0cDDIM\u7684\u91c7\u6837\u5982\u4e0b\uff1a</p> <pre><code>bs = shape[0]\n\n# \u53ef\u4ee5\u901a\u8fc7x_last\u6307\u5b9a\u521d\u59cb\u566a\u58f0\nx = x_last if x_last is not None else torch.randn(shape, device=device)\n\n# \u53ef\u4ee5\u901a\u8fc7skip_steps\u8df3\u8fc7\u4e00\u4e9b\u65f6\u95f4\u6b65\ntime_steps = np.flip(self.time_steps)[skip_steps:] # flip\u662f\u7ffb\u8f6c\u987a\u5e8f\n\nfor i, step in monit.enum('Sample', time_steps):\n    index = len(time_steps) - i - 1\n    # \u6269\u5145\u7ef4\u5ea6\n    ts = x.new_full((bs,), step, dtype=torch.long)\n    x, pred_x0, e_t = self.p_sample(x, cond, ts, step, index=index, \n                                    repeat_noise=repeat_noise, \n                                    temperature=temperature, \n                                    uncond_scale=uncond_scale, \n                                    uncond_cond=uncond_cond)\nreturn x\n</code></pre> <p>\u5177\u4f53\u7684\u6bcf\u4e00\u6b65\u91c7\u6837\u8fc7\u7a0b\u5982\u4e0b\uff1a</p> <pre><code># \u5f97\u5230\u9884\u6d4b\u566a\u58f0\u503ce_t\ne_t = self.get_eps(x, t, c, uncond_scale=uncond_scale, uncond_cond=uncond_cond)\n\n# \u6839\u636ee_t\u8ba1\u7b97x_prev, pred_x0\nx_prev, pred_x0 = self.get_x_prev_and_pred_x0(e_t, index, x,\n        temperature=temperature,\n        repeat_noise=repeat_noise)\nreturn x_prev, pred_x0, e_t\n\ndef get_x_prev_and_pred_x0(self, e_t: torch.Tensor, index: int, x: torch.Tensor, *,\n                           temperature: float,\n                           repeat_noise: bool):\n    alpha = self.ddim_alpha[index]\n    alpha_prev = self.ddim_alpha_prev[index]\n    sigma = self.ddim_sigma[index]\n    sqrt_one_minus_alpha = self.ddim_sqrt_one_minus_alpha[index]\n\n    pred_x0 = (x - sqrt_one_minus_alpha * e_t) / (alpha ** 0.5)\n    dir_xt = (1. - alpha_prev - sigma ** 2).sqrt() * e_t\n\n    if sigma == 0.:\n        noise = 0.\n    elif repeat_noise:\n        noise = torch.randn((1, *x.shape[1:]), device=x.device)\n    else:\n        noise = torch.randn(x.shape, device=x.device)\n\n    noise = noise * temperature\n    x_prev = (alpha_prev ** 0.5) * pred_x0 + dir_xt + sigma * noise\n    return x_prev, pred_x0\n\n</code></pre> <p>\u5176\u4e2d\u6838\u5fc3\u7684\u4ee3\u7801\u516c\u5f0f\u5bf9\u5e94\u5173\u7cfb\u5982\u4e0b\uff1a</p>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/DDIM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#paint","title":"Paint\uff08\u5b9a\u5236\u5316\u91c7\u6837/\u53bb\u566a\uff09","text":"<p>\u5b9a\u5236\u5316\u4f53\u73b0\u5728\uff1a</p> <ul> <li>\u53ef\u4ee5\u4ece\u6307\u5b9a\u65f6\u95f4\u6b65\u5f00\u59cb\uff0c\u53ef\u4ee5\u8df3\u6b65\u9aa4</li> <li>\u53ef\u4ee5\u6307\u5b9a\u8f93\u5165x\uff0c\u6bd4\u5982\u53ef\u4ee5\u662f\u4e00\u5f20\u56fe\u7247\u52a0\u566a\u4e4b\u540e\u5f97\u5230\u7684\u566a\u58f0</li> <li>\u53ef\u4ee5\u4f7f\u7528Mask\u8fdb\u884c\u7279\u5f81\u878d\u5408</li> </ul> <pre><code>def paint(self, x: torch.Tensor, cond: torch.Tensor, t_start: int, *,\n              orig: Optional[torch.Tensor] = None,\n              mask: Optional[torch.Tensor] = None, orig_noise: Optional[torch.Tensor] = None,\n              uncond_scale: float = 1.,\n              uncond_cond: Optional[torch.Tensor] = None,\n              ):\n\n        bs = x.shape[0]\n        time_steps = np.flip(self.time_steps[:t_start])\n\n        for i, step in monit.enum('Paint', time_steps):\n            index = len(time_steps) - i - 1\n            ts = x.new_full((bs,), step, dtype=torch.long)\n\n            x, _, _ = self.p_sample(x, cond, ts, step, index=index,\n                                    uncond_scale=uncond_scale,\n                                    uncond_cond=uncond_cond)\n            if orig is not None:\n                orig_t = self.q_sample(orig, index, noise=orig_noise)\n                x = orig_t * mask + x * (1 - mask)\n        return x\n</code></pre>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/DDPM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/","title":"Denoising Diffusion Probabilistic Models","text":"<p>code: nn.labml.ai: Denoising Diffusion Probabilistic Models</p> <p>paper: Denoising Diffusion Probabilistic Models</p>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/DDPM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#_1","title":"\u57fa\u7840\u5b9a\u4e49","text":"<p>diffusion\u4e2d\u7684\u51e0\u4e2a\u7b26\u53f7\u8981\u6bd4\u8f83\u6e05\u695a\uff1a</p> <pre><code>self.beta = torch.linspace(0.0001, 0.02, n_steps).to(device)\nself.alpha = 1 - self.beta\nself.alpha_bar = torch.cumprod(self.alpha, dim=0)\nself.sigma2 = self.beta\nself.n_steps = n_steps # \u8fd9\u4e2a\u8bad\u7ec3\u7684\u65f6\u5019\u751f\u6210\u4e00\u6279t\uff0c\u8fd9\u4e9bt\u662f\u968f\u673a\u7684\u4e14\u5c0f\u4e8en_steps\n</code></pre>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/DDPM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#q-x_t-x_0","title":"\u524d\u5411\u8fc7\u7a0b q ( x_t | x_0 )","text":"<p>\u6574\u4f53\u5c31\u662f\u5b9e\u73b0\u4e00\u4e2a\u91c7\u6837\u7684\u8fc7\u7a0b\uff0c\u4e5f\u5c31\u662f\u6839\u636e\u65f6\u95f4\u6b65 t \u548c\u521d\u59cb\u72b6\u6001 x0\uff0c\u91c7\u6837\u4e00\u4e2a\u72b6\u6001 x_t\u3002</p> <p>\ud835\udc3c \u662f\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\uff08identity matrix\uff09\uff0c\u4e5f\u79f0\u4e3a\u6052\u7b49\u77e9\u9635\u3002\u5728\u77e9\u9635\u4e58\u6cd5\u4e2d\u7c7b\u4f3c\u4e8e\u6570\u5b571\u7684\u4f5c\u7528\u3002</p> <pre><code>def q_sample(self, \n            x0: torch.Tensor, \n            t: torch.Tensor, \n            eps: Optional[torch.Tensor] = None):  \n\n    if eps is None:\n        eps = torch.randn_like(x0)\n    mean, var = self.q_xt_x0(x0, t)\n\n    # \u4ece\u5747\u503c\u4e3amean\uff0c\u65b9\u5dee\u4e3avar\u7684\u6b63\u6001\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u8fd4\u56de\u8fd9\u4e2a\u91c7\u6837\u7ed3\u679c\n    return mean + (var ** 0.5) * eps \n</code></pre> <pre><code>def q_xt_x0(self, x0: torch.Tensor, t: torch.Tensor) \n                    -&gt; Tuple[torch.Tensor, torch.Tensor]:\n\n    # \u590d\u73b0\u516c\u5f0f\u7f62\u4e86\n    mean = gather(self.alpha_bar, t) ** 0.5 * x0\n    var = 1 - gather(self.alpha_bar, t)\n    return mean, var\n</code></pre>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/DDPM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#p-x_t-1-x_t","title":"\u9006\u5411\u8fc7\u7a0b p ( x_t-1 | x_t )","text":"<p>\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cDDPM\u4e2d\u7684\u65b9\u5dee\u662f\u4e0d\u9884\u6d4b\u7684\uff0c\u5373\u524d\u5411\u8fc7\u7a0b\u548c\u9006\u5411\u8fc7\u7a0b\u5206\u5e03\u7684\u65b9\u5dee\u4e00\u81f4\uff01\u4f46\u662f\u4ee3\u7801\u8fd8\u662f\u7b80\u5316\u4e86\u65b9\u5dee\u7684\u8868\u793a\uff0c\u539f\u672c\u7684\u65b9\u5dee\u662f\u6c42\u89e3\u51fa\u6765\u7684\uff0c\u4f1a\u66f4\u52a0\u590d\u6742\u4e00\u70b9\uff0c\u539f\u672c\u7684\u65b9\u5dee\u5982\u4e0b\uff1a</p> <p>\u4e3a\u4ec0\u4e48\u8981\u7b80\u5316\u8fd9\u4e2a\u65b9\u5dee\u5462\uff1f\u7406\u7531\u5982\u4e0b\uff1a</p> <p>\u9006\u5411\u8fc7\u7a0b\u6574\u4f53\u5c31\u662f\u5b9e\u73b0\u4e00\u4e2a\u91c7\u6837\u7684\u8fc7\u7a0b\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a</p> <p>\u8bad\u7ec3\u7684\u65f6\u5019\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528MSE\u635f\u5931\u51fd\u6570\uff08\u5747\u65b9\u8bef\u5dee\uff09\u5373\u53ef\uff08\u56e0\u4e3a\u8f93\u5165\u662f\u4e00\u6279\u6570\u636e\uff09\u3002</p> <pre><code>def p_sample(self, xt: torch.Tensor, t: torch.Tensor):\n    # \u83b7\u5f97\u4e00\u4e9b\u53c2\u6570\n    eps_theta = self.eps_model(xt, t)\n    alpha_bar = gather(self.alpha_bar, t)\n    alpha = gather(self.alpha, t)\n    eps_coef = (1 - alpha) / (1 - alpha_bar) ** .5\n\n    # \u91c7\u6837\u516c\u5f0f\n    mean = 1 / (alpha ** 0.5) * (xt - eps_coef * eps_theta)\n    var = gather(self.sigma2, t)\n    eps = torch.randn(xt.shape, device=xt.device)\n    return mean + (var ** .5) * eps\n</code></pre>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/DDPM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#unet-model-for-ddpm","title":"Unet model for DDPM","text":"<p>Unet\u6a21\u578b\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff0c\u4e3b\u8981\u53ef\u4ee5\u5206\u4e3aUp Block\u3001Down Block\u3001Middle Block\uff1a</p> <p>\u4e3a\u4ec0\u4e48\u8981\u5c06Encoder\u548cDecoder\u8fde\u63a5\u8d77\u6765\u5462\uff1f\u4e00\u822c\u8ba4\u4e3a\uff0cEncoder\u5305\u542b\u66f4\u591a\u7684\u7a7a\u95f4\u4fe1\u606f\uff0cDecoder\u5305\u542b\u66f4\u591a\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u5c06\u4e24\u8005\u7ed3\u5408\u8d77\u6765\uff0c\u53ef\u4ee5\u5b9e\u73b0\u50cf\u7d20\u7ea7\u522b\u7684\u5206\u5272\u6548\u679c\u3002</p> <p>\u7531\u4e8eUp Block\u3001Down Block\u3001Middle Block\u90fd\u662f\u7531ResidualBlock\u548cAttentionBlock\u6784\u6210\u7684\u3002\u800c\u4e14AttentionBlock\u5c31\u662f\u5e38\u89c1\u7684Multi-head attention\uff0c\u56e0\u6b64\u8fd9\u91cc\u8be6\u7ec6\u5206\u6790\u4e00\u4e0bResidualBlock\u3002</p> <p>\u9700\u8981\u8bb0\u4f4f\u4e00\u4e2a\u5f88\u91cd\u8981\u7684\u70b9\u662fResidualBlock\u548cAttentionBlock\u7684\u8f93\u5165\u548c\u8f93\u51fa\u7ef4\u5ea6\u4e00\u81f4\u3002</p>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/DDPM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#residual-block","title":"Residual Block","text":"<p>\u5148\u8865\u5145\u4e00\u4e9b\u6982\u5ff5\uff1a</p> <ul> <li>\u7ec4\u5f52\u4e00\u5316\uff08Group Normalization\uff09\u901a\u8fc7\u5c06\u901a\u9053\u5212\u5206\u4e3a\u591a\u4e2a\u7ec4\uff0c\u5e76\u5728\u6bcf\u4e2a\u7ec4\u5185\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u6765\u89e3\u51b3\u6279\u5f52\u4e00\u5316\u5728\u5c0f\u6279\u91cf\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\u3002</li> <li>Shortcut \u662f\u6307\u6377\u5f84\u8fde\u63a5\uff0c\u7528\u4e8e\u5728\u8f93\u5165\u548c\u8f93\u51fa\u7ef4\u5ea6\u4e0d\u540c\u65f6\u8c03\u6574\uff0c\u4ee5\u6b63\u786e\u5730\u6267\u884c\u52a0\u6cd5\u64cd\u4f5c\u3002</li> <li> <p>\u5148\u5f52\u4e00\u5316\uff0c\u518d\u6fc0\u6d3b\uff0c\u6700\u540e\u5377\u79ef\uff0c\u5728\u6fc0\u6d3b\u4e4b\u524d\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u53ef\u4ee5\u786e\u4fdd\u6fc0\u6d3b\u51fd\u6570\u8f93\u5165\u7684\u5206\u5e03\u66f4\u7a33\u5b9a\u548c\u96c6\u4e2d\uff0c\u4ece\u800c\u4f7f\u5f97\u7f51\u7edc\u8bad\u7ec3\u66f4\u52a0\u7a33\u5b9a\u3002\u5728\u5f52\u4e00\u5316\u548c\u6fc0\u6d3b\u540e\u7684\u7279\u5f81\u56fe\u4e0a\u8fdb\u884c\u5377\u79ef\u64cd\u4f5c\uff0c\u5728\u7a33\u5b9a\u548c\u96c6\u4e2d\u5206\u5e03\u7684\u6570\u636e\u4e0a\u8fdb\u884c\u64cd\u4f5c\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u5b66\u4e60\u548c\u63d0\u53d6\u7279\u5f81\u3002</p> </li> <li> <p>Residual Block\u5b9e\u73b0\u4e86\u65f6\u95f4\u4fe1\u606ft\u7684\u7f16\u7801\u3002\u4f46\u662f\u8f93\u5165\u7684t\u662f\u7ecf\u8fc7\u7f16\u7801\u7684\u5411\u91cf\uff01\u800c\u4e0d\u662f\u4e00\u4e2a\u6570\u5b57\uff01</p> </li> </ul> <p>x has shape [batch_size, in_channels, height, width] t has shape [batch_size, time_channels]</p> <pre><code>class ResidualBlock(Module):\n    def __init__(self, in_channels: int, out_channels: int, time_channels: int,\n                 n_groups: int = 32, dropout: float = 0.1):\n        super().__init__()\n        self.norm1 = nn.GroupNorm(n_groups, in_channels)\n        self.act1 = Swish()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), padding=(1, 1))\n        self.norm2 = nn.GroupNorm(n_groups, out_channels)\n        self.act2 = Swish()\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), padding=(1, 1))\n        if in_channels != out_channels:\n            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1))\n            else:\n                self.shortcut = nn.Identity()\n        self.time_emb = nn.Linear(time_channels, out_channels)\n        self.time_act = Swish()\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x: torch.Tensor, t: torch.Tensor):\n        h = self.conv1(self.act1(self.norm1(x)))\n        h += self.time_emb(self.time_act(t))[:, :, None, None]\n        h = self.conv2(self.dropout(self.act2(self.norm2(h))))\n        return h + self.shortcut(x)\n</code></pre>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/DDPM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#down","title":"Down","text":"<ul> <li>DownBlock\u662f\u56fe\u4e2d\u7684\u6c34\u5e73\u7bad\u5934\uff0c\u4e0d\u8fc7\u7a0d\u52a0\u6539\u8fdb\u7531ResidualBlock\u548cAttentionBlock\u6784\u6210\u3002</li> <li>Downsample\u5219\u662f\u4e2a\u5377\u79ef\u5c42\uff0c\u7528\u4e8e\u4e0b\u91c7\u6837\uff0c\u662f\u56fe\u4e2d\u7684\u5411\u4e0b\u7684\u7bad\u5934\u3002</li> </ul> <pre><code>down = []\nout_channels = in_channels = n_channels\nfor i in range(n_resolutions):\n    out_channels = in_channels * ch_mults[i]\n    for _ in range(n_blocks):\n        down.append(DownBlock(in_channels, out_channels, n_channels * 4, is_attn[i]))\n        in_channels = out_channels\n    if i &lt; n_resolutions - 1:\n        down.append(Downsample(in_channels))\nself.down = nn.ModuleList(down)\n</code></pre> <p>Middle\u3001Up\u7c7b\u4f3c\uff0c\u8fd9\u91cc\u4e0d\u518d\u8d58\u8ff0\u4e86\uff0c\u53ef\u4ee5\u81ea\u884c\u67e5\u770b\u4ee3\u7801\u3002</p>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/DDPM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#unet","title":"Unet","text":"<pre><code>def forward(self, x: torch.Tensor, t: torch.Tensor):\n    t = self.time_emb(t)\n    x = self.image_proj(x)\n    h = [x]\n\n    # \u4e0b\u91c7\u6837\n    for m in self.down:\n        x = m(x, t)\n        h.append(x)\n    x = self.middle(x, t)\n\n    # \u4e0a\u91c7\u6837\n    for m in self.up:\n        if isinstance(m, Upsample):\n            x = m(x, t)\n        # \u62fc\u63a5\u64cd\u4f5c\n        else:\n            s = h.pop()\n            x = torch.cat((x, s), dim=1)\n            x = m(x, t)\n    return self.final(self.act(self.norm(x)))\n</code></pre>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/LDM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/","title":"Latent Diffusion Models","text":"<p>Code: nn.labml.ai: Latent Diffusion Models</p> <p>Paper: High-Resolution Image Synthesis with Latent Diffusion Models</p> <p>DDPM\u548cLDM\u7684\u6838\u5fc3\u5dee\u5f02\u5728\u4e8eUnet\u7f51\u7edc\u3002\u5728 DDPM \u7684\u4ee3\u7801\u5206\u6790\u4e2d\uff0c\u6211\u4eec\u5df2\u7ecf\u5b9e\u73b0\u4e86 Unet\uff0c\u4f46\u662f\u8fd9\u91cc\u7684 Unet \u548c DDPM \u7684 Unet \u4e0d\u540c\u3002\u56e0\u4e3a Stable Diffusion \u9700\u8981\u5f15\u5165\u6761\u4ef6\u4fe1\u606f\uff08c\uff09\u7684\u63a7\u5236\u3002</p>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/LDM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#unet-for-stable-diffusion","title":"Unet for Stable Diffusion","text":"<p>Unet for DDPM \u6211\u4eec\u4e4b\u524d\u8be6\u7ec6\u5206\u6790\u8fc7\uff0c\u4e3b\u8981\u662f\u7531ResidualBlock\u548cAttentionBlock\u6784\u6210\uff0c\u5176\u4e2dResidualBlock\u53ef\u4ee5\u878d\u5408\u65f6\u95f4\u4fe1\u606ft\uff0cAttentionBlock\u5355\u7eaf\u4e3a\u4e86\u6a21\u578b\u6027\u80fd\u66f4\u597d\u3002</p> <p>\u5728 Unet for Stable Diffusion \u4e2d\uff0cResidualBlock\u4fdd\u6301\u4e00\u81f4\uff0c\u53ef\u4ee5\u878d\u5408\u65f6\u95f4\u4fe1\u606ft\uff1bAttentionBlock\u5219\u5f15\u5165\u4e86\u6761\u4ef6\u4fe1\u606fc\u5f15\u5bfc\uff0c\u4ece\u591a\u5934\u6ce8\u610f\u529b\u53d8\u6210\u4e86\u4ea4\u53c9\u6ce8\u610f\u529b\uff01\u540c\u65f6\u5347\u7ea7\u4e86\u4e00\u4e0b\uff0c\u53d8\u6210\u4e86SpatialTransformer\u3002</p>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/LDM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#spatialtransformer","title":"SpatialTransformer","text":"<p>\u4e3a\u4e86\u66f4\u597d\u7684\u7406\u89e3\uff0c\u6211\u753b\u4e86\u4e00\u4e0b\u5176\u5927\u81f4\u7ed3\u6784\u56fe\uff0c\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>def forward(self, x: torch.Tensor, cond: torch.Tensor):\n\n    b, c, h, w = x.shape\n    x_in = x # For residual connection\n    x = self.norm(x)\n\n    # Transpose and reshape from `[batch_size, channels, height, width]`\n    # to `[batch_size, height * width, channels]`\u8fd9\u4e2a\u6ca1\u529e\u6cd5\u89c6\u89c9Transformer\u53ea\u80fd\u8fd9\u6837\uff01\n    x = self.proj_in(x)\n    x = x.permute(0, 2, 3, 1).view(b, h * w, c)\n\n    for block in self.transformer_blocks:\n        x = block(x, cond)\n\n    # Reshape\n    x = x.view(b, h, w, c).permute(0, 3, 1, 2)\n    x = self.proj_out(x)\n    return x + x_in\n</code></pre> <p>\u5176\u4e2d\u4f7f\u7528\u5230\u7684transformer_blocks\u4e3a\u591a\u4e2aBasicTransformerBlock\uff1a</p> <pre><code>self.attn1 = CrossAttention(d_model, d_model, n_heads, d_head)\nself.attn2 = CrossAttention(d_model, d_cond, n_heads, d_head)\n\ndef forward(self, x: torch.Tensor, cond: torch.Tensor):\n        # Self attention\n        x = self.attn1(self.norm1(x)) + x\n\n        # Cross-attention with conditioning\n        x = self.attn2(self.norm2(x), cond=cond) + x\n\n        # Feed-forward network\n        x = self.ff(self.norm3(x)) + x\n\n        return x\n</code></pre> <p>\u5176\u4e2d\uff08attn1\u3001attn2\uff09\u975e\u5e38\u91cd\u8981\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u548c\u81ea\u6ce8\u610f\u529b\u90fd\u53ef\u4ee5\u5b9e\u73b0\u5982\u4e0b\uff1a</p> <pre><code>def forward(self, x: torch.Tensor, cond: Optional[torch.Tensor] = None):\n    # If `cond` is `None` we perform self attention\n    has_cond = cond is not None\n    if not has_cond:\n        cond = x\n\n    # Get query, key and value vectors\n    q = self.to_q(x)\n    k = self.to_k(cond)\n    v = self.to_v(cond)\n\n    # Use flash attention if it's available and the head size is less than or equal to `128`\n    if CrossAttention.use_flash_attention and self.flash is not None and not has_cond and self.d_head &lt;= 128:\n        return self.flash_attention(q, k, v)\n    # Otherwise, fallback to normal attention\n    else:\n        return self.normal_attention(q, k, v)\n</code></pre>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/LDM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#autoencoder-first_stage_model","title":"Autoencoder (first_stage_model)","text":""},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/LDM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#encode-decode","title":"encode &amp; decode","text":"<pre><code>def encode(self, img: torch.Tensor) -&gt; 'GaussianDistribution':\n    # [batch_size, z_channels * 2, z_height, z_height]\n    z = self.encoder(img) \n\n    # [batch_size, emb_channels * 2, z_height, z_height]\n    moments = self.quant_conv(z) \n\n    return GaussianDistribution(moments)\n</code></pre> <p>\u9ad8\u65af\u5206\u5e03\u4e3b\u8981\u53c2\u6570\u662f\u5747\u503c (mean) \u548c\u65b9\u5dee (variance)\uff0c\u5373\u7b2c\u4e00\u548c\u7b2c\u4e8c\u9636\u77e9 (moments)</p> <pre><code>def decode(self, z: torch.Tensor):\n    z = self.post_quant_conv(z)\n    return self.decoder(z)\n</code></pre>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/LDM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#gaussiandistribution","title":"GaussianDistribution","text":"<pre><code>class GaussianDistribution:\n    def __init__(self, parameters: torch.Tensor):\n        self.mean, log_var = torch.chunk(parameters, 2, dim=1)\n        self.log_var = torch.clamp(log_var, -30.0, 20.0)\n        self.std = torch.exp(0.5 * self.log_var)\n\n    def sample(self):\n        return self.mean + self.std * torch.randn_like(self.std)\n</code></pre>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/LDM%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#cliptextembedder-cond_stage_model","title":"CLIPTextEmbedder (cond_stage_model)","text":"<pre><code>class CLIPTextEmbedder(nn.Module):\n\n     def __init__(self, version: str = \"openai/clip-vit-large-patch14\", device=\"cuda:0\", max_length: int = 77):\n        super().__init__()\n        self.tokenizer = CLIPTokenizer.from_pretrained(version)\n        self.transformer = CLIPTextModel.from_pretrained(version).eval()\n        self.device = device\n        self.max_length = max_length\n\n    def forward(self, prompts: List[str]):\n        batch_encoding = self.tokenizer(\n            prompts, \n            truncation=True, \n            max_length=self.max_length, \n            return_length=True, # \u8fd4\u56de\u7684\u4e00\u4e2a\u5b57\u6bb5\u4e3alength!\n            return_overflowing_tokens=False, \n            # \u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u4f60\u53ef\u80fd\u9700\u8981\u4fdd\u7559\u88ab\u622a\u65ad\u7684\u90e8\u5206\u4ee5\u4fbf\u540e\u7eed\u5904\u7406\u3002\u4f46\u8fd9\u91cc\u4e0d\u7528\n            padding=\"max_length\", \n            return_tensors=\"pt\")\n        tokens = batch_encoding[\"input_ids\"].to(self.device)\n        return self.transformer(input_ids=tokens).last_hidden_state\n</code></pre>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/Llava%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/","title":"Llava","text":"<p>\u6e90\u7801\u6765\u81eaTransformers\u5e93\u4e2d\u7684llava\u5b9e\u73b0\uff0c\u4e3a\u4e86\u68b3\u7406\u903b\u8f91\uff0c\u6211\u8fdb\u884c\u4e86\u90e8\u5206\u8c03\u6574</p> <p>\u5176\u4e2d\u7684Vision Encoder\u4f7f\u7528\u7684\u662fCLIP\u6a21\u578b\uff0cLanguage Model\u4f7f\u7528\u7684\u662fLlama\u6a21\u578b\u3002</p> <p>\u53e6\u5916\uff0cCLIP\u6a21\u578b\u8fd9\u91cc\u4f7f\u7528\u7684\u662fVIT\uff0824\u5c42\uff09\u3002</p>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/Llava%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#_1","title":"\u6e90\u7801\u89e3\u6790","text":"<ul> <li>\u7b2c\u4e00\u6b65\uff1a\u83b7\u5f97\u56fe\u7247\u548c\u6587\u672c\u7684\u5d4c\u5165</li> </ul> <pre><code># \u6587\u672c\u5d4c\u5165 torch.Size([1, 13, 4096])\ninputs_embeds = self.get_input_embeddings()(input_ids)\n\n# \u56fe\u7247\u5d4c\u5165 torch.Size([1, 576, 4096])\nimage_outputs = self.vision_tower(pixel_values, output_hidden_states=True)\nselected_image_feature = image_outputs.hidden_states[vision_feature_layer] # -2\nselected_image_feature = selected_image_feature[:, 1:] # \u53bb\u9664\u4e86CLS token\nimage_features = self.multi_modal_projector(selected_image_feature) # 1024 -&gt; 4096\n</code></pre> <p>\u30101\u3011\u901a\u5e38\uff0c\u6700\u540e\u4e00\u5c42\u7528\u4e8e\u5176\u4ed6\u4efb\u52a1\uff08\u4f8b\u5982\u5206\u7c7b\u7b49\uff09\uff0c\u4e14\u8fdb\u884c\u4e86\u975e\u7ebf\u6027\u6fc0\u6d3b\u6216\u53d8\u6362\u3002\u9009\u62e9 -2 \u7684\u539f\u56e0\u662f\uff0c\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\uff0c\u5012\u6570\u7b2c\u4e8c\u5c42\u7684\u8f93\u51fa\u5305\u542b\u4e86\u4e30\u5bcc\u7684\u7279\u5f81\u4fe1\u606f\uff0c\u5e76\u4e14\u6ca1\u6709\u8fc7\u591a\u7684\u975e\u7ebf\u6027\u5904\u7406\u3002</p> <p>\u30102\u3011\u6ce8\u610f\u8fd9\u91cc\u5904\u7406\u9664\u4e86\u8c03\u7528vision_tower\uff08\u5b9e\u9645\u4e0a\u5c31\u662fCLIP\u89c6\u89c9\u7f16\u7801\u5668-24\u5c42\uff09\uff0c\u8fd8\u8c03\u7528\u4e86multi_modal_projector\uff0c\u5c06\u7279\u5f81\u8fdb\u884c\u4e00\u4e2a\u6620\u5c04\uff0c\u4ece1024\u7684\u89c6\u89c9\u7a7a\u95f4\u6620\u5c04\u5230\u4e864096\u7684\u6587\u672c\u7a7a\u95f4\u3002</p> <pre><code>self.linear_1 = nn.Linear(config.vision_config.hidden_size, config.text_config.hidden_size, bias=True)\nself.act = ACT2FN[config.projector_hidden_act]\nself.linear_2 = nn.Linear(config.text_config.hidden_size, config.text_config.hidden_size, bias=True)\n</code></pre> <ul> <li>\u7b2c\u4e8c\u6b65\uff1a\u878d\u5408\u6587\u672c\u7279\u5f81\u548c\u56fe\u7247\u7279\u5f81</li> </ul> <pre><code>inputs_embeds, attention_mask, labels, position_ids = \nself._merge_input_ids_with_image_features(\n                    image_features, \n                    inputs_embeds, \n                    input_ids, \n                    attention_mask, \n                    labels\n                )\n# If we have [\"hey\" \"&lt;image&gt;\", \"how\", \"are\"]\n# we need to index copy on [0, 577, 578, 579] for the text \n# and [1:576] for the image features\n</code></pre> <p>\u4f1a\u53d1\u73b0\u8fd9\u4e2a\u878d\u5408\u5341\u5206\u7b80\u5355\uff0c\u5c31\u662f\u5c06\u8fd9\u4e2a\u56fe\u7247\u7684tokens\u63d2\u5165\u5230\u6587\u672c\u7684tokens\u4e2d\u95f4\u5373\u53ef\u3002</p> <ul> <li>\u7b2c\u4e09\u6b65\uff1a\u8c03\u7528Llama\u6a21\u578b\u5f97\u5230\u8f93\u51fa</li> </ul> <pre><code>outputs = self.language_model(\n            attention_mask=attention_mask,\n            position_ids=position_ids,\n            past_key_values=past_key_values,\n            inputs_embeds=inputs_embeds,\n            use_cache=use_cache,\n            output_attentions=output_attentions,\n            output_hidden_states=output_hidden_states,\n            return_dict=return_dict,\n        )\n# ['logits', 'past_key_values']\n</code></pre> <p>logits \u8868\u793a\u6a21\u578b\u5bf9\u4e8e\u8f93\u5165\u5e8f\u5217\u6bcf\u4e2a\u4f4d\u7f6e\u9884\u6d4b\u4e0b\u4e00\u4e2a token \u7684\u539f\u59cb\u5206\u6570\u3002\u5b83\u7684\u7ef4\u5ea6\u901a\u5e38\u662f <code>(batch_size, sequence_length, vocab_size)</code>\uff0c\u5176\u4e2dsequence_length\u4e3a\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u3002</p> <p>past_key_values \u901a\u5e38\u5305\u542b\u4e86\u6bcf\u4e00\u5c42 Transformer \u4e2d\u7684\u6ce8\u610f\u529b\u673a\u5236\u7684\u952e\uff08key\uff09\u548c\u503c\uff08value\uff09\u77e9\u9635\u3002\u8fd9\u6837\uff0c\u5f53\u6211\u4eec\u751f\u6210\u4e0b\u4e00\u4e2a token \u65f6\uff0c\u6a21\u578b\u53ea\u9700\u8981\u8ba1\u7b97\u65b0 token \u7684\u952e\u548c\u503c\uff0c\u5e76\u4e0e\u524d\u9762\u5b58\u50a8\u7684\u952e\u548c\u503c\u8fdb\u884c\u6ce8\u610f\u529b\u8ba1\u7b97\uff0c\u800c\u4e0d\u9700\u8981\u91cd\u65b0\u8ba1\u7b97\u6574\u4e2a\u5e8f\u5217\u7684\u6ce8\u610f\u529b\u3002<code>(2, batch_size, num_heads, sequence_length, head_dim)</code>\uff0c\u5176\u4e2d\uff1a2: \u7b2c\u4e00\u4e2a\u8868\u793a\u952e\uff08key\uff09\uff0c\u7b2c\u4e8c\u4e2a\u8868\u793a\u503c\uff08value\uff09</p> <p>\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5219\u662f\u4e00\u4e2a\u81ea\u56de\u5f52\uff01\u6240\u4ee5\u4f1a\u8c03\u7528\u4e00\u76f4\u5230\u751f\u6210<code>&lt;eos&gt;</code>\u4e3a\u6b62\u3002</p>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/Llava%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#processor","title":"Processor\u5206\u6790","text":"<p>llava\u4f7f\u7528\u7684processor\u5206\u4e3a\uff1aself.image_processor \u548c self.tokenizer</p> <p>\u524d\u8005\u4e3a\u89c6\u89c9\u5904\u7406\u5668\uff08\u5177\u4f53\u4e3aCLIPImageProcessor\uff09\uff0c\u540e\u8005\u4e3a\u6587\u672c\u5904\u7406\u5668</p> <ul> <li>\u5206\u6790\u89c6\u89c9\u5904\u7406\u5668\u8fdb\u884c\u4e86\u54ea\u4e9b\u64cd\u4f5c</li> </ul> <pre><code># convert_rgb   RGBA-&gt;RGB\n\n# to_numpy_array   PIL.Image.Image  -&gt; numpy.ndarray (height, width, channels) \n ## \u6ce8\u610f\u683c\u5f0f\u662fChannelDimension.LAST\uff08channels_last\uff09\n ## -&gt; (1152, 2048, 3)\n\n# resize         {'shortest_edge': 336}\u4f7f\u6700\u77ed\u8fb9\u4e3a336 -&gt; (336, 597, 3)\n\n# center_crop    {'height': 336, 'width': 336} -&gt; (336, 336, 3)\n\n# rescale        image = image * scale (0-255 -&gt; 0-1)\n\n# normalize      image = (image - image_mean) / image_std\n\n# change_channel (336, 336, 3) -&gt; (3, 336, 336)\n</code></pre> <p>\u6211\u89c9\u5f97\u53ef\u4ee5\u5b66\u4e60\u7684\u70b9\u662f\uff0c\u4e00\u822c\u662f\u5148resize\u5230shortest_edge\uff0c\u7136\u540e\u518dcenter_crop\u3002\u800c\u4e0d\u662f\u76f4\u63a5resize\u5230\u4e00\u4e2a\u6b63\u65b9\u5f62\uff0c\u56e0\u4e3a\u8fd9\u6837\u53ef\u4ee5\u907f\u514d\u592a\u591a\u4fe1\u606f\u4e22\u5931\uff01</p> <p>\u4e4b\u524d\u89c9\u5f97\u6bcf\u6b21\u8f93\u51fa\u67e5\u770b\u56fe\u7247\u90fd\u611f\u89c9\u5947\u602a\uff0c\u539f\u6765llava\u8fd9\u4e2a\u6a21\u578b\u5c31\u6ca1\u8003\u8651\u8f93\u51fa\u56fe\u7247\u7684\uff0c\u6240\u4ee5\u5bf9\u56fe\u7247\u8fdb\u884c\u4e86\u5f88\u591a\u9884\u5904\u7406\uff0c\u8f93\u5165\u7684\u56fe\u7247\u662f\u7ecf\u8fc7\u4e00\u5806\u5904\u7406\u7684\u81ea\u7136\u4e5f\u5c31\u5f88\u5947\u602a\u4e86\u3002</p>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/Llava%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#_2","title":"\u6df1\u5165\u5206\u6790","text":"<p>\u503c\u5f97\u5206\u6790\u7684\u70b9\u662f\uff1a</p> <ul> <li><code>CLIP</code>\u83b7\u53d6\u7684\u89c6\u89c9\u7279\u5f81\uff0c\u53ea\u63d0\u53d6\u5012\u6570\u7b2c\u4e8c\u5c42\u7684\u89c6\u89c9Tokens\uff08\u9664CLS token\uff09</li> <li><code>multi_modal_projector</code> \u5c06\u89c6\u89c9\u7a7a\u95f4\uff08576 * 1024\uff09\u76f4\u63a5\u6620\u5c04\u5230\u6587\u672c\u7a7a\u95f4\uff08576 * 4096\uff09</li> </ul>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/Pytorch/","title":"Pytorch","text":"<p>\u5728\u524d\u9762\u7684Pytorch\u5e93\u7684\u4ecb\u7ecd\u4e2d\uff0c\u6211\u4eec\u4e3b\u8981\u662f\u4e86\u89e3\u8bf6Pytorch\u7684\u6574\u4f53\u77e5\u8bc6\u3002\u5728\u8fd9\u91cc\u6211\u4eec\u5f3a\u8c03\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684Pytorch\u7684\u57fa\u672c\u529f\uff0c\u6bd4\u5982\u5e38\u7528\u51fd\u6570\u3001\u5e38\u89c1\u4ee3\u7801\u3001\u7f51\u7edc\u5c42\u642d\u5efa\u7b49</p>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/Pytorch/#_1","title":"\u5e38\u7528\u51fd\u6570","text":"\u51fd\u6570 \u8bf4\u660e \u793a\u4f8b\u4ee3\u7801 .expand() \u5c06\u5f20\u91cf\u6269\u5c55\u5230\u6307\u5b9a\u7684\u5f62\u72b6\uff0c\u800c\u4e0d\u5b9e\u9645\u590d\u5236\u6570\u636e\u3002\u5b83\u5728\u65b0\u589e\u7684\u7ef4\u5ea6\u4e0a\u6269\u5c55\u539f\u59cb\u5f20\u91cf mask = mask.expand(seq_len, seq_len, batch_size) .view() \u8fd4\u56de\u4e00\u4e2a\u65b0\u7684\u5f20\u91cf\uff0c\u5177\u6709\u76f8\u540c\u7684\u6570\u636e\u4f46\u4e0d\u540c\u7684\u5f62\u72b6 x_viewed = x.view(3, 2) .transpose() \u7528\u4e8e\u4ea4\u6362\u5f20\u91cf\u7684\u4e24\u4e2a\u7ef4\u5ea6 x_transposed = x.transpose(0, 1) .permute() \u7528\u4e8e\u91cd\u65b0\u6392\u5217\u5f20\u91cf\u7684\u6240\u6709\u7ef4\u5ea6 x_permuted = x.permute(1, 2, 0) .einsum() \u7528\u4e8e\u6309\u7231\u56e0\u65af\u5766\u6c42\u548c\u7ea6\u5b9a(\u7b80\u6d01\u5730\u8868\u793a\u590d\u6742\u7684\u5f20\u91cf\u8fd0\u7b97)\u8fdb\u884c\u5f20\u91cf\u8fd0\u7b97\u3002 attention_scores = torch.einsum('ibhd,jbhd-&gt;ijbh', query, key) .register_parameter() \u7528\u4e8e\u6ce8\u518c\u53c2\u6570\uff0c\u4ee5\u4fbf\u5728\u4fdd\u5b58\u6a21\u578b\u65f6\u5c06\u5176\u4fdd\u5b58\u5230\u6a21\u578b\u4e2d model.register_parameter('weight', torch.nn.Parameter(torch.randn(10, 10))) .register_buffer() \u7528\u4e8e\u6ce8\u518c\u7f13\u51b2\u533a\uff0c\u7528\u4e8e\u5b58\u50a8\u4e0d\u9700\u8981\u68af\u5ea6\u7684\u53d8\u91cf model.register_buffer('running_mean', torch.zeros(10)) torch.norm() \u7528\u4e8e\u8ba1\u7b97\u5f20\u91cf\u7684\u8303\u6570(L1\u6216L2) norm = torch.norm(x, p=2) torch.rand() \u548c torch.randn() \u7528\u4e8e\u751f\u62100-1\u7684\u968f\u673a\u5f20\u91cf\u6216\u6b63\u592a\u5206\u5e03\u7684\u5f20\u91cf x = torch.rand(3, 4) isinstance() \u7528\u4e8e\u68c0\u67e5\u5bf9\u8c61\u662f\u5426\u5c5e\u4e8e\u7279\u5b9a\u7c7b\u6216\u7c7b\u578b\u7684\u5185\u7f6e\u51fd\u6570 print(isinstance(model.fc1, nn.Linear)) torch.chunk() \u7528\u4e8e\u5c06\u5f20\u91cf\u5207\u5206\u4e3a\u591a\u4e2a\u5b50\u5f20\u91cf chunks = torch.chunk(x, 3, dim=0) torch.gather() \u7528\u4e8e\u4ece\u5f20\u91cf\u4e2d\u83b7\u53d6\u6307\u5b9a\u7d22\u5f15\u7684\u5143\u7d20 selected_elements = torch.gather(x, dim=0, index=indices) <ul> <li>\u4f7f\u7528Hook\u51fd\u6570\u83b7\u53d6\u68af\u5ea6\u3001\u4fee\u6539\u68af\u5ea6</li> </ul> <pre><code>import torch\nx = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n\ndef print_hook(grad):\n    print(f\"Gradient: {grad}\")\n\nhook_handle = x.register_hook(print_hook)\ny = x * 2\nz = y.sum()\nz.backward()\n\n# \u8f93\u51fa\uff1a\n# Gradient: tensor([2., 2., 2.])\n</code></pre> <ul> <li>\u4ece\u5206\u5e03\u4e2d\u91c7\u6837/\u4e0a\u91c7\u6837\u3001\u4e0b\u91c7\u6837</li> </ul> <pre><code># \u4ece\u5747\u503c\u4e3a mean\uff0c\u65b9\u5dee\u4e3a var \u7684\u9ad8\u65af\u5206\u5e03\u4e2d\u91c7\u6837\nmean + (var ** 0.5) * eps\n\n# \u4e0a\u91c7\u6837\u548c\u4e0b\u91c7\u6837\uff08unet\uff09\nself.conv = nn.ConvTranspose2d(n_channels, n_channels, (4, 4), (2, 2), (1, 1))\nself.conv = nn.Conv2d(n_channels, n_channels, (3, 3), (2, 2), (1, 1))\n</code></pre>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/Pytorch/#_2","title":"\u5e38\u89c1\u7ed3\u6784","text":""},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/Pytorch/#multi-headed-attention","title":"Multi-Headed Attention","text":"<p>Code from : Attention Is All You Need</p> <p>\u4e0b\u9762\u4ecb\u7ecd\u7684\u662f\u4e0a\u4e09\u89d2Mask\u548c\u586b\u5145Mask\uff01</p> <pre><code># \u8f93\u5165\uff1a[seq_len_q, seq_len_k, batch_size]\n# \u8f93\u51fa\uff1a[seq_len_q, seq_len_k, batch_size, heads]\n\ndef prepare_mask(self, mask: torch.Tensor, query_shape: List[int], key_shape:List[int]):\n    assert ...\n    mask = mask.unsqueeze(-1)\n    return mask\n\n# \u4e0a\u4e09\u89d2Mask\ndef generate_upper_triangular_mask(seq_len, batch_size):\n    # \u751f\u6210\u4e00\u4e2a [seq_len, seq_len] \u7684\u4e0a\u4e09\u89d2\u77e9\u9635\n    # diagonal=1 \u786e\u4fdd\u5bf9\u89d2\u7ebf\u4e0a\u7684\u5143\u7d20\u4e3a\u96f6\n    mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)\n    # \u6269\u5c55\u5230 [seq_len, seq_len, batch_size]\n    mask = mask.unsqueeze(-1).expand(seq_len, seq_len, batch_size)\n    return mask\n\n# \u586b\u5145Mask\ndef generate_padding_mask(padded_sequences, pad_token=0):\n\n    seq_len, batch_size = padded_sequences.shape\n    mask = (padded_sequences == pad_token).unsqueeze(0).expand(seq_len, seq_len, batch_size)\n\n    return mask\n</code></pre> <p>\u5728\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u4e2d\uff0c\u6211\u4eec\u5c06\u8f93\u5165\u5206\u6210\u591a\u4e2a\u5934\uff08heads\uff09\uff0c\u6bcf\u4e2a\u5934\u72ec\u7acb\u5730\u6267\u884c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7136\u540e\u5c06\u7ed3\u679c\u62fc\u63a5\u5728\u4e00\u8d77\u3002\u8fd9\u4f7f\u6a21\u578b\u53ef\u4ee5\u5173\u6ce8\u8f93\u5165\u7684\u4e0d\u540c\u90e8\u5206\u6216\u7279\u5f81\u3002\u6574\u4f53\u7684\u4ee3\u7801\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code># \u8f93\u5165\uff1aqkv [seq_len, batch_size, d_model]\n\ndef forward(self, *, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor,  mask: Optional[torch.Tensor] = None):\n\n    seq_len, batch_size, _ = query.shape\n    if mask is not None:\n        mask = self.prepare_mask(mask, query.shape, key.shape)\n\n    # [seq_len, batch_size, heads, d_k]\n    query = self.query(query)\n    key = self.key(key)\n    value = self.value(value)\n\n    scores = self.get_scores(query, key)\n    scores *= self.scale\n    if mask is not None:\n        scores = scores.masked_fill(mask, float('-inf'))\n    attn = self.softmax(scores)\n    tracker.debug('attn', attn)\n    attn = self.dropout(attn)\n    x = torch.einsum(\"ijbh,jbhd-&gt;ibhd\", attn, value) # attn * value\n    self.attn = attn.detach()\n\n    # [seq_len, batch_size, heads * d_k]\n    x = x.reshape(seq_len, batch_size, -1)\n    return self.output(x)\n</code></pre>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/Pytorch/#dropout","title":"Dropout\u5c42","text":"<p>[1] \u5728\u8bad\u7ec3\u671f\u95f4\u968f\u673a\u5c06\u4e00\u90e8\u5206\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u8bbe\u7f6e\u4e3a\u96f6\uff0c\u4ee5\u6b64\u6765\u7834\u574f\u795e\u7ecf\u5143\u4e4b\u95f4\u53ef\u80fd\u51fa\u73b0\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u4ece\u800c\u589e\u5f3a\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002</p> <p>[2] \u4e3a\u4e86\u4fdd\u6301\u8f93\u5165\u7684\u671f\u671b\u503c\u4e0d\u53d8\uff0c\u5269\u4f59\u672a\u7f6e\u96f6\u7684\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u4f1a\u9664\u4ee5 1 - dropout_prob\uff0c\u4ee5\u8fdb\u884c\u5c3a\u5ea6\u8c03\u6574\u3002\u4f8b\u5982\uff0c\u5982\u679c dropout_prob=0.5\uff0c\u90a3\u4e48\u5269\u4e0b\u7684\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u5c06\u4e58\u4ee5 2\u3002</p> <p>[3] \u5728\u6a21\u578b\u8bc4\u4f30\u6216\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff0cDropout \u5c42\u4e0d\u8fdb\u884c\u4efb\u4f55\u64cd\u4f5c\uff0c\u6240\u6709\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u90fd\u4fdd\u6301\u4e0d\u53d8\u3002\u8fd9\u4fdd\u8bc1\u4e86\u5728\u63a8\u7406\u9636\u6bb5\u6a21\u578b\u7684\u8f93\u51fa\u7a33\u5b9a\u4e14\u53ef\u9884\u6d4b\u3002</p> <pre><code>class MyDropout(nn.Module):\n    def __init__(self, p=0.5):\n        super(MyDropout, self).__init__()\n        self.p = p\n\n    def forward(self, x):\n        if self.training:\n            mask = (torch.rand_like(x) &gt; self.p).float()\n            return x * mask / (1 - self.p)\n        else:\n            return x\n</code></pre>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/Pytorch/#bn-affine-momentum","title":"BN\u5c42 (affine + momentum)","text":"<p>\u4f7f\u7528\u52a8\u91cf\u66f4\u65b0\u7684\u65b9\u5f0f\u53ef\u4ee5\u5e73\u6ed1\u5730\u4f30\u8ba1\u6574\u4e2a\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u800c\u4e0d\u4ec5\u4ec5\u4f9d\u8d56\u5355\u4e2a\u6279\u6b21\u7684\u7edf\u8ba1\u4fe1\u606f\u3002\u8fd9\u6837\u53ef\u4ee5\u51cf\u5c11\u7531\u4e8e\u6279\u6b21\u95f4\u5dee\u5f02\u5bfc\u81f4\u7684\u4e0d\u7a33\u5b9a\u6027\u3002</p> <pre><code>class BatchNorm(nn.Moudle):\n    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True):\n        super(BatchNorm, self).__init__()\n        self.num_features = num_features\n        self.eps = eps\n        self.momentum = momentum\n\n        if self.affine:\n            # \u7f29\u653e\u53c2\u6570 &amp; \u504f\u79fb\u53c2\u6570\n            self.gamma = nn.Parameter(torch.ones(num_features))\n            self.beta = nn.Parameter(torch.zeros(num_features))\n        else :\n            self.register_parameter('gamma', None)\n            self.register_parameter('beta', None)\n\n        self.register_buffer('running_mean', torch.zeros(num_features))\n        self.register_buffer('running_var', torch.ones(num_features))\n\n    def forward(self, x):\n        if self.training:\n            mean = x.mean(dim=0)\n            var = x.var(dim=0)\n\n            self.running_mean = self.momentum * self.running_mean + (1 - self.momentum) * mean\n            self.running_var = self.momentum * self.running_var + (1 - self.momentum) * var\n\n            x = (x - mean) / torch.sqrt(var + self.eps)\n        else:\n            x = (x - self.running_mean) / torch.sqrt(self.running_var + self.eps)\n\n        if self.affine:\n            x = x * self.gamma + self.beta\n        return x\n</code></pre>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/Pytorch/#_3","title":"\u77e5\u8bc6\u79ef\u7d2f","text":"<ul> <li>\u968f\u673a\u5f20\u91cf\u751f\u6210</li> </ul> <p><code>torch.rand</code>\uff0c\u751f\u6210\u4e00\u4e2a\u5747\u5300\u5206\u5e03\u7684\u968f\u673a\u6570\u5f20\u91cf\uff0c\u968f\u673a\u6570\u7684\u8303\u56f4\u5728 <code>[0, 1)</code> \u4e4b\u95f4\u3002</p> <p><code>torch.randn</code>\uff0c\u751f\u6210\u4e00\u4e2a\u6b63\u6001\u5206\u5e03\uff08\u6807\u51c6\u6b63\u6001\u5206\u5e03\uff0c\u5747\u503c\u4e3a 0\uff0c\u6807\u51c6\u5dee\u4e3a 1\uff09\u7684\u968f\u673a\u6570\u5f20\u91cf\u3002</p> <ul> <li>NLP\u548cCV\u7ef4\u5ea6\u4fe1\u606f\uff08for transformer\uff09</li> </ul> <ul> <li>\u53c2\u6570\u4f20\u9012\u89c4\u8303\u5316</li> </ul> <pre><code># \u5728Python\u51fd\u6570\u5b9a\u4e49\u4e2d\uff0c\u4f7f\u7528*\u662f\u4e3a\u4e86\u6307\u793a\u4ece\u6b64\u4f4d\u7f6e\u5f00\u59cb\uff0c\n# \u540e\u9762\u7684\u53c2\u6570\u5fc5\u987b\u901a\u8fc7\u5173\u952e\u5b57\u53c2\u6570\uff08keyword arguments\uff09\u6765\u4f20\u9012\uff0c\n# \u800c\u4e0d\u80fd\u901a\u8fc7\u4f4d\u7f6e\u53c2\u6570\uff08positional arguments\uff09\u6765\u4f20\u9012\u3002\ndef forward(self, *, query: torch.Tensor, key: torch.Tensor):\n</code></pre> <ul> <li>\u76ee\u6807\u51fd\u6570\u4e2d\u7684\u6b63\u5219\u5316\u9879\u7684\u8ba1\u7b97</li> </ul> <pre><code># L2 \u6b63\u5219\u5316\u9879\nl2_reg = torch.tensor(0.0)\nfor param in model.parameters():\n    l2_reg += torch.norm(param, 2) ** 2\nloss += lambda_l2 * l2_reg\n\n# L1 \u6b63\u5219\u5316\u9879\nl1_reg = torch.tensor(0.0)\nfor param in model.parameters():\n    l1_reg += torch.norm(param, 1)\nloss += lambda_l1 * l1_reg\n</code></pre>"},{"location":"%E4%BB%A3%E7%A0%81%E7%A0%94%E8%AF%BB%E4%B8%8E%E5%88%86%E6%9E%90/%E8%B0%83%E8%AF%95%E4%BB%A3%E7%A0%81/","title":"\u8c03\u8bd5\u4ee3\u7801","text":"<p>\u4f7f\u7528\u573a\u666f\uff1aVScode\u9700\u8981\u8c03\u8bd5\u4ee3\u7801\u4e2d\u7684\u5e93\uff0c\u4ee5\u5206\u6790\u5176\u8fd0\u884c\u903b\u8f91\u7684\u65f6\u5019 eg. transformers</p> <p>\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cVScode\u662f\u4e0d\u4f1a\u8fdb\u5165\u5e93\u6216\u8005\u5305\u6587\u4ef6\u5185\u90e8\u8fdb\u884c\u8c03\u8bd5\u7684\uff0c\u6240\u4ee5\uff0c\u5982\u679c\u6211\u4eec\u9700\u8981\u5e94\u8be5\u4fee\u6539VScode\u4e2d\u7684debug\u914d\u7f6e\u6587\u4ef6\uff0c\u5373launch.json\u6587\u4ef6\u3002</p> <pre><code>{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Python \u8c03\u8bd5\u7a0b\u5e8f: \u5f53\u524d\u6587\u4ef6\",\n            \"type\": \"debugpy\",\n            \"request\": \"launch\",\n            \"program\": \"${file}\",\n            \"console\": \"integratedTerminal\",\n            \"justMyCode\": false \n            //\u3010\u91cd\u8981\u3011\u9700\u8981\u5c06\u8fd9\u4e2a\u53c2\u6570\u8bbe\u7f6e\u4e3afalse\u624d\u80fd\u6b63\u5e38debug\u8fdb\u5165\u5e93\n        }\n    ]\n}\n</code></pre> <p>\u8c03\u8bd5\u7684\u51e0\u4e2a\u6309\u94ae\u90fd\u5f88\u65b9\u4fbf\uff0c\u9700\u8981\u5b66\u4f1a\u5982\u4f55\u4f7f\u7528\uff1a</p> <ul> <li>\u7ee7\u7eed\uff1a\u8fd0\u884c\u81f3\u4e0b\u4e00\u4e2a\u65ad\u70b9</li> <li>\u9010\u8fc7\u7a0b\uff1a\u9010\u884c\u6267\u884c\uff0c\u4f46\u662f\u4e0d\u4f1a\u8fdb\u5165\u8c03\u7528\u7684\u51fd\u6570\u5185\u90e8</li> <li>\u5355\u6b65\u8c03\u8bd5\uff1a\u6700\u5c0f\u7684\u8c03\u8bd5\u5355\u4f4d\uff0c\u9010\u884c\u6267\u884c\uff0c\u4f46\u662f\u4f1a\u8fdb\u5165\u51fd\u6570\u7684\u5185\u90e8</li> <li>\u5355\u6b65\u8df3\u51fa\uff1a\u8df3\u51fa\u8c03\u7528\uff0c\u6ce8\u610f\u8fd9\u4e0d\u662f\u5012\u9000\uff01\u8c03\u8bd5\u4e0d\u80fd\u5012\u9000\uff01</li> <li>\u91cd\u542f\uff1a\u91cd\u542f\u81f3\u7b2c\u4e00\u4e2a\u65ad\u70b9</li> <li>\u7ed3\u675f\uff1a\u7ed3\u675f\u8c03\u8bd5</li> </ul> <p>\u53e6\u5916\u8c03\u8bd5\u63a7\u5236\u53f0\u771f\u7684\u5f88\u597d\u7528\uff0c\u53ef\u4ee5\u518d\u8c03\u8bd5\u63a7\u5236\u53f0\u8f93\u5165\u5404\u79cdPython\u547d\u4ee4\u4ee5\u67e5\u770b\u5176\u4e2d\u7684\u5404\u4e2a\u5c5e\u6027\u503c\u3002\u867d\u7136\u9f20\u6807\u653e\u5728\u8fd9\u4e2a\u53d8\u91cf\u7684\u4e0a\u9762\u4e5f\u4f1a\u663e\u793a\uff0c\u4f46\u6709\u65f6\u9700\u8981\u4f7f\u7528\u5230tensor.shape\u8fd9\u6837\u7684\u6307\u4ee4\u3002</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/DDIM-DDPM/","title":"DDIM &lt;- DDPM","text":"<p>\u672c\u6765\u60f3\u5077\u61d2\u7684\uff0c\u4f46\u662f\u88ab\u62f7\u6253\u4e86\uff0c\u56e0\u6b64\u91cd\u65b0\u5b66\u4e00\u904d\uff01\u5176\u5b9e\u53d1\u73b0\u4e5f\u6ca1\u90a3\u4e48\u96be\uff01</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/DDIM-DDPM/#_1","title":"\u672c\u8d28","text":"<p>DDIM\u4e0d\u518d\u9075\u5faa\u9a6c\u5c14\u79d1\u592b\u6027\u8d28\uff0c\u4e14\u5c06\u65b9\u5dee\u8bbe\u7f6e\u4e3a0\uff0c\u727a\u7272\u4e86\u90e8\u5206\u6a21\u578b\u7684\u591a\u6837\u6027\uff0c\u63d0\u5347\u4e86\u901f\u5ea6\u548c\u751f\u6210\u8d28\u91cf\uff01</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/DDIM-DDPM/#ddpm","title":"DDPM\u7684\u9a6c\u5c14\u79d1\u592b\u6027\u8d28","text":"<p>\u5f53\u4e00\u4e2a\u968f\u673a\u8fc7\u7a0b\u5728\u7ed9\u5b9a\u73b0\u5728\u72b6\u6001\u53ca\u6240\u6709\u8fc7\u53bb\u72b6\u6001\u60c5\u51b5\u4e0b\uff0c\u5176\u672a\u6765\u72b6\u6001\u7684\u6761\u4ef6\u6982\u7387\u5206\u5e03\u4ec5\u4f9d\u8d56\u4e8e\u5f53\u524d\u72b6\u6001\uff0c\u8fd9\u4e2a\u6027\u8d28\u88ab\u79f0\u4e3a\u9a6c\u5c14\u79d1\u592b\u6027\u8d28\uff0c\u5b9a\u4e49\u5982\u4e0b\uff1a</p> <p>\u5728DDPM\u7684\u524d\u5411\u8fc7\u7a0b\u4e2d\uff0c\u4ecex_0\u5230x_t\u7684\u63a8\u5bfc\u4f9d\u8d56\u4e8e\u9a6c\u5c14\u79d1\u592b\u6027\u8d28\u3002\u8fd9\u91cc\u4e0d\u505a\u8fc7\u591a\u89e3\u91ca\u3002</p> <p>\u5728DDPM\u7684\u53cd\u5411\u8fc7\u7a0b\u4e2d\uff0c\u5176\u9a6c\u5c14\u79d1\u592b\u6027\u8d28\u4f53\u73b0\u5982\u4e0b\uff1a</p> <p>\u5176\u4e2d\u7684q\u600e\u4e48\u6c42\u51fa\u6765\u7684\u5462\uff0c\u5b9e\u9645\u4e0a\u7b80\u5316\u4e86 q(x_t | x_t-1, x_0) \u4e3a q(x_t | x_t-1) \u3010\u7b2c\u4e00\u884c\u3011\uff0c\u56e0\u4e3a\u7531\u9a6c\u5c14\u79d1\u592b\u6027\u8d28\uff0c\u53ef\u4ee5\u77e5\u9053x_t\u53ea\u4e0ex_t-1\u6709\u5173\uff0c\u800c\u4e0ex_0\u65e0\u5173\u3002</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/DDIM-DDPM/#ddim","title":"DDIM\u53bb\u9a6c\u5c14\u79d1\u592b\u6027","text":"<p>\u73b0\u5728\u6211\u4eec\u4e0d\u80fd\u7b80\u5316 q(x_t | x_t-1, x_0) \u4e3a q(x_t | x_t-1)\uff0c\u90a3\u4e48\u4e0a\u9762\u7684\u53cd\u5411\u8fc7\u7a0b\u5982\u4f55\u6c42\u89e3\u5462\uff1f\u5373\u5982\u4f55\u901a\u8fc7\u975e\u9a6c\u513f\u53ef\u592b\u6027\u8d28\u6c42\u89e3 q(x_t-1 | x_t, x_0)\uff1f\u5982\u679c\u53ef\u4ee5\u5b9e\u73b0\u8fd9\u4e2a\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u53ef\u4ee5\u4ece\u4efb\u610fk\u6b65\u5230s\u6b65\u4e86\uff01</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/DDIM-DDPM/#_2","title":"\u65b9\u6cd5\u4e00\uff1a\u5f85\u5b9a\u7cfb\u6570\u6cd5","text":"<p>\u6211\u4eec\u5c06\u4efb\u610f\u7684k\u6b65\u8fd8\u539f\u5230s\u6b65\u5047\u8bbe\u4e3a q(x_s | x_k, x_0) \uff0c\u7136\u540e\u5f85\u5b9a\u7cfb\u6570\u6cd5\u6c42\u89e3\u3002\u5177\u4f53\u5982\u4e0b\uff1a</p> <p>\u4ee4\u84dd\u8272\u7684\u6846\u7b49\u4e8e\u7eff\u8272\u7684\u6846\uff0c\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\uff1a</p> <p>\u5c06\u7cfb\u6570m\u548c\u7cfb\u6570k\u5e26\u5165\u5230\u516c\u5f0f\uff0c\u90a3\u4e48\u5747\u503c\u548c\u65b9\u5dee\u5c31\u5982\u4e0b\u6240\u793a\uff1a</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/DDIM-DDPM/#_3","title":"\u65b9\u6cd5\u4e8c\uff1a\u914d\u51d1\u6cd5","text":"<p>\u5176\u4e2d\u6709\u4e24\u4e2a\u5173\u952e\u6b65\u9aa4\uff0c\u5206\u522b\u662f\u7b2c\u4e8c\u884c\u3010\u566a\u58f0\u5206\u89e3\u3011\u548c\u7b2c\u4e09\u884c\u3010x0\u7684\u4f30\u8ba1\u3011\uff1a</p> <p>\u566a\u58f0\u7684\u5206\u89e3\u57fa\u4e8e\u9ad8\u65af\u5206\u5e03\u7684\u7ebf\u6027\u6027\u8d28\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u65b9\u5dee\u4e00\u81f4\u53c2\u6570\u5c31\u6709\u6240\u4fee\u6539\uff01</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/DDIM-DDPM/#_4","title":"\u5173\u4e8e\u566a\u58f0\u7684\u8ba8\u8bba","text":"<p>\u6700\u521d\u7684DDPM\u7684\u65b9\u5dee\u5982\u4e0b\u6240\u793a\uff1a</p> <p>DDIM\u5728\u524d\u9762\u52a0\u4e86\u4e00\u4e2a\u7cfb\u6570\u8fdb\u884c\u63a2\u7a76\u5b9e\u9a8c\uff1a</p> <p>\u7ed3\u679c\u8868\u660e\uff0c\u65b9\u5dee\u4e3a\u96f6\u65f6\uff0c\u56fe\u7247\u8d28\u91cf\u6700\u597d\uff01</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/DDIM-inversion%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/","title":"DDIM \u91c7\u6837\u4e0e DDIM \u9006\u5411\u4ee3\u7801\u5206\u6790","text":"<p>\u53c2\u8003\u4ee3\u7801\uff1aHF:DDIM Inversion</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/DDIM-inversion%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#_1","title":"\u539f\u7406\u8bb2\u89e3","text":""},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/DDIM-inversion%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#ddim","title":"DDIM\u91c7\u6837(\u53bb\u566a\u8fc7\u7a0b)","text":""},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/DDIM-inversion%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#_2","title":"\u5feb\u901f\u5b9e\u73b0","text":"<pre><code>pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\npipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\nimage = pipe(prompt, negative_prompt=negative_prompt).images[0]\n</code></pre>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/DDIM-inversion%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#_3","title":"\u5177\u4f53\u5b9e\u73b0","text":"<p>\u5176\u5b9e\u4ee3\u7801\u5f88\u6e05\u695a\u4e86\uff0c\u4f46\u662f\u4e3a\u4e86\u4f7f\u903b\u8f91\u66f4\u52a0\u6e05\u6670\uff0c\u6211\u753b\u4e86\u4e00\u4e2a\u601d\u7ef4\u5bfc\u56fe\u5e2e\u52a9\u7406\u89e3\u3002</p> <p>\u6709\u4ee5\u4e0b\u503c\u5f97\u6ce8\u610f\u7684\u4e8b\u60c5\uff1a</p> <ul> <li> <p>set_timesteps\u662f\u53bb\u566a\u8fc7\u7a0b\uff08\u91c7\u6837\u8fc7\u7a0b\uff09t \u7684\u751f\u6210\u65b9\u5f0f\uff0c\u800c\u52a0\u566a\u7684\u65f6\u5019\u5e94\u8be5\u8981\u53cd\u8fc7\u6765\u3002\u8fd9\u91cc\u5728\u540e\u9762DDIM Inversion\u7684\u65f6\u5019\u5e94\u8be5\u8be6\u7ec6\u67e5\u770b\u76f8\u5e94\u4ee3\u7801\u3002</p> </li> <li> <p>\u6587\u5b57\u4fe1\u606f\u662f\u4f5c\u4e3aencoder_hidden_states\u4f20\u5165Unet\u4e2d\u7684\uff0c\u800c\u5b9e\u9645\u4e0a\u5f88\u591a\u4fe1\u606f\u90fd\u53ef\u4ee5\u4ee5\u8fd9\u6837\u7684\u65b9\u5f0f\u4f20\u5165\uff0c\u5305\u62ec\u56fe\u7247\u3001\u7ed3\u6784\u7b49\u4fe1\u606f\u3002</p> </li> <li> <p>\u8fd9\u91cc\u4f7f\u7528\u7684\u662f\u9690\u7a7a\u95f4\u7684\u6269\u6563\u6a21\u578b\uff0c\u4f46\u662f\u566a\u58f0\u662f\u76f4\u63a5\u751f\u6210\u9690\u7a7a\u95f4\u7684\u566a\u58f0\uff01</p> </li> </ul> <pre><code># Sample function (regular DDIM)\n@torch.no_grad()\ndef sample(\n    prompt,\n    start_step=0,\n    start_latents=None,\n    guidance_scale=3.5,\n    num_inference_steps=30,\n    num_images_per_prompt=1,\n    do_classifier_free_guidance=True,\n    negative_prompt=\"\",\n    device=device,\n):\n\n    # Encode prompt\n    text_embeddings = pipe._encode_prompt(\n        prompt, device, num_images_per_prompt, do_classifier_free_guidance, negative_prompt\n    )\n\n    # create timesteps\n    pipe.scheduler.set_timesteps(num_inference_steps, device=device)\n\n    # Create start latents\n    if start_latents is None:\n        start_latents = torch.randn(1, 4, 64, 64, device=device)\n        start_latents *= pipe.scheduler.init_noise_sigma\n    latents = start_latents.clone()\n\n    for i in tqdm(range(start_step, num_inference_steps)):\n\n        t = pipe.scheduler.timesteps[i]\n\n        # Expand the latents if we are doing classifier free guidance\n        latent_model_input = torch.cat([latents] * 2) if do_classifier_free_guidance else latents\n        latent_model_input = pipe.scheduler.scale_model_input(latent_model_input, t)\n\n        # Predict the noise\n        noise_pred = pipe.unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n\n        # Perform guidance\n        if do_classifier_free_guidance:\n            noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n            noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n\n        # latents = pipe.scheduler.step(noise_pred, t, latents).prev_sample\n        prev_t = max(1, t.item() - (1000 // num_inference_steps))  # t-1\n        alpha_t = pipe.scheduler.alphas_cumprod[t.item()]\n        alpha_t_prev = pipe.scheduler.alphas_cumprod[prev_t]\n        predicted_x0 = (latents - (1 - alpha_t).sqrt() * noise_pred) / alpha_t.sqrt()\n        direction_pointing_to_xt = (1 - alpha_t_prev).sqrt() * noise_pred\n        latents = alpha_t_prev.sqrt() * predicted_x0 + direction_pointing_to_xt\n\n    # decode latents\n    images = pipe.decode_latents(latents)\n    images = pipe.numpy_to_pil(images)\n\n    return images\n</code></pre> <p>\u8c03\u7528\u5c31\u5341\u5206\u7b80\u5355\u4e86\uff0c\u7ed9\u51fa\u4ee3\u7801\u4e0d\u505a\u5206\u6790\uff1a</p> <pre><code>image = sample(\"Watercolor painting of a beach sunset\", \n                negative_prompt=negative_prompt,\n                num_inference_steps=50)[0]\n</code></pre>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/DDIM-inversion%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#ddim-inversion","title":"DDIM Inversion","text":"<ul> <li>\u5904\u7406\u56fe\u7247\u5f97\u5230\u8d77\u59cb\u7684latents( Encode the image )</li> </ul> <pre><code># torchvision.transforms.functional.to_tensor(img) \u5c06\u503c\u8f6c\u5316\u52300~1\u4e4b\u95f4\n# unsqueeze(0) \u5347\u7ef4\u5ea6\u5f97\u5230Batchsize\u8fd9\u4e2a\u7ef4\u5ea6\n# * 2 - 1 \u5c06\u503c\u8f6c\u5316\u5230-1~1\u4e4b\u95f4\nwith torch.no_grad():\n    latent = pipe.vae.encode(tfms.functional.to_tensor(input_image).unsqueeze(0).to(device) * 2 - 1)\n\n# latent.latent_dist.sample() \u5f97\u5230latents\uff0c.latent_dist \u662f\u6f5c\u5728\u5206\u5e03 \n# \u8fd9\u662f\u56e0\u4e3aVAE_encoder\u7684\u8f93\u51fa\u662fDistribution\uff08\u53ea\u6709\u5747\u503c\u548c\u65b9\u5dee\uff09\uff0c\u6240\u4ee5\u9700\u8981sample()\n# 0.18215 \u662f\u4e00\u4e2a\u7f29\u653e\u56e0\u5b50\uff0c\u662fVAE\u56fa\u5b9a\u7684\u4e0d\u7528\u7ba1\nl = 0.18215 * latent.latent_dist.sample()\n</code></pre> <ul> <li>Inversion</li> </ul> <p>\u6ce8\u610f\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u5217\u8868\uff0c\u800c\u4e0d\u662f\u4e00\u4e2alatent\u3002</p> <pre><code>## Inversion\n@torch.no_grad()\ndef invert(\n    start_latents,\n    prompt,\n    guidance_scale=3.5,\n    num_inference_steps=80,\n    num_images_per_prompt=1,\n    do_classifier_free_guidance=True,\n    negative_prompt=\"\",\n    device=device,\n):\n    # Encode prompt\n    text_embeddings = pipe._encode_prompt(\n        prompt, device, num_images_per_prompt, do_classifier_free_guidance, negative_prompt\n    )\n\n    # get latents\n    latents = start_latents.clone()\n\n    # keep a list of the inverted latents\n    intermediate_latents = []\n\n    # set_timesteps\n    pipe.scheduler.set_timesteps(num_inference_steps, device=device)\n    timesteps = reversed(pipe.scheduler.timesteps)\n\n    for i in tqdm(range(1, num_inference_steps), total=num_inference_steps - 1):\n\n        #  skip the final iteration\n        if i &gt;= num_inference_steps - 1:\n            continue\n\n        t = timesteps[i]\n\n        # Expand the latents if we are doing classifier free guidance\n        latent_model_input = torch.cat([latents] * 2) if do_classifier_free_guidance else latents\n        latent_model_input = pipe.scheduler.scale_model_input(latent_model_input, t)\n\n        # Predict the noise residual\n        noise_pred = pipe.unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n\n        # Perform guidance\n        if do_classifier_free_guidance:\n            noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n            noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n\n        current_t = max(0, t.item() - (1000 // num_inference_steps))  # t - 1\n        next_t = t  # min(999, t.item() + (1000//num_inference_steps)) # t \n        alpha_t = pipe.scheduler.alphas_cumprod[current_t]\n        alpha_t_next = pipe.scheduler.alphas_cumprod[next_t]\n\n        # Inverted update step\uff1a x(t) &lt;- x(t-1) \n        latents = (latents - (1 - alpha_t).sqrt() * noise_pred) \n            * (alpha_t_next.sqrt() / alpha_t.sqrt()) \n            + (1 - alpha_t_next).sqrt() * noise_pred\n\n        intermediate_latents.append(latents)\n\n    return torch.cat(intermediate_latents)\n\n# Decode the final inverted latents\nwith torch.no_grad():\n    im = pipe.decode_latents(inverted_latents[-1].unsqueeze(0))\npipe.numpy_to_pil(im)[0]\n</code></pre>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/Diffusion%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/","title":"\u751f\u6210\u6a21\u578b\u5e95\u5c42\u539f\u7406","text":"<p>\u5728\u770b\u4e86\u65e0\u6570\u6587\u7ae0\u4e4b\u540e\u7684\u5927\u5f7b\u5927\u609f\uff0c\u6545\u6309\u7167\u81ea\u5df1\u7684\u7406\u89e3\u603b\u7ed3\u4e86\u4e00\u4e0b\u751f\u6210\u6a21\u578b\u7684\u5e95\u5c42\u539f\u7406\u3002</p> <p>\u5305\u62ec\uff1aVAE\u3001Diffusion\u3001GAN\u3001FLOW\u3001\u6240\u6709\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/Diffusion%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/#_2","title":"\u751f\u6210\u6a21\u578b\u7684\u8bad\u7ec3\u76ee\u6807\u662f\u4ec0\u4e48\uff1f","text":"<p>\u5728\u56fe\u50cf\u9886\u57df\uff0c\u4e00\u4e2a\u597d\u7684\u751f\u6210\u6a21\u578b\u5e94\u8be5\u5c3d\u53ef\u80fd\u5730\u751f\u6210\u4e0e\u7ed9\u5b9a\u56fe\u50cf\uff08\u5927\u90e8\u5206\u60c5\u51b5\u4e0b\u662f\u771f\u5b9e\u56fe\u50cf\uff09\u76f8\u4f3c\u7684\u56fe\u50cf\u3002\u6240\u4ee5\uff0c\u751f\u6210\u6a21\u578b\u6700\u5e95\u5c42\u7684\u8bad\u7ec3\u76ee\u6807\u662f\uff1a\u8ba9\u751f\u6210\u56fe\u50cf\u7684\u5206\u5e03\u548c\u7ed9\u5b9a\u56fe\u50cf\u7684\u5206\u5e03\u5c3d\u53ef\u80fd\u76f8\u4f3c\u3002</p> <p>\u751f\u6210\u7684\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a\u4ece\u4e00\u4e2a\u5206\u5e03\u4e2d\u91c7\u6837\u7684\u8fc7\u7a0b\u3002</p> <p>\u4f46\u662f\uff0c\u6211\u4eec\u65e0\u6cd5\u5f97\u77e5\uff0c\u4e5f\u65e0\u6cd5\u76f4\u63a5\u8ba1\u7b97\u7ed9\u5b9a\u56fe\u50cf\u7684\u5206\u5e03\u3002\u4e3a\u4ec0\u4e48\u5462\uff1f\u56e0\u4e3a\u5982\u679c\u80fd\u591f\u5f97\u5230\u7ed9\u56fe\u56fe\u50cf\u7684\u5206\u5e03\uff0c\u90a3\u968f\u673a\u91c7\u6837\u4e0d\u5c31\u53ef\u4ee5\u76f4\u63a5\u751f\u6210\u56fe\u50cf\u4e86\uff0c\u90a3\u8fd8\u8981\u505a\u4ec0\u4e48\u5de5\u4f5c\u5462\u3002\u4e8b\u5b9e\u4e0a\uff0c\u6211\u4eec\u8fd9\u4e24\u4e2a\u5206\u5e03\u4e00\u4e2a\u90fd\u6c42\u4e0d\u51fa\u6765\u3002</p> <p>\u6240\u4ee5\uff0c\u9700\u8981\u8fd0\u7528\u4e00\u4e9b\u65b9\u6cd5\u6765\u7b49\u4ef7\u8fd9\u4e2a\u8bad\u7ec3\u76ee\u6807\uff1a</p> <ul> <li>\u65b9\u6cd5\u4e00\uff1a\u6700\u5927\u5316\u4f3c\u7136\uff0c\u53ef\u4ee5\u8bc1\u660e\u6700\u5927\u5316\u4f3c\u7136\u5c31\u662f\u5728\u6700\u5c0f\u5316\u4e24\u4e2a\u5206\u5e03\u7684KL\u6563\u5ea6\u3002</li> </ul> <p>\u76f8\u5173\u5de5\u4f5c\u6709\uff1aVAE\u3001Diffusion\u3001FLOW \u4ee5\u53ca\u5b83\u4eec\u7684\u53d8\u4f53</p> <ul> <li>\u65b9\u6cd5\u4e8c\uff1a\u751f\u6210\u5bf9\u6297\u8bad\u7ec3\uff0c\u53ef\u4ee5\u8bc1\u660e\u751f\u6210\u5bf9\u6297\u8bad\u7ec3\u5c31\u662f\u5728\u6700\u5c0f\u5316\u4e24\u4e2a\u5206\u5e03\u7684JS\u6563\u5ea6\u3002</li> </ul> <p>\u76f8\u5173\u5de5\u4f5c\u6709\uff1aGAN \u4ee5\u53ca\u5b83\u7684\u53d8\u4f53</p> <p>\u62d3\u5c55\u5230\u6587\u5b57\u9886\u57df\uff0c\u8bed\u8a00\u751f\u6210\u6a21\u578b\u5176\u76ee\u6807\u4e5f\u662f\uff1a\u8ba9\u751f\u6210\u6587\u5b57\u7684\u5206\u5e03\u548c\u7ed9\u5b9a\u6587\u5b57\u7684\u5206\u5e03\u5c3d\u53ef\u80fd\u76f8\u4f3c\u3002\u4e0d\u8fc7\uff0c\u6587\u5b57\u7684\u5206\u5e03\u662f\u79bb\u6563\u7684\u3002\u79bb\u6563\u7684\u5206\u5e03\u4e4b\u95f4\u7684\u76f8\u4f3c\u7a0b\u5ea6\u6709\u4e00\u4e2a\u5f88\u597d\u8861\u91cf\u65b9\u6cd5\uff0c\u90a3\u5c31\u662f\u4ea4\u53c9\u71b5\u635f\u5931\u3002\u8fd9\u5c31\u53ef\u4ee5\u89e3\u91ca\u51e0\u4e4e\u6240\u6709\u8bed\u8a00\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\u90fd\u662f\u4ea4\u53c9\u71b5\u635f\u5931\u7684\u539f\u56e0\u3002</p> <p>\u62d3\u5c55\u5230\u97f3\u9891\u9886\u57df\uff0c\u97f3\u9891\u5206\u5e03\u548c\u56fe\u50cf\u5206\u5e03\u4e00\u6837\u4e5f\u662f\u8fde\u7eed\u7684\uff0c\u56e0\u6b64\u53ef\u4ee5\u628a\u56fe\u50cf\u9886\u57df\u7684\u6a21\u578b\u642c\u5230\u97f3\u9891\u9886\u57df\u6765\uff0c\u8fd9\u5c31\u662f\u5f88\u591a\u97f3\u9891\u751f\u6210\u6a21\u578b\u548c\u56fe\u50cf\u751f\u6210\u6a21\u578b\u539f\u7406\u4e00\u81f4\u7684\u672c\u8d28\u539f\u56e0\u3002</p> <p>\u5bf9\u4e8e\u6240\u6709\u6a21\u6001\u7684\u751f\u6210\u4efb\u52a1\uff0c\u672c\u8d28\u90fd\u662f\u4e00\u6837\u7684\uff0c\u4e00\u5207\u751f\u6210\u90fd\u53ef\u8ba4\u4e3a\u662f\u5206\u5e03\u91c7\u6837\u7684\u95ee\u9898\u3002\u5305\u62ec\uff1a\u5b57\u4f53\u751f\u6210\u3001\u6392\u7248\u751f\u6210\u30013D\u751f\u6210\u3001\u89c6\u9891\u751f\u6210\u3001\u751f\u7269\u5206\u5b50\u751f\u6210\u7b49\u7b49\u3002</p> <p>\u611f\u53f9\u4e00\u53e5\uff0c\u6570\u5b66\u662f\u7406\u79d1\u4e4b\u57fa\u4e0d\u662f\u5439\u7684...</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/Diffusion%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/#_3","title":"\u975e\u5e38\u91cd\u8981\u7684\u7ed3\u8bba\uff01","text":""},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/Diffusion%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/#_4","title":"\u751f\u6210\u6a21\u578b\u7684\u6838\u5fc3\u539f\u7406","text":"<p>\u603b\u7ed3\u4e00\u4e0b\u4e94\u5927\u7c7b\u751f\u6210\u6a21\u578b\uff1aVAE Diffusion FLOW GAN \u8bed\u8a00\u6a21\u578b</p> <p>\u4e0b\u9762\u662f\u6211\u5455\u5fc3\u6ca5\u8840\u5f97\u5230\u7684\u7ed3\u8bba\uff0c\u5df2\u6b7b...</p> \u7c7b\u578b \u6838\u5fc3\u539f\u7406 \u6c42\u89e3\u601d\u8def \u5177\u4f53\u6c42\u89e3\u65b9\u6cd5 VAE \u6700\u5927\u5316\u4f3c\u7136/\u6700\u5c0f\u5316KL\u6563\u5ea6 \u6c42\u89e3\u6700\u5927\u5316\u4f3c\u7136\u7684\u4e00\u79cd\u4e0b\u754c A - B \u8bbe\u8ba1\u4e86VAE\u6a21\u578b\uff0c\u6a21\u578b\u751f\u6210\u5206\u5e03\u548c\u771f\u5b9e\u5206\u5e03\u7684\u903c\u8fd1\u7a0b\u5ea6\u4e3a A\uff0c\u6a21\u578b\u7684\u9690\u53d8\u91cf\u7684\u5206\u5e03\u548c\u6807\u51c6\u6b63\u592a\u5206\u5e03\u7684\u903c\u8fd1\u7a0b\u5ea6\u4e3a B\uff0c\u6a21\u578b\u7684\u8bad\u7ec3\u76ee\u6807\u4e3amax A  min B\u3002 Diffusion \u6700\u5927\u5316\u4f3c\u7136/\u6700\u5c0f\u5316KL\u6563\u5ea6 \u6c42\u89e3\u6700\u5927\u5316\u4f3c\u7136\u7684\u53e6\u4e00\u79cd\u4e0b\u754c C - D + E \u8bbe\u8ba1\u4e86Diffusion\u6a21\u578b\uff0cD\u662f\u5e38\u91cf\u4e0d\u7528\u7ba1\uff0cC\u548cE\u7c7b\u4f3c\uff0cE\u8868\u793a\u4e3a\u524d\u5411\u8fc7\u7a0b\u7684\u5206\u5e03\u548c\u9006\u5411\u8fc7\u7a0b\u7684\u5206\u5e03\u7684KL\u6563\u5ea6\uff0c\u800c\u524d\u5411\u8fc7\u7a0b\u7684\u5206\u5e03\u7684\u65b9\u5dee\u548c\u5747\u503c\u786e\u5b9a\uff0c\u6545\u6a21\u578b\u8bad\u7ec3\u76ee\u6807\u4f7f\u9006\u5411\u8fc7\u7a0b\u63a5\u8fd1\u524d\u5411\u8fc7\u7a0b\u7684\u5206\u5e03\u5373\u53ef\uff08\u5747\u503c \u65b9\u5dee\uff09 FLOW \u6700\u5927\u5316\u4f3c\u7136/\u6700\u5c0f\u5316KL\u6563\u5ea6 \u6c42\u89e3\u6700\u5927\u5316\u4f3c\u7136\u7684\u7b49\u4ef7\u5f62\u5f0f X X\u9700\u8981\u6a21\u578b\u591a\u6b65\u53ef\u9006\uff0c\u5426\u5219\u4e0d\u7b49\u4ef7\uff0c\u6240\u4ee5FLOW\u7c7b\u65b9\u6cd5\u90fd\u662f\u8bbe\u8ba1\u4e00\u4e2a\u5de7\u5999\u7684\u53ef\u9006\u7684\u6a21\u578b GAN \u751f\u6210\u5bf9\u6297\u8bad\u7ec3/\u6700\u5c0f\u5316JS\u6563\u5ea6 \u6700\u5c0f\u5316\u8bbe\u8ba1\u7684LOSS A + B \uff0c\u800c\u8fd9\u4e2aLOSS\u7b49\u4ef7\u4e8e-2log2 + 2JS - A - B \u5c31\u662f0-1\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u5224\u522b\u5668\u76ee\u6807\u662f\u6700\u5c0f\u5316\u8fd9\u4e2a\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u751f\u6210\u5668\u76ee\u6807\u662f\u6700\u5927\u5316\u8fd9\u4e2a\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff08\u5373\u6700\u5c0f\u5316LOSS A + B\uff09\u3002 \u8bed\u8a00\u6a21\u578b \u6700\u5c0f\u5316\u4ea4\u53c9\u71b5 \u76f4\u63a5\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 \u539f\u7406\u4e0a\u4efb\u4f55\u6a21\u578b\u90fd\u53ef\u4ee5\u6210\u4e3a\u8bed\u8a00\u6a21\u578b\uff0c\u53ea\u662f\u6548\u679c\u597d\u4e0d\u597d\u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u53ef\u4ee5\u76f4\u63a5\u7b97\uff0c\u4e5f\u4e0d\u7528\u7cbe\u5de7\u7684\u8bbe\u8ba1\u3002 \u6a21\u578b\u7684\u597d\u574f\u4f1a\u5f71\u54cd\u4ea4\u53c9\u71b5\u7684\u6700\u5c0f\u503c\u3002\u6a21\u578b\u8d8a\u597d\u4ea4\u53c9\u71b5\u8d8a\u5c0f\u3002 <p>\u4e3a\u4ec0\u4e48\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u7b80\u5355\u5730\u76f4\u63a5\u7528\u4ea4\u53c9\u71b5\u635f\u5931\uff1f \u8bed\u8a00\u662f\u79bb\u6563\u5206\u5e03\uff0c\u800c\u56fe\u50cf\u3001\u97f3\u9891\u662f\u8fde\u7eed\u5206\u5e03\u3002</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/Diffusion%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/#_5","title":"\u4e3a\u4ec0\u4e48\u6240\u6709\u6a21\u6001\u53ef\u901a\u7528\uff1f","text":"<p>\u56fe\u50cf\u3001\u97f3\u9891\u867d\u7136\u662f\u8fde\u7eed\u5206\u5e03\uff0c\u4f46\u662f\u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u53d8\u4e3a\u79bb\u6563\u5206\u5e03\uff0c\u65b9\u6cd5\u633a\u591a\u7684\uff0c\u4e0d\u540c\u6a21\u578b\u7528\u7684\u4e0d\u540c\uff0c\u53ef\u4ee5\u8003\u8651\u5355\u5f00\u4e00\u8282\u3002\u7b80\u5355\u5c31\u76f4\u63a5\u53d6\u50cf\u7d20\u7684\u6574\u6570\u503c\u5373\u53ef\u3002</p> <p>\u6587\u5b57\u867d\u7136\u662f\u79bb\u6563\u5206\u5e03\uff0c\u4f46\u662fembedding\u53ef\u4ee5\u5c06\u5176\u53d8\u4e3a\u8fde\u7eed\u5206\u5e03\uff0c\u5957\u4e00\u4e2a\u8fde\u7eed\u5206\u5e03\u7684\u751f\u6210\u6a21\u578b\uff0c\u6700\u540e\u518d\u8fd1\u4f3c\u8f6c\u56de\u5230\u79bb\u6563\u5206\u5e03\u5c31OK\u4e86\u3002\u6bd4\u5982 diffsion\u53ef\u4ee5\u7528\u4e8e\u6587\u5b57\u751f\u6210\u3001item\u63a8\u8350\u3002</p> <p>\u56fe\u4ec5\u4e3a\u4e2a\u4eba\u7406\u89e3\u3002</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/Diffusion%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/#kl","title":"\u6700\u5927\u5316\u4f3c\u7136=\u6700\u5c0f\u5316KL\u6563\u5ea6\uff1f","text":"<p>\u2193 \u8fd9\u6bb5\u8bdd\u60f3\u4e86\u5f88\u4e45\uff0c\u8868\u8ff0\u662f\u7cbe\u51c6\u7684\uff0c\u53ea\u662f\u4e0d\u592a\u597d\u7406\u89e3\u3002</p> <p>\u5047\u8bbe\u5bf9\u4e8e\u4efb\u610f\u4e00\u5f20\u7ed9\u5b9a\u7684\u56fe\uff0c\u6211\u4eec\u90fd\u80fd\u591f\u8ba1\u7b97\u6a21\u578b(\u03b8)\u4ea7\u751f\u5b83\u7684\u6982\u7387\u3002\u90a3\u4e48\u4ece\u6570\u5b66\u4e0a\uff0c\u6211\u4eec\u53ef\u4ee5\u8bc1\u660e\uff1a\u6c42\u89e3\u03b8\u4f7f\u201c\u6a21\u578b\u4ea7\u751f\u4e00\u7ec4\u7ed9\u5b9a\u7684\u56fe\uff08\u771f\u5b9e\u7684\u56fe\uff09\u7684\u6982\u7387\u7684\u79ef\u201d\u6700\u5927\u7684\u8fc7\u7a0b\uff0c\u7b49\u540c\u4e8e\u4f7f\u201c\u6a21\u578b\u4ea7\u751f\u56fe\u7684\u5206\u5e03\uff08P\u03b8()\uff09\u63a5\u8fd1\u4e8e\u771f\u5b9e\u56fe\u50cf\u5206\u5e03\uff08Preal()\uff09\u201d\u7684\u8fc7\u7a0b\u3002\u8fd9\u5c31\u610f\u5473\u7740\uff0c\u6211\u4eec\u5982\u679c\u60f3\u8981\u4ea7\u751f\u4efb\u610f\u771f\u5b9e\u7684\u56fe\uff0c\u53ea\u9700\u8981\u4f7f\u6a21\u578b\u4ea7\u751f\u4e00\u7ec4\u7ed9\u5b9a\u7684\u56fe\uff08\u771f\u5b9e\u7684\u56fe\uff09\u7684\u6982\u7387\u7684\u79ef\u6700\u5927\uff0c\u8bc1\u660e\u8fc7\u7a0b\u5982\u4e0b\u6240\u793a\uff1a</p> <p>\u8fd9\u5c31\u89e3\u91ca\u4e86\uff1a\u4e3a\u4ec0\u4e48\u5728\u5f88\u591a\u751f\u6210\u6a21\u578b\u4e2d\uff0c\u6211\u4eec\u8981\u6700\u5927\u5316\u4f3c\u7136\u3002</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/Diffusion%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/#_6","title":"\u5982\u4f55\u8ba1\u7b97\u6700\u5927\u5316\u4f3c\u7136\uff1f","text":"<p>\u76f4\u89c2\u4e0a\uff0c\u6700\u5927\u5316\u5bf9\u6570\u4f3c\u7136\u7684\u4e0b\u754c\uff0c\u53ef\u4ee5\u6700\u5927\u5316\u5bf9\u6570\u4f3c\u7136\u3002\u4f46\u662f\u6211\u4eec\u65e0\u6cd5\u5f97\u5230\u7cbe\u786e\u4e0b\u754c\uff0c\u800c\u6cdb\u4e0b\u754c\u5176\u5b9e\u6709\u5f88\u591a\u79cd\uff0c\u6240\u4ee5\u4e0d\u540c\u7684\u6a21\u578b\u4f1a\u7ed9\u51fa\u4e0d\u540c\u7684\u4e0b\u754c\uff0c\u6bd4\u5982VAE\u548cDiffusion\u3002\u4ed6\u4eec\u6a21\u578b\u7684\u8bbe\u8ba1\u548c\u635f\u5931\u51fd\u6570\u7684\u8bbe\u8ba1\u90fd\u662f\u4e3a\u4e86\u6700\u5927\u5316\u8fd9\u4e2a\u4e0b\u754c\u3002</p> <p>FLOW\u4e0d\u592a\u4e00\u6837\uff0cFLOW\u627e\u5230\u4e86\u4f3c\u7136\u7684\u7b49\u4ef7\u516c\u5f0f\uff0c\u800c\u4e0d\u662f\u5176\u4e0b\u754c\uff0c\u5176\u8bad\u7ec3\u76ee\u6807\u76f4\u63a5\u662f\u6700\u5927\u5316\u4f3c\u7136\u7684\u7b49\u4ef7\u5f62\u5f0f\uff08\u6bd4\u8f83\u9876\uff09\u3002\u7136\u800c\u8fd9\u5f88\u96be\u8bbe\u8ba1\u6a21\u578b\uff0c\u56e0\u6b64\u6548\u679c\u4e0d\u662f\u5f88\u597d\u3002</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/Diffusion%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/#vae","title":"VAE \u7684\u6700\u5927\u5316\u4e0b\u754c","text":"<p>\u6211\u4eec\u53ef\u4ee5\u8bc1\u660e\u7ed9\u5b9a\u4efb\u610f\u4e00\u4e2a\u5206\u5e03q\uff08z|x\uff09\uff0c\u90fd\u53ef\u4ee5\u6c42\u51fa\u5bf9\u6570\u4f3c\u7136\u5173\u4e8e\u8be5\u5206\u5e03\u7684\u4e0b\u754c\uff0c\u8bc1\u660e\u5982\u4e0b\uff1a</p> <p>\u5c06\uff081\uff09\u548c\uff086\uff09\u8054\u7acb\uff0c\u53d8\u5f62\u4e00\u4e0b\u5c31\u6709\uff1a</p> <p>\u800c\u8fd9\u4e2a\u4e1c\u897f\u5c31\u662fVAE\u63a8\u5bfc\u51fa\u6765\u7684\u6700\u5927\u5316\u4f3c\u7136\u7684\u4e0b\u754c\u3002</p> <p>\u90a3\u8fd9\u4e2a\u548cVAE\u6a21\u578b\u7684\u8bad\u7ec3\u76ee\u6807\u6709\u4ec0\u4e48\u5173\u7cfb\u5462\uff1f\u89e3\u91ca\u5982\u4e0b\uff1a</p> <p>\u6240\u4ee5\u8bf4\uff0c\u524d\u534a\u90e8\u5206\u5c31\u662f\u8f93\u5165\u548c\u8f93\u51fa\u7684\u5dee\u5f02\uff0c\u8fd9\u4e5f\u662f\u6a21\u578b\u7684\u7b2c\u4e00\u4e2a\u635f\u5931\u51fd\u6570MSE\uff1b\u540e\u534a\u90e8\u5206\uff0c\u6211\u4eec\u5047\u8bbe\u4e86\u540e\u5ef6\u6982\u7387\u662f\u6b63\u592a\u5206\u5e03\uff0c\u5148\u9a8c\u6982\u7387\u662f\u6807\u51c6\u6b63\u592a\u5206\u5e03\uff0c\u4e24\u8005\u7684\u5dee\u5f02\u5c31\u662f\u7b2c\u4e8c\u4e2a\u635f\u5931\u51fd\u6570\u5982\u4e0b\u6240\u793a\uff1a</p> <p>\u81f3\u6b64\uff0c\u6211\u4eec\u5c31\u80fd\u89e3\u91ca\uff0c\u4e3a\u4ec0\u4e48VAE\u8981\u8fd9\u6837\u8bbe\u8ba1\u8bad\u7ec3\u76ee\u6807\uff08\u635f\u5931\u51fd\u6570\uff09\u5566\uff01</p> <p>\u6240\u4ee5VAE\u4e0d\u540c\u4e8eAutoencoders\uff01\uff01\uff01Autoencoders\u662f\u4e00\u4e2a\u786e\u5b9a\u6027\u6a21\u578b\uff0c\u4e3b\u8981\u7684\u4f5c\u7528\u7684\u5b66\u4e60\u4e00\u4e2a\u6570\u636e\u7684\u9690\u6027\u8868\u8fbe\uff0c\u56e0\u6b64\u53ef\u4ee5\u7528\u6765\u538b\u7f29\u6570\u636e\u3002\u800cVAE\u662f\u4e00\u4e2a\u6982\u7387\u6a21\u578b\uff0c\u5b83\u628a\u6df1\u5ea6\u6a21\u578b\u548c\u6982\u7387\u65b9\u6cd5\u7ed3\u5408\u4e86\u8d77\u6765\uff0c\u4e5f\u56e0\u6b64\u53d6\u540dVariational Autoencoder\u3002\u5b83\u7684\u4e3b\u8981\u4f5c\u7528\u662f\u751f\u6210\u65b0\u7684\u76f8\u4f3c\u7684\u6570\u636e\u800c\u975e\u5b66\u4e60\u4e00\u4e2a\u4f4e\u7ef4\u7684\u9690\u6027\u8868\u8fbe\uff08\u538b\u7f29\uff09\u3002</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/Diffusion%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/#ddpm","title":"DDPM \u7684\u6700\u5927\u5316\u4e0b\u754c","text":"<p>\u8fd9\u4e2a\u4e0b\u754c\u5206\u4e3a\u4e09\u4e2a\u90e8\u5206\uff1a\u7b2c\u4e00\u4e2a\u90e8\u5206\u548c\u7b2c\u4e09\u4e2a\u90e8\u5206\u5904\u7406\u76f8\u4f3c\uff0c\u7b2c\u4e8c\u90e8\u5206\u662f\u4e2a\u5b9a\u503c\uff0c\u6240\u4ee5\u6211\u4eec\u53ea\u4ecb\u7ecd\u7b2c\u4e09\u90e8\u5206\u7684\u5982\u4f55\u6c42\u89e3\u3002 \u4e0b\u754c\u7684\u4e09\u4e2a\u90e8\u5206\u653e\u5927\u6765\u770b\uff0c\u5982\u4e0b\u6240\u793a\uff1a</p> <p>\u5176\u4e2d\u84dd\u8272\u90e8\u5206\u662ft-1\u65f6\u523b\u7684\u5206\u5e03\uff0c\u5728\u6570\u5b66\u4e0a\uff0c\u53ef\u4ee5\u6c42\u51fa\u8be5\u5206\u5e03\u5c31\u662f\u6b63\u6001\u5206\u5e03\uff0c\u4e14\u80fd\u5f97\u5230\u5176\u5747\u503c\u548c\u65b9\u5dee\uff1a</p> <p>\u90a3\u4e48\uff0c\u5230\u76ee\u524d\u4e3a\u6b62\uff0c\u6700\u5927\u5316\u4e0b\u754c\u5c31\u662f\u6700\u5c0f\u5316\u84dd\u8272\u90e8\u5206\u548c\u5176\u540e\u9762\u90e8\u5206\u7684KL\u6563\u5ea6\u3002\u5373\uff0c\u8ba9\u8fd9\u4e24\u4e2a\u6b63\u592a\u5206\u5e03\u8d8a\u63a5\u8fd1\u8d8a\u597d\u3002\u600e\u4e48\u8ba9\u4e24\u4e2a\u6b63\u592a\u5206\u5e03\u8d8a\u63a5\u8fd1\u8d8a\u597d\u5462\uff1f</p> <p>\u7531\u4e8e\u5176\u4e2d\u4e00\u4e2a\u6b63\u592a\u5206\u5e03\uff08\u84dd\u8272\u7684\u90e8\u5206\uff09\u7684\u5747\u503c\u548c\u65b9\u5dee\u662f\u5df2\u77e5\u7684\uff0cDDPM\u9009\u62e9\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u65b9\u6cd5\uff0c\u5373\u8ba9\u540e\u9762\u90e8\u5206\u7684\u5747\u503c\u8d8a\u63a5\u8fd1\u84dd\u8272\u90e8\u5206\u7684\u5747\u503c\uff08\u4e0d\u8003\u8651\u65b9\u5dee\u7684\u4e8b\u60c5\uff0c\u5047\u8bbe\u540e\u9762\u90e8\u5206\u7684\u65b9\u5dee\u56fa\u5b9a\uff09\uff0c\u8fd9\u6837\u4e24\u5206\u5e03\u5c31\u8d8a\u63a5\u8fd1\u3002</p> <p>\u540e\u9762\u90e8\u5206\u7684\u5747\u503c\u53c8\u600e\u4e48\u6c42\u5462\uff1f\u76f4\u63a5\u8ba9\u6a21\u578b\u9884\u6d4b\u540e\u9762\u90e8\u5206\u7684\u5747\u503c\uff0c\u7136\u540e\u8ba9\u8fd9\u4e2a\u9884\u6d4b\u7684\u5747\u503c\u63a5\u8fd1\u84dd\u8272\u90e8\u5206\u7684\u5747\u503c\uff08\u5df2\u77e5\uff09\u3002\u6211\u4eec\u8fd8\u53ef\u4ee5\u5bf9\u8fd9\u4e2a\u5df2\u77e5\u7684\u5747\u503c\u5316\u7b80\u4e00\u4e0b\uff0c\u5982\u4e0b\u6240\u793a\uff1a</p> <p>\u653e\u5927\u6765\u770b\u5c31\u662f\uff1a</p> <p>\u90a3\u4e48\u8fd9\u4e2a\u5df2\u77e5\u7684\u5747\u503c\u88ab\u6211\u4eec\u5316\u7b80\u7684\u5f88\u7b80\u5355\u4e86\uff0c\u5b83\u5c31\u53ea\u5305\u542b\u4e86\u4e00\u4e2a\u672a\u77e5\u6570\uff0c\u5373\u6dfb\u52a0\u7684\u90a3\u4e00\u6b65\u566a\u58f0\u3002\u90a3\u6211\u4eec\u6a21\u578b\u53ea\u53d6\u9884\u6d4b\u90a3\u4e2a\u566a\u58f0\u5c31\u597d\u5566\uff0c\u7136\u540e\u4e00\u5207\u90fd\u89e3\u51b3\u4e86\u3002</p> <p>\u8fd9\u5c31\u89e3\u91ca\u4e86\u6269\u6563\u6a21\u578b\u7684\u8bad\u7ec3\u76ee\u6807\uff0c\u4f46\u662f\u76f4\u89c2\u4e0a\uff0c\u8fd9\u4e0d\u5c31\u662f\u52a0\u566a\u8fc7\u7a0b\u7684\u9006\u516c\u5f0f\u5417\u3002\u3002\u3002</p> <p>\u4e0d\u8fc7\uff0c\u81f3\u6b64\uff0c\u6211\u4eec\u5c31\u80fd\u66f4\u52a0\u6df1\u5165\u7406\u89e3Diffusion\u7684\u635f\u5931\u51fd\u6570\u8bbe\u8ba1\u5566\uff01</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/Diffusion%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/#flow","title":"FLOW\uff1a\u4f3c\u7136\u7684\u7b49\u4ef7\u5f62\u5f0f","text":"<p>\u8865\u5145\u4e00\u5219\u6570\u5b66\u77e5\u8bc6\uff1a</p> <p>\u5176\u4e2d\u7684J\u8868\u793a\u96c5\u5404\u6bd4\u77e9\u9635\uff0c\u7ed9\u5b9a\u51fd\u6570 f:\uff08Rm x Rn \uff09, \u8be5\u51fd\u6570\u7684\u6240\u6709\u4e00\u9636\u504f\u5bfc\u6570\u7ec4\u6210\u7684\u77e9\u9635 J \u79f0\u4e3a Jacobian \u77e9\u9635\u3002\u82e5 m = n\uff0c\u53ef\u4ee5\u5b9a\u4e49\u5173\u4e8e\u65b9\u9635 J\u7684\u884c\u5217\u5f0f\u3002</p> <p>\u90a3\u4e48\u7531\u53d8\u91cf\u53d8\u6362\u5b9a\u7406\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\u4f3c\u7136\u7684\u7b49\u4ef7\u5f62\u5f0f\uff1a</p> <p>\u4e0d\u8fc7\u8981\u60f3\u4e00\u6b65\u505a\u5230\uff0c\u57fa\u672c\u4e0a\u4e0d\u53ef\u80fd\uff0c\u6240\u4ee5\u53ef\u4ee5\u5c06\u5176\u5206\u89e3\u4e3a\u591a\u6b65\u53ef\u9006\u7684\u64cd\u4f5c\uff1a</p> <p>\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u53ea\u9700\u8981\u5229\u7528 f\u9006\uff0c\u800c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528 f \u8fdb\u884c\u751f\u6210\uff0c\u56e0\u6b64\u5bf9 f \u7ea6\u675f\u4e3a\uff1af \u7f51\u7edc\u662f\u53ef\u9006\u7684\u3002\u8fd9\u5bf9\u7f51\u7edc\u7ed3\u6784\u8981\u6c42\u6bd4\u8f83\u4e25\u683c\uff0c\u5728\u5b9e\u73b0\u65f6\uff0c\u901a\u5e38\u8981\u6c42 f \u7684\u8f93\u5165\u8f93\u51fa\u662f\u76f8\u540c\u7ef4\u5ea6\u7684\u6765\u4fdd\u8bc1 f \u7684\u53ef\u9006\u6027\u3002\u8fd9\u5c31\u662f\u6240\u6709\u57fa\u4e8e\u6d41\u6a21\u578b\u7684\u6a21\u578b\u7684\u8bbe\u8ba1\u601d\u8def\u3002</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/Diffusion%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/#js","title":"\u751f\u6210\u5bf9\u6297\u8bad\u7ec3=\u6700\u5c0f\u5316JS\u6563\u5ea6\uff1f","text":"<p>\u751f\u6210\u5bf9\u6297\u8bad\u7ec3\uff0c\u76f4\u89c2\u4e0a\u53ef\u4ee5\u7406\u89e3\u4e3a\u5224\u522b\u5668\u548c\u751f\u6210\u5668\u8bad\u7ec3\uff0c\u4ed6\u7684\u8bad\u7ec3\u635f\u5931\u51fd\u6570\u5982\u4e0b\u6240\u793a\uff0c\u5176\u4e2dD\u8868\u793a\u5224\u522b\u5668\uff0cG\u8868\u793a\u751f\u6210\u5668\uff0cx\u8868\u793a\u771f\u5b9e\u56fe\u50cf\uff0cz\u8868\u793a\u566a\u58f0\u5411\u91cf\uff1a</p> <p>\u76f4\u89c2\u4e0a\u7406\u89e3\u8fd9\u4e2a\u516c\u5f0f\uff1a</p> <ul> <li>\u5bf9\u4e8e\u68c0\u6d4b\u5668D\uff0c\u5b83\u7684\u76ee\u6807\u662f\u8ba9x\uff08\u771f\u5b9e\u56fe\u7247\uff09\u5224\u65ad\u4e3a1\uff0c\u7531z\u751f\u6210\u7684\u56fe\u7247\u5224\u65ad\u4e3a0</li> <li>\u5bf9\u4e8e\u751f\u6210\u5668G\uff0c\u5b83\u7684\u76ee\u6807\u662f\u4f7f\u5f97D\u5c06\u7531z\u751f\u6210\u7684\u56fe\u7247\u5224\u65ad\u4e3a1</li> </ul> <p>\u4ece\u6570\u5b66\u4e0a\uff0c\u6211\u4eec\u53ef\u4ee5\u8bc1\u660e\u8fd9\u4e2a\u8bad\u7ec3\u76ee\u6807\u5c31\u662f\u6700\u5c0f\u5316\u771f\u5b9e\u5206\u5e03\u548c\u751f\u6210\u5206\u5e03\u4e4b\u95f4\u7684JS\u6563\u5ea6\uff1a</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/Diffusion%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/#_7","title":"\u5982\u4f55\u8fdb\u884c\u751f\u6210\u5bf9\u6297\u8bad\u7ec3\uff1f","text":""},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/Diffusion%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/#gan","title":"GAN\u7684\u771f\u5b9e\u635f\u5931\u51fd\u6570","text":"<p>\u73b0\u5728\u6211\u4eec\u53ea\u77e5\u9053\u4e0a\u9762\u90a3\u4e2a\u635f\u5931\u51fd\u6570\u662f\u6b63\u786e\u7684\uff0c\u6309\u7167\u5b83\u8bad\u7ec3\u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a\u597d\u7684\u56fe\u50cf\u751f\u6210\u5668\uff0c\u4f46\u662f\uff0c\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\u6839\u672c\u7b97\u4e0d\u51fa\u6765\u554a\uff0c\u867d\u7136\u5176\u7406\u8bba\u4e0a\u53ef\u4ee5\u7b80\u5316\u4e3a\u5982\u4e0b\u516c\u5f0f\uff0c\u4f46\u662f\u6837\u672c\u7a7a\u95f4\u662f\u65e0\u7a77\u5927\u7684\uff0c\u90a3\u4e48\u6211\u4eec\u6ca1\u529e\u6cd5\u83b7\u5f97\u5b83\u7684\u771f\u5b9e\u671f\u671b\u3002</p> <p>\u90a3\u4e48\u53ea\u80fd\u8fd1\u4f3c\u6c42\u89e3\u54af\uff0c\u4e5f\u5c31\u662f\u7528\u90e8\u5206\u771f\u5b9e\u548c\u90e8\u5206\u751f\u6210\u7684\u6837\u672c\u53bb\u5047\u88c5\u8fd9\u4e2a\u771f\u5b9e\u7684\u5206\u5e03\uff0c\u53ef\u4ee5\u8ba4\u4e3a\u6709\u70b9\u79bb\u6563\u5316\u7684\u611f\u89c9\u3002\u4e8e\u662f\u6211\u4eec\u7684\u8bad\u7ec3\u76ee\u6807\u5c31\u53d8\u6210\u4e86\u4e00\u4e2a0-1\u4ea4\u53c9\u71b5\u635f\u5931\u4e86\u3002</p> <p>\u81f3\u6b64\uff0c\u751f\u6210\u5bf9\u6297\u8bad\u7ec3\u7684\u635f\u5931\u51fd\u6570\u5c31\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u5206\u7c7b\u4ea4\u53c9\u71b5\u635f\u5931\u3002\u4e0d\u8fc7\u53ea\u662f\u4ea4\u66ff\u8bad\u7ec3\u6548\u679c\u6700\u597d\u3002</p> <p>\u6ce8\u610f\u5224\u522b\u5668\u76ee\u6807\u662f\u6700\u5c0f\u5316\u8fd9\u4e2a\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u751f\u6210\u5668\u76ee\u6807\u662f\u6700\u5927\u5316\u8fd9\u4e2a\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u3002</p>"},{"location":"%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/Diffusion%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/#gan_1","title":"GAN\u7684\u672c\u8d28\u95ee\u9898","text":"<p>\u4e00\u4e2a\u95ee\u9898\u662f\uff0cGAN\u8bbe\u8ba1\u635f\u5931\u51fd\u6570\u5e76\u4e0d\u5b8c\u5168\u7b49\u4e8e\u4e24\u500d\u7684JS\u6563\u5ea6\uff0c\u4e5f\u5c31\u662f\u524d\u9762\u6709-2log2\u8fd9\u4e2a\u90e8\u5206\u3002</p> <p>\u6211\u4eec\u77e5\u9053\uff0c\u5f53\u635f\u5931\u51fd\u6570\u4e00\u76f4\u4e3a0\u65f6\uff0c\u5176\u5b9e\u6211\u4eec\u65e0\u6cd5\u8bad\u7ec3\u6a21\u578b\uff0c\u800c\u5f53\u4e24\u4e2a\u5206\u5e03\u4e0d\u91cd\u53e0\u65f6\uff0cJS\u6563\u5ea6\u53d6log2\uff0c\u4ece\u800c\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\u53d60\u3002\u6709\u4e24\u79cd\u60c5\u51b5\u4f1a\u5bfc\u81f4\u4e24\u4e2a\u5206\u5e03\u4e0d\u91cd\u53e0\uff1a</p> <ul> <li>\u5176\u4e00\uff1a\u751f\u6210\u5668\u592a\u8fa3\u9e21\u4e86\uff0c\u751f\u6210\u56fe\u7684\u5206\u5e03\u4e00\u76f4\u548c\u771f\u5b9e\u7684\u56fe\u7684\u5206\u5e03\u91cd\u53e0\u4e0d\u4e86\u3002</li> <li>\u5176\u4e8c\uff1a\u5224\u522b\u5668\u592a\u5f3a\u5927\u4e86\uff0c\u751a\u81f3\u8fc7\u62df\u5408\uff0c\u786c\u662f\u80fd\u628a\u4e24\u4e2a\u5206\u5e03\u5b8c\u5168\u5206\u5f00\u3002</li> </ul> <p>\u4ee5\u4e0a\u4e24\u79cd\u60c5\u51b5\u4f1a\u5bfc\u81f4GAN\u5f88\u96be\u8bad\u7ec3\uff0c\u95ee\u9898\u4e00\u53ef\u4ee5\u52a0\u6b63\u5219\u5316\u65b9\u6cd5\u6216\u8005\u51cf\u5c11\u6a21\u578b\u53c2\u6570\u8ba9\u4ed6\u53d8\u5f31\uff0c\u95ee\u9898\u4e8c\u53ef\u4ee5\u52a0\u4e00\u70b9\u566a\u58f0\u8ba9\u4e24\u4e2a\u5206\u5e03\u91cd\u53e0\u3002\u4f46\u662f\u8fd9\u4e24\u4e2a\u89e3\u51b3\u65b9\u6848\u53ea\u80fd\u7f13\u89e3\u95ee\u9898\uff0c\u672c\u8d28\u65e0\u6cd5\u6539\u53d8\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/GPT%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/","title":"GPT\u4ee3\u7801\u5206\u6790","text":"<p>\u4e3b\u8981\u53c2\u8003\u4ee3\u7801\uff1aNanoGPT\u4ee3\u7801 \u4e2d\u7684 model.py</p> <p>\u90e8\u5206\u53c2\u8003\u4ee3\u7801\uff1a\u4ece\u96f6\u5f00\u59cb\u624b\u6413\u4e00\u4e2aLLM \u4e2d\u7684 model.py</p> <p>\u90e8\u5206\u53c2\u8003\u4ee3\u7801\uff1aTransformers\u5e93\u4e2d\u7684GPT2\u6a21\u578b</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/GPT%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#_1","title":"\u6838\u5fc3\u4ee3\u7801\u903b\u8f91","text":"<p>\u5bf9\u5e94\u4ee3\u7801\u4e2d\u7684\uff1amodel.py/GPT/forward</p> <pre><code>def forward(self, idx, targets=None):\n    device = idx.device\n    b, t = idx.size()\n    assert t &lt;= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n    pos = torch.arange(0, t, dtype=torch.long, device=device) \n\n    # \u6700\u6838\u5fc3\u7684\u6a21\u578b\u90e8\u5206\uff0c\u6ce8\u610f\u8f93\u5165\u548c\u8f93\u51fa\u7ef4\u5ea6\u4e00\u81f4\n    tok_emb = self.transformer.wte(idx) # (b, t, n_embd)\n    pos_emb = self.transformer.wpe(pos) # (t, n_embd)\n    x = self.transformer.drop(tok_emb + pos_emb)\n    for block in self.transformer.h:\n        x = block(x)\n    x = self.transformer.ln_f(x) # (b, t, n_embd)\n\n    # \u5904\u7406\u6a21\u578b\u7684\u8f93\u51fa\n    if targets is not None: \n        # \u8bad\u7ec3\u6a21\u5f0f : (b, t, n_embd) --&gt; (b, t, n_vocab)\n        logits = self.lm_head(x) \n        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n    else: \n        # \u63a8\u7406\u6a21\u5f0f : (b, t, n_embd) --&gt; (b, 1, n_embd)--&gt; (b, 1, n_vocab)\n        # \u8fd9\u91cc\u4f7f\u7528\u4e86\u4e00\u4e2a\u989d\u5916\u7684 []\uff0c\u8fd9\u4f7f\u5f97\u7ed3\u679c\u4fdd\u6301\u4e86\u539f\u59cb\u7684\u4e09\u7ef4\u5f62\u72b6\u3002\n        logits = self.lm_head(x[:, [-1], :]) \n        loss = None\n    return logits, loss \n</code></pre> <p>\u4e0a\u9762\u7684\u4ee3\u7801\u8fd8\u6ca1\u6709\u6d89\u53ca\u600e\u4e48\u5c06\u6982\u7387\u5206\u5e03\u91c7\u6837\u4e3aembedding\uff0c\u63a5\u4e0b\u6765\u8fdb\u884c\u5b8c\u6574\u5206\u6790\u3002</p> <p>\u5bf9\u5e94\u4ee3\u7801\u4e2d\u7684\uff1amodel.py/GPT/generate</p> <pre><code>def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n    for _ in range(max_new_tokens):\n\n        # \u5982\u679c\u6587\u672c\u957f\u4e86\uff0c\u76f4\u63a5\u622a\u53d6\u524d\u9762\u4e00\u90e8\u5206\n        idx_cond = idx if idx.size(1) &lt;= self.config.block_size else idx[:, -self.config.block_size:]\n\n        # \u8c03\u7528\u4e86forward\u51fd\u6570\n        logits, _ = self(idx_cond) \n        logits = logits[:, -1, :] / temperature # logits\uff1a(b, n_vocab)\n\n        # \u5c06topk\u4ee5\u5916\u7684\u90e8\u5206\u503c\u7f6e\u4e3a\u65e0\u7a77\u5c0f\uff0c\u6982\u7387\u7f6e\u4e3a\u96f6\n        if top_k is not None:\n            v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n            logits[logits &lt; v[:, [-1]]] = -float('Inf')\n        probs = F.softmax(logits, dim=-1)\n\n        # \u4ece\u591a\u9879\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u5f97\u5230\u4e0b\u4e00\u4e2a\u5b57\u7684embedding\uff0c\u5e76\u62fc\u63a5\n        idx_next = torch.multinomial(probs, num_samples=1)\n        idx = torch.cat((idx, idx_next), dim=1)\n    return idx\n</code></pre>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/GPT%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#_2","title":"\u6a21\u578b\u5177\u4f53\u7ed3\u6784","text":""},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/GPT%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#_3","title":"\u5b8f\u89c2\u7ed3\u6784\u5b9a\u4e49","text":"<pre><code>def __init__(self, config):\n    super().__init__()\n    assert config.vocab_size is not None\n    assert config.block_size is not None\n    self.config = config\n\n    # \u5b9a\u4e49\u6a21\u578b\u7ed3\u6784\n    self.transformer = nn.ModuleDict(dict(\n        wte = nn.Embedding(config.vocab_size, config.n_embd),\n        wpe = nn.Embedding(config.block_size, config.n_embd),\n        drop = nn.Dropout(config.dropout),\n        h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n        ln_f = LayerNorm(config.n_embd, bias=config.bias),\n    ))\n    self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n\n    # \u5171\u4eab\u90e8\u5206\u53c2\u6570 \uff1f\uff1f\uff1f\u8fd9\u91cc\u7684\u7ef4\u5ea6\u6211\u6ca1\u6709\u641e\u61c2\u4e3a\u4ec0\u4e48\n    # \u5b9e\u9645\u4e0a\u662f\u5c06\u5f20\u91cf\u5bf9\u8c61\u7684\u5f15\u7528\u8d4b\u7ed9\u4e86\u5b83\uff0c\u800c\u4e0d\u662f\u521b\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u5f20\u91cf\u5bf9\u8c61\u3002\n    self.transformer.wte.weight = self.lm_head.weight \n\n    # \u521d\u59cb\u5316\u6743\u91cd\n    self.apply(self._init_weights)\n    # \uff1f\uff1f\uff1f\u4e3a\u4ec0\u4e48\u8981\u7279\u6b8a\u5904\u7406\u8fd9\u4e2a\u70b9\u6ca1\u6709\u5f88\u641e\u6e05\u695a\uff0c\u53ef\u80fd\u662f\u67d0\u79cd\u6280\u5de7\n    for pn, p in self.named_parameters():\n        if pn.endswith('c_proj.weight'):\n            torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n    print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n\n</code></pre> <ul> <li>\u5982\u4f55\u8ba1\u7b97\u6a21\u578b\u4e2d\u6240\u6709\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff1f</li> </ul> <pre><code># self.parameters() \u8fd4\u56de\u6a21\u578b\u4e2d\u6240\u6709\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff08\u5373\u6743\u91cd\u548c\u504f\u7f6e\uff09\n# p.numel() \u8ba1\u7b97\u5f20\u91cf\u4e2d\u5143\u7d20\u7684\u603b\u6570\u91cf\n\nn_params = sum(p.numel() for p in self.parameters())\n</code></pre> <ul> <li>\u5982\u4f55\u521d\u59cb\u5316\u6a21\u578b\u7684\u6240\u6709\u6743\u91cd?</li> </ul> <pre><code># apply() \u63a5\u53d7\u4e00\u4e2a\u51fd\u6570\uff0c\u5e76\u5c06\u8fd9\u4e2a\u51fd\u6570\u5e94\u7528\u5230\u6a21\u578b\u7684\u6bcf\u4e2a\u5b50\u6a21\u5757\u4e0a\u3002\n# self._init_weights \u662f\u4e00\u4e2a\u51fd\u6570\uff0c\u6240\u4ee5\u521d\u59cb\u5316\u5c31\u662fself.apply(self._init_weights)\n# torch.nn.init.normal_\u5c06\u5f20\u91cf\u7684\u503c\u4ece\u6b63\u6001\u5206\u5e03\u4e2d\u91c7\u6837\n\ndef _init_weights(self, module):\n    if isinstance(module, nn.Linear):\n        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n        if module.bias is not None:\n            torch.nn.init.zeros_(module.bias)\n    elif isinstance(module, nn.Embedding):\n        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n</code></pre>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/GPT%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#_4","title":"\u5177\u4f53\u6a21\u5757\u5b9a\u4e49","text":"<pre><code>def __init__(self, config):\n    super().__init__()\n    self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n    self.attn = CausalSelfAttention(config)\n    self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n    self.mlp = MLP(config)\ndef forward(self, x):\n    x = x + self.attn(self.ln_1(x))\n    x = x + self.mlp(self.ln_2(x))\n    return x\n</code></pre> <ul> <li>LN \u5c42\u7684\u5177\u4f53\u5b9e\u73b0</li> </ul> <pre><code>def __init__(self, ndim, bias):\n    super().__init__()\n    self.weight = nn.Parameter(torch.ones(ndim))\n    self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\ndef forward(self, input):\n    return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)\n</code></pre> <ul> <li>MLP \u5c42\u7684\u5177\u4f53\u5b9e\u73b0</li> </ul> <pre><code>def __init__(self, config):\n    super().__init__()\n    self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n    self.gelu    = nn.GELU()\n    self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n    self.dropout = nn.Dropout(config.dropout)\n</code></pre> <ul> <li>CausalSelfAttention \u5c42\u7684\u5177\u4f53\u5b9e\u73b0</li> </ul> <pre><code>def forward(self, x):\n    B, T, C = x.size() # batch size, sequence length, (n_embd)\n\n    q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n\n    # \u8fd9\u4e2a\u62c6\u6210\u591a\u4e2a\u5934\uff0c\u6211\u53ea\u80fd\u8bf4\u4e0d\u8981\u592a\u806a\u660e\uff0c\u6700\u540e\u7ef4\u5ea6\u53d8\u6210 (B, nh, T, hs)\n    k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) \n    q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) \n    v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) \n\n    # causal self-attention; \n    # Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -&gt; (B, nh, T, T)\n    if self.flash:\n        # \u9ad8\u6548\u5b9e\u73b0\u7248\u672c \u8ba1\u7b97\u7f29\u653e\u70b9\u79ef\u6ce8\u610f\u529b\n        y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n    else:\n        # \u624b\u5de5\u5b9e\u73b0\u7248\u672c \u8ba1\u7b97\u7f29\u653e\u70b9\u79ef\u6ce8\u610f\u529b\n        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n        # \u4e0b\u9762\u7684\u8fd9\u4e2abias\u7531\u4e8e\u6ce8\u518c\u8fc7\u7f13\u51b2\u533a\u6240\u4ee5\u4f1a\u5b9e\u73b0\u56e0\u679c\u6ce8\u610f\u529b\uff01\uff01\uff01\u725b\n        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n        att = F.softmax(att, dim=-1)\n        att = self.attn_dropout(att)\n        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -&gt; (B, nh, T, hs)\n    # contiguous() \u4fdd\u8bc1\u5176\u5b58\u50a8\u5728\u5185\u5b58\u4e2d\u7684\u987a\u5e8f\u4e0e\u5176\u5728\u5f20\u91cf\u7a7a\u95f4\u4e2d\u7684\u987a\u5e8f\u662f\u4e00\u81f4\u7684\u3002\n    y = y.transpose(1, 2).contiguous().view(B, T, C) \n\n    # \u7b49\u7ef4\u5ea6\u7684\u8f93\u51fa\u6620\u5c04\uff0c\u518d\u52a0\u4e00\u4e2adropout\n    y = self.resid_dropout(self.c_proj(y))\n    return y\n</code></pre> <ul> <li>\u7406\u89e3mask_attention\u662f\u9632\u6b62padding\u7684\u90e8\u5206\u88ab\u5173\u6ce8\uff01\u800c\u4e0d\u662f\u5b9e\u73b0\u56e0\u679c\u6ce8\u610f\u529b\uff01</li> </ul> <p>\u53c2\u8003\u94fe\u63a5\uff1atransformer\u4e2d: self-attention\u90e8\u5206\u662f\u5426\u9700\u8981\u8fdb\u884cmask\uff1f</p> <ul> <li>\u5982\u4f55\u5b9e\u73b0\u56e0\u679c\u6ce8\u610f\u529b\uff1f</li> </ul> <pre><code># scaled_dot_product_attention\u4e2d\u81ea\u5e26\u5b9e\u73b0\uff0c\u6240\u4ee5\u5982\u679c\u7248\u672c\u597d\u5c31\u4e0d\u7528\u624b\u52a8\u5b9e\u73b0\u4e86\nself.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\nif not self.flash:\n    print(\"WARNING: using slow attention. Flash Attention requires PyTorch &gt;= 2.0\")\n    # causal mask \n    # torch.tril \u521b\u5efa\u4e86\u4e00\u4e2a\u4e0b\u4e09\u89d2\u77e9\u9635\uff0c\u5176\u5de6\u4e0b\u89d2\u7684\u5143\u7d20\u4e3a 1\uff0c\u5176\u4f59\u5143\u7d20\u4e3a 0\n    # .view \u5c06\u8fd9\u4e2a\u4e0b\u4e09\u89d2\u77e9\u9635\u91cd\u5851\u4e3a 4 \u7ef4\u5f20\u91cf\uff0c\u4ee5\u5339\u914d\u540e\u7eed\u6ce8\u610f\u529b\u8ba1\u7b97\u7684\u8981\u6c42\n    # self.register_buffer() \u5c06bias\u6ce8\u518c\u5230\u7f13\u51b2\u533a\n    self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n                                .view(1, 1, config.block_size, config.block_size))\n</code></pre> <p>\u8865\u5145\uff1a\u7f13\u51b2\u533a\u662f\u53ef\u4ee5\u88ab\u6a21\u578b\u8bbf\u95ee\u4f46\u4e0d\u4f1a\u88ab\u4f18\u5316\u5668\u66f4\u65b0\u7684\u5f20\u91cf\uff0c\u901a\u5e38\u7528\u4e8e\u5b58\u50a8\u6a21\u578b\u7684\u56fa\u5b9a\u53c2\u6570\u3001\u5e38\u91cf\u6216\u4e2d\u95f4\u7ed3\u679c\u3002\u8fd9\u4e9b\u53c2\u6570\u901a\u5e38\u662f\u4e0d\u9700\u8981\u68af\u5ea6\u7684\uff0c\u4f46\u9700\u8981\u5728\u6a21\u578b\u7684\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u88ab\u8bbf\u95ee\u5230\u3002</p> <p>\u6216\u8005\uff0c\u76f4\u63a5\u7ed9torch.nn.functional.scaled_dot_product_attention() \u4f20\u53c2\u6570is_causal = True</p> <ul> <li>\u4e3a\u4ec0\u4e48\u8981\u7528contiguous()\u4fdd\u8bc1\u5b58\u50a8\u987a\u5e8f\u662f\u4e00\u81f4\u7684\uff1f</li> </ul> <p>\u5f53\u6211\u4eec\u5bf9\u5f20\u91cf\u8fdb\u884c\u4e00\u4e9b\u64cd\u4f5c\uff08\u4f8b\u5982\u8f6c\u7f6e\u3001reshape\u7b49\uff09\u540e\uff0c\u53ef\u80fd\u4f1a\u6539\u53d8\u5f20\u91cf\u7684\u5b58\u50a8\u987a\u5e8f\uff0c\u4f7f\u5f97\u5b83\u4e0d\u518d\u6ee1\u8db3\u201c\u884c\u4f18\u5148\u201d\u7684\u89c4\u5219\u3002\u8fd9\u4f1a\u5bfc\u81f4\u4e00\u4e9b\u95ee\u9898\uff0c\u4f8b\u5982\u5728\u4f7f\u7528\u4e00\u4e9b\u5e95\u5c42\u7684\u4f18\u5316\u5e93\uff08\u5982cuBLAS\u3001cuDNN\u7b49\uff09\u8fdb\u884c\u8ba1\u7b97\u65f6\uff0c\u8fd9\u4e9b\u5e93\u901a\u5e38\u4f1a\u5047\u8bbe\u5f20\u91cf\u7684\u5b58\u50a8\u987a\u5e8f\u662f\u201c\u884c\u4f18\u5148\u201d\uff0c\u5982\u679c\u4e0d\u6ee1\u8db3\u8fd9\u4e2a\u5047\u8bbe\uff0c\u53ef\u80fd\u4f1a\u5bfc\u81f4\u8ba1\u7b97\u7ed3\u679c\u9519\u8bef\u6216\u6027\u80fd\u4e0b\u964d\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/","title":"\u4f4d\u7f6e\u7f16\u7801","text":"<p>\u53c2\u8003\u8d44\u6599\uff1a\u56db\u79cdPosition Embedding\u7684\u539f\u7406\u4e0ePyTorch\u624b\u5199\u9010\u884c\u5b9e\u73b0</p> <p>\u53c2\u8003\u8d44\u6599\uff1a\u4f4d\u7f6e\u7f16\u7801\u516c\u5f0f\u8be6\u7ec6\u7406\u89e3\u8865\u5145</p> <p>\u53c2\u8003\u8d44\u6599\uff1a\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801-\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\u4e0e\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u7684\u7ed3\u5408</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/#motivation","title":"Motivation","text":"<p>\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u5e8f\u5217\u6570\u636e\uff08\u5982\u6587\u672c\u3001\u97f3\u9891\u3001\u65f6\u95f4\u5e8f\u5217\u7b49\uff09\u65f6\uff0c\u6a21\u578b\u9700\u8981\u80fd\u591f\u7406\u89e3\u8f93\u5165\u6570\u636e\u7684\u987a\u5e8f\u548c\u4f4d\u7f6e\u4fe1\u606f\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff08\u5982\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\uff09\u548c self-attention \u6ca1\u6709\u8003\u8651\u8f93\u5165\u6570\u636e\u7684\u4f4d\u7f6e\u4fe1\u606f\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u5728\u5904\u7406\u5e8f\u5217\u6570\u636e\u65f6\u6027\u80fd\u4e0b\u964d\uff0c\u7279\u522b\u662f\u5728\u957f\u5e8f\u5217\u60c5\u51b5\u4e0b\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/#method","title":"Method","text":""},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/#position-embedding","title":"Position Embedding","text":"<p>\u9996\u5148\uff0c\u4f4d\u7f6e\u7f16\u7801\u9700\u8981\u548c\u5355\u8bcd\u7f16\u7801\u957f\u5ea6\u4e00\u81f4\uff0c\u5426\u5219\u4e0d\u80fd\u76f8\u52a0\u3002\u5982\u679c\u5355\u8bcd\u7f16\u7801\u7684\u957f\u5ea6\u4e3a512\uff0c\u90a3\u4e48\u4f4d\u7f6e\u7f16\u7801\u7684\u957f\u5ea6\u4e5f\u8981\u4e3a512\u3002\u800c\u6bcf\u4e2a\u7ef4\u5ea6\u7684\u53d6\u503c\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u53ef\u4ee5\u53c2\u7167\u4e0b\u56fe\u7406\u89e3\uff1a</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/#_2","title":"\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801","text":"<p>\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\u7531\u4e24\u79cd\u5f62\u5f0f\uff0c\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u6211\u4eec\u53ea\u4ecb\u7ecd\u4e0b\u9762\u8fd9\u79cd\u3002\u5047\u8bbe\u5e8f\u5217\u7684\u957f\u5ea6\u4e3a\ud835\udc3f\uff0c\u8f93\u5165\u7684\u7ef4\u5ea6\u4e3a \ud835\udc51_model\uff08Transformer \u6a21\u578b\u4e2d\u7684\u9690\u85cf\u5c42\u7ef4\u5ea6\uff09\uff0c\u4f4d\u7f6e pos \u548c\u7ef4\u5ea6 i \u7684\u4f4d\u7f6e\u7f16\u7801\u53ef\u4ee5\u8ba1\u7b97\u5982\u4e0b\uff1a</p> <ul> <li>\u4e3a\u4ec0\u4e48\u8fd9\u6837\u53ef\u4ee5\u5305\u542b\u4f4d\u7f6e\u4fe1\u606f\uff1f</li> </ul> <p>\u4ece\u4e09\u89d2\u51fd\u6570\u516c\u5f0f\u53ef\u4ee5\u770b\u51fa\uff0c\u6b64\u65f6\u523b\u7684\u4f4d\u7f6e\u4fe1\u606f\u662f\u53ef\u4ee5\u7531\u4e4b\u524d\u65f6\u523b\u7684\u4f4d\u7f6e\u4fe1\u606f\u8ba1\u7b97\u5f97\u5230\u7684\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/#_3","title":"\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801","text":"<p>\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\u7684\u95ee\u9898\u662f\uff0c\u7b2c\u4e00\u4e2a\u4f4d\u7f6e\u548c\u7b2c\u4e8c\u4e2a\u4f4d\u7f6e\u7684\u5dee\u5f02\u7b49\u540c\u4e8e\u7b2c\u4e00\u4e2a\u4f4d\u7f6e\u4e0e\u7b2cN\u4e2a\u4f4d\u7f6e\u7684\u5dee\u5f02\uff0c\u6ca1\u6709\u8003\u8651\u8fdc\u8fd1\u7684\u95ee\u9898\u3002\u56e0\u6b64\u5c31\u4ea7\u751f\u4e86\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u6bd4\u5982T5\u6a21\u578b\u3002</p> <p>\u6ce8\u610f\u8fd9\u4e2a\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u7684\u4f4d\u7f6e\u4e0d\u518d\u662f\u52a0\u5728\u8f93\u5165\u7684\u4f4d\u7f6e\uff01\u56e0\u6b64\u8fd0\u884c\u901f\u5ea6\u6bd4\u5176\u4ed6\u4f4d\u7f6e\u7f16\u7801\u8981\u6162\u3002\u4e0d\u8fc7\u5b83\u7684\u4f18\u52bf\u4e5f\u5f88\u660e\u663e\uff0c\u53ef\u4ee5\u62d3\u5c55\u5230\u65e0\u9650\u957f\u5ea6\uff0c\u6bd5\u7adf\u8fd9\u4e2a\u53ea\u548c\u76f8\u5bf9\u4f4d\u7f6e\u6709\u5173\u4e0e\u7edd\u5bf9\u4f4d\u7f6e\u65e0\u5173\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/#rope","title":"RoPE \u4f4d\u7f6e\u7f16\u7801","text":"<p>RoPE \u7ed3\u5408\u4e86\u4e24\u8005\u7684\u4f18\u52bf\u3002</p> <p>\u76f4\u89c2\u4e0a\uff0c\u53ef\u4ee5\u4ece\u4e0b\u56fe\u4e2d\u7406\u89e3\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801\uff1a</p> <p>\u5177\u4f53\u7684\u8868\u8fbe\u5f62\u5f0f\u5982\u4e0b\uff0c\u7b2c\u4e00\u90e8\u5206\u662f\u65cb\u8f6c\u77e9\u9635\uff0c\u7b2c\u4e8c\u90e8\u5206\u662fQ\u548cK\uff0c\u7b2c\u4e09\u90e8\u5206\u662f\u8981\u65cb\u8f6c\u7684\u5355\u8bcd\u5411\u91cf\uff0c\u4e3a\u4e86\u65b9\u4fbf\u7406\u89e3\uff0c\u8fd9\u91cc\u7528\u7684\u90fd\u662f\u4e24\u4e2a\u7ef4\u5ea6\u7684\u8868\u8fbe\u5f62\u5f0f\uff1a</p> <p>\u66f4\u52a0\u901a\u7528\u7684\u8868\u8fbe\u5f62\u5f0f\u5982\u4e0b\uff1a</p> <p>\u4f46\u662f\u8fd9\u4e2a\u8868\u8fbe\u5f62\u5f0f\u8fc7\u4e8e\u590d\u6742\uff0c\u4e0b\u9762\u7ed9\u51fa\u4e00\u4e2a\u53d8\u5f62\u4e4b\u540e\u7684\u5f62\u5f0f\uff1a</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/#_4","title":"\u53ef\u8bad\u7ec3\u7684\u4f4d\u7f6e\u7f16\u7801","text":"<p>\u53ef\u8bad\u7ec3\u7684\u4f4d\u7f6e\u7f16\u7801\u6bd4\u8f83\u7b80\u5355\uff0c\u6ca1\u6709\u592a\u591a\u77e5\u8bc6\u70b9\uff0c\u5176\u5b9e\u5f88\u50cf\u5355\u8bcd\u7f16\u7801\u4e5f\u662f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5b66\u4e60\u7684\u53c2\u6570\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/","title":"\u5e38\u89c1\u5927\u6a21\u578b\uff08LM\uff09\u539f\u7406","text":""},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#_1","title":"\u6982\u8981\u8bf4\u660e","text":"<p>\u53c2\u8003\u6587\u732e1\uff1a\u56fd\u5916\u7248\u672c\u7684\u5927\u6a21\u578b\u5217\u8868 Awesome-LLM</p> <p>\u53c2\u8003\u6587\u732e2\uff1a\u56fd\u5185\u7248\u672c\u7684\u5927\u6a21\u578b\u5217\u8868 awesome-llm</p> <p>\u4e00\u4e9b\u5e38\u7528\u7684\u6a21\u578b\u53c2\u6570\u5fc3\u7406\u8981\u6709\u6570\uff1aLLAMA2\uff08LLAMA3\uff09\u3001ChatGLM3\u3001GPT2\u3001bert</p> \u6a21\u578b \u6765\u6e90 \u53c2\u6570\u91cf \u6700\u5927\u4e0a\u4e0b\u6587\u957f\u5ea6 \u663e\u5b58\u5360\u7528(\u5168\u7cbe\u5ea6) llama2 Meta 7B/13B/70B 4k(4096) 28G/52G/280G chatglm3 THU 6B 8k/32k/128k 24G~28G gpt2 OpenAI 117M/345M/762M/1.5B 1k(1024) &lt;6G bert Google 110M/340M 1k(1024) &lt;2G <ul> <li>\u7cbe\u5ea6\uff1a\u901a\u5e38\u6709Float32(4\u5b57\u8282)(\u53c8\u79f0\u5168\u7cbe\u5ea6) / Float16(2\u5b57\u8282) / Int8(1\u5b57\u8282) / Int4(0.5\u5b57\u8282)</li> <li>Alpaca \u662f\u65af\u5766\u798f\u5728LLaMa-7B\u7684\u57fa\u7840\u4e0a\u76d1\u7763\u5fae\u8c03\u51fa\u6765\u7684\u6a21\u578b</li> <li>Vicuna \u662f\u5728LLaMa-13B\u7684\u57fa\u7840\u4e0a\u4f7f\u7528\u76d1\u7763\u6570\u636e\u5fae\u8c03\u5f97\u5230\u7684\u6a21\u578b\uff0c\u6570\u636e\u6765\u81eaShareGPT.com</li> <li>1T\uff1a\u8868\u793a10\u768412\u6b21\u65b9\uff0c\u53731\u4e07\u4ebf\uff0c\u5176\u6b21\u662f 1B(10\u4ebf)\u30011M(100\u4e07) </li> </ul>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#bert","title":"BERT","text":"<p>\u53c2\u8003\u6587\u732e\uff1aBERT/RoBERTa/ALBERT/ELECTRA\u3001ERNIE</p> <p>\u4ecd\u5728\u8865\u5145\u4e2d...</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#gpt","title":"GPT","text":""},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#method","title":"Method","text":"<p>\u4e3a\u4e86\u66f4\u52a0\u6df1\u5165\u4e86\u89e3 GPT \u6a21\u578b\uff0c\u6211\u7814\u7a76\u4e86\u5b83\u7684\u5b9e\u73b0\u4ee3\u7801\uff0c\u5176\u5b9e\u5e76\u4e0d\u53ef\u6015\u3002</p> <p>\u5177\u4f53\u7684\u4ee3\u7801\u5206\u6790\uff0c\u8bf7\u53c2\u8003\u6211\u7684\u53e6\u4e00\u4e2ablog \"GPT\u4ee3\u7801\u5206\u6790\"\uff0c \u672c\u5c0f\u8282\u4e0d\u518d\u8d58\u8ff0\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#motivation","title":"Motivation","text":"<p>GPT1\u6a21\u578b\u7684\u8bad\u7ec3\u4e3b\u8981\u5206\u4e3a\u4e0b\u9762\u4e24\u4e2a\u9636\u6bb5\uff1a</p> <p>\u9636\u6bb5\u4e00\u3010\u65e0\u76d1\u7763\u5b66\u4e60\u3011\uff1a\u7ed9\u5b9a\u4e0a\u6587\u9884\u6d4b\u4e0b\u4e00\u4e2a\u5355\u8bcd\u53d1\u751f\u7684\u6982\u7387\u3002\u6a21\u578b\u5b66\u4e60\u5229\u7528\u6700\u5927\u4f3c\u7136\u601d\u60f3\u3002</p> <p>\u9636\u6bb5\u4e8c\u3010\u6709\u76d1\u7763\u5b66\u4e60\u3011\uff1a\u6839\u636e\u4e0d\u540c\u7684\u6709\u76d1\u7763\u4e0b\u6e38\u4efb\u52a1\uff0c\u53bb\u5fae\u8c03\u6a21\u578b\u4ea7\u751f\u4e0b\u6e38\u4efb\u52a1\u6a21\u578b\u96c6\u5408\u3002</p> <p>\u8fd9\u79cd\u505a\u6cd5\u6bd4\u8f83\u7e41\u7410\uff0c\u4e14\u8bad\u7ec3\u51fa\u7684\u6a21\u578b\u6cdb\u5316\u6027\u8f83\u5dee\uff0c\u6240\u4ee5GPT2\u7684\u601d\u60f3\u662f\u53ea\u8bad\u7ec3\u4e00\u9636\u6bb5\u6a21\u578b\uff0c\u76f4\u63a5\u5c06\u4e0b\u6e38\u4efb\u52a1\uff08task\uff09\u4f5c\u4e3a\u8f93\u5165\uff0c\u653e\u5165\u65e0\u76d1\u7763\u8bed\u8a00\u6a21\u578b\u4e2d\u505a\u8bad\u7ec3\u3002\u56e0\u6b64\uff0cGPT2\u4e0d\u9700\u8981\u523b\u610f\u5730\u7ec4\u7ec7\u8bad\u7ec3\u96c6\u7684\u683c\u5f0f\uff0c\u53ea\u9700\u8981\u5c06\u6d77\u91cf\u7684\u6570\u636e\u76f4\u63a5\u5582\u7ed9\u6a21\u578b\uff0c\u5b83\u81ea\u7136\u80fd\u5b66\u4e60\u5230\u5404\u79cd\u6280\u80fd\uff0c\u4e14\u5728\u9884\u6d4b\u65f6\uff0c\u53ea\u9700\u8981\u7ed9\u4e00\u4e9b\u63d0\u793a\uff08Prompt\uff09\uff0c\u5c31\u80fd\u591f\u5f97\u5230\u6bd4\u8f83\u4e0d\u9519\u7684\u8f93\u51fa\u3002</p> <p>GPT3\u7684\u52a8\u673a\u66f4\u52a0\u7b80\u5355\uff0c\u56e0\u4e3aGPT2\u7684\u6548\u679c\u4e0d\u597d\uff0c\u89c9\u5f97\u539f\u56e0\u53ef\u80fd\u662f\u5927\u5c0f\u4e0d\u591f + \u8bad\u7ec3\u4e0d\u591f\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#framework","title":"Framework","text":"<p>\u6574\u4f53\u6765\u8bf4\uff0c\u4e09\u4ee3\u6a21\u578b\u6ca1\u6709\u592a\u5927\u7684\u5dee\u522b\uff0c\u4e3b\u8981\u662f\u589e\u5927\u4e86\u53c2\u6570\u91cf\u3001\u8bad\u7ec3\u91cf\u548c\u52a0\u5165\u4e86\u4e00\u4e9b\u5c0f\u4fee\u6539\u3002</p> <p>GPT1\u7684Decoder\u6a21\u5757\u753112\u5c42\u7b80\u5316\u7248DecoderLayer\u4e32\u8054\u800c\u6210\u3002GPT2\u7684\u6a21\u578b\u7ed3\u6784\u548cGPT1\u57fa\u672c\u4e00\u81f4\uff0c\u4e0d\u540c\u70b9\u5728\u4e8e\uff1aLayerNorm\u88ab\u63d0\u524d\u81f3DecoderLayer\u7684\u8f93\u5165\u4f4d\u7f6e\u3001\u6b8b\u5dee\u5c42\u53c2\u6570\u7684\u521d\u59cb\u5316\u53c2\u6570\u7edf\u4e00\u9664\u4ee5\u6b8b\u5dee\u7f51\u7edc\u7684\u5c42\u6570\u5f00\u6839\u53f7\u7684\u5012\u6570\u3001\u8bcd\u5178\u5927\u5c0f\u53d8\u4e3a50257\uff0c\u53e5\u5b50\u7684\u957f\u5ea6\u4ece512\u53d8\u4e3a1024\uff0cbatchsize\u53d8\u4e3a512\u3002</p> <p>Pre-LayerNorm \u53ef\u4ee5\u51cf\u5c11\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5185\u90e8\u534f\u53d8\u91cf\u504f\u79fb\uff08Internal Covariate Shift\uff09\uff0c\u4ece\u800c\u52a0\u901f\u6536\u655b\u901f\u5ea6\uff0c\u5e76\u4e14\u6709\u52a9\u4e8e\u8bad\u7ec3\u66f4\u6df1\u7684\u7f51\u7edc\u7ed3\u6784\u3002</p> <p>GPT3\u6574\u4f53\u7ed3\u6784\u548cGPT2\u57fa\u672c\u4e00\u81f4\uff0c\u6709\u4e24\u70b9\u4e0d\u540c\uff1a\uff081\uff09\u6a21\u578b\u4e2d\u7684Transformer\u91c7\u7528\u7684\u662f\u7c7b\u4f3cSparse Transformer \u7684\u7ed3\u6784\uff0c\u7528\u4ee5\u8282\u7701\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u663e\u5b58\u5360\u7528\u3002\uff082\uff09GPT3\u8bad\u7ec3\u4e868\u79cd\u53c2\u6570\u91cf\u4e0d\u540c\u7684\u6a21\u578b\uff0c\u6700\u5927\u53c2\u6570\u91cf\u4e3a175B\u3002</p> <p>\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5141\u8bb8\u67e5\u770b\u8f93\u5165\u5e8f\u5217\u4e2d\u7684\u6240\u6709\u4f4d\u7f6e\uff0c\u5176\u8ba1\u7b97\u6210\u672c\u968f\u7740\u5e8f\u5217\u957f\u5ea6\u7684\u589e\u52a0\u800c\u5448\u4e8c\u6b21\u65b9\u589e\u957f\uff0c\u4ece\u800c\u9650\u5236\u4e86\u6a21\u578b\u5904\u7406\u957f\u5e8f\u5217\u7684\u80fd\u529b\u3002Sparse Transformer \u53ef\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff1a</p> <p>\uff081\uff09\u5206\u5757\u6ce8\u610f\u529b\uff082\uff09\u7a00\u758f\u5168\u5c40\u6ce8\u610f\u529b\uff083\uff09\u5206\u5c42\u6ce8\u610f\u529b\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#llama","title":"LLAMA","text":"<p>\u53c2\u8003\u8d44\u6599\uff1aLLaMA v1/2\u6a21\u578b\u7ed3\u6784\u603b\u89c8</p> <p>\u53ef\u4ee5\u53d1\u73b0\u5f88\u50cfGPT\u7684\u7ed3\u6784\uff0c\u4e3b\u8981\u5206\u4e3a\uff1aAttention\u5c42\u548cMLP\u5c42\u4e24\u4e2a\u90e8\u5206\u3002\u63a5\u4e0b\u6765\u8be6\u7ec6\u4ecb\u7ecd\u5b83\u7684\u6bcf\u4e2a\u90e8\u5206\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#group-query-attention","title":"Group-Query Attention","text":"<p>\u81ea\u56de\u5f52\u6a21\u578b\u751f\u6210\u56de\u7b54\u65f6\uff0c\u9700\u8981\u524d\u9762\u751f\u6210\u7684KV\u7f13\u5b58\u8d77\u6765\uff0c\u6765\u52a0\u901f\u8ba1\u7b97\u3002\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236(MHA)\u9700\u8981\u7684\u7f13\u5b58\u91cf\u5f88\u5927\uff0cMulti-Query Attention\u6307\u51fa\u591a\u4e2a\u5934\u4e4b\u95f4\u53ef\u4ee5\u5171\u4eabKV\u5bf9\u3002Group-Query Attention\u6ca1\u6709\u50cfMQA\u4e00\u6837\u6781\u7aef\uff0c\u5c06query\u5206\u7ec4\uff0c\u7ec4\u5185\u5171\u4eabKV\uff0c\u6548\u679c\u63a5\u8fd1MHA\uff0c\u901f\u5ea6\u4e0a\u4e0eMQA\u53ef\u6bd4\u8f83\u3002</p> <p>\u4e3a\u4ec0\u4e48Q\u4e00\u5b9a\u8981\u4e0d\u540c\uff1f \u5f53\u7136\u5566\uff0c\u4e0d\u7136\u641e\u4ec0\u4e48\u591a\u5934\u6ce8\u610f\u529b\u54c8\u54c8\u54c8</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#rmsnorm","title":"RMSNorm","text":"<p>\u8be6\u7ec6\u8bf7\u53c2\u89c1\u6211\u7684\u53e6\u4e00\u4e2a blog \"Normlization\"</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#swiglu","title":"SwiGLU","text":"<p>\u53c2\u8003\u8d44\u6599\uff1a\u5927\u6a21\u578b\u57fa\u7840\uff5c\u6fc0\u6d3b\u51fd\u6570\uff5c\u4eceReLU \u5230SwiGLU</p> <p>\u611f\u89c9\u81ea\u5df1\u7684\u603b\u7ed3\u662f\u5168\u7f51\u6700\u597d\u7684 : \uff09</p> <ul> <li>ReLU &amp; GELU &amp; SiLU &amp; Swish</li> </ul> <ul> <li>GLU \u95e8\u63a7\u7ebf\u6027\u5355\u5143</li> </ul> <p>GLU\uff08Gated Linear Units\uff09\u5176\u5b9e\u4e0d\u7b97\u662f\u4e00\u79cd\u6fc0\u6d3b\u51fd\u6570\uff0c\u800c\u662f\u4e00\u79cd\u795e\u7ecf\u7f51\u7edc\u5c42\u3002\u5b83\u662f\u4e00\u4e2a\u7ebf\u6027\u53d8\u6362\u540e\u9762\u63a5\u95e8\u63a7\u673a\u5236\u7684\u7ed3\u6784\u3002\u5176\u4e2d\u95e8\u63a7\u673a\u5236\u662f\u4e00\u4e2asigmoid\u51fd\u6570\u7528\u6765\u63a7\u5236\u4fe1\u606f\u80fd\u591f\u901a\u8fc7\u591a\u5c11\u3002\u8fd9\u79cd\u673a\u5236\u53ef\u4ee5\u4f7f\u6a21\u578b\u81ea\u52a8\u5730\u9009\u62e9\u6027\u5730\u4fdd\u7559\u6216\u4e22\u5f03\u8f93\u5165\u7684\u67d0\u4e9b\u90e8\u5206\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\u548c\u6cdb\u5316\u80fd\u529b\u3002</p> <ul> <li>SwiGLU = Swish + GLU</li> </ul> <p>SwiGLU \u6574\u5408\u4e86Swish\u548cGLU\uff08\u91c7\u7528Swish\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\u7684GLU\uff09\uff0c\u4f7f\u5f97\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u81ea\u9002\u5e94\u5730\u9009\u62e9\u6027\u5730\u4fdd\u7559\u6216\u4e22\u5f03\u8f93\u5165\u7684\u67d0\u4e9b\u90e8\u5206\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\u548c\u6cdb\u5316\u80fd\u529b\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#rope","title":"RoPE","text":"<p>Llama\u548cGPT\u4f7f\u7528\u7684\u4f4d\u7f6e\u7f16\u7801\u4e0d\u540c\uff0cRoPE\u5373\u6709\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\u7684\u4f18\u52bf\uff0c\u53c8\u6709\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u7684\u4f18\u52bf\u3002\u8fd9\u4e2a\u4e0d\u540c\u4e0d\u4ec5\u4ec5\u662f\u65b9\u6cd5\u7684\u4e0d\u540c\uff0c\u800c\u66f4\u91cd\u8981\u7684\u662f\u5b9e\u73b0\u4f4d\u7f6e\u7684\u4e0d\u540c\uff01</p> <p>\u8be6\u7ec6\u8bf7\u53c2\u89c1\u6211\u7684\u53e6\u4e00\u4e2a blog \"\u4f4d\u7f6e\u7f16\u7801\"</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#glm","title":"GLM","text":""},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#motivation_1","title":"Motivation","text":"<ul> <li>autoregressive\u81ea\u56de\u5f52\u6a21\u578b\uff08AR\u6a21\u578b\uff09\uff1a\u4ee3\u8868\u4f5cGPT\uff0c\u901a\u5e38\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u751f\u6210\u5f0f\u4efb\u52a1\uff08NLG\uff09\u3002</li> <li>autoencoding\u81ea\u7f16\u7801\u6a21\u578b\uff08AE\u6a21\u578b\uff09\uff1a\u4ee3\u8868\u4f5cBERT\uff0c\u9002\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u7406\u89e3\uff08NLU\uff09\uff0c\u65e0\u6cd5\u76f4\u63a5\u7528\u4e8e\u6587\u672c\u751f\u6210\u3002</li> <li>encoder-decoder\uff08Seq2seq\u6a21\u578b\uff09\uff1a\u4ee3\u8868\u4f5cT5\uff0c\u7528\u4e8e\u6761\u4ef6\u751f\u6210\u4efb\u52a1\uff0c\u6bd4\u5982\u6587\u672c\u6458\u8981\u3001\u673a\u5668\u7ffb\u8bd1\u7b49\u3002</li> </ul> <p>GLM\u6a21\u578b\u57fa\u4e8eautoregressive blank infilling\u7684\u65b9\u6cd5\uff0c\u60f3\u8981\u7ed3\u5408\u4e0a\u8ff0\u4e09\u79cd\u9884\u8bad\u7ec3\u6a21\u578b\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#framework_1","title":"Framework","text":"<p>\u6574\u4f53\u6765\u8bf4GLM\u7684\u5728\u6a21\u578b\u67b6\u6784\u4e0a\u6ca1\u6709\u4ec0\u4e48\u521b\u65b0\uff0c\u91cd\u70b9\u5728\u4e8e\u8bad\u7ec3\u4efb\u52a1\u7684\u8bbe\u8ba1\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#method_1","title":"Method","text":""},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#_2","title":"\u81ea\u56de\u5f52\u7a7a\u767d\u586b\u5145","text":"<p>\u53ef\u4ee5\u628a\u81ea\u56de\u5f52\u7a7a\u767d\u586b\u5145\u7406\u89e3\u4e3aBERT\u7684\u63a9\u7801\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u662fGLM\u63a9\u7801\u7684\u4e0d\u662f\u4e00\u4e2a\u5355\u8bcd\u6216\u662f\u4e00\u4e2a\u5b9e\u4f53\uff0c\u800c\u662f\u4e00\u4e2a\u53e5\u5b50\u7247\u6bb5\u3002\u8fd9\u4e2a\u53e5\u5b50\u7247\u6bb5\u7684\u5177\u4f53\u5185\u5bb9\u901a\u8fc7\u81ea\u56de\u5f52\u7684\u65b9\u5f0f\u6765\u9884\u6d4b\u3002\u4e3b\u8981\u6765\u8bf4\u6709\u4e24\u4e2a\u4f18\u70b9\uff1a</p> <ul> <li>\u8fdb\u884c\u751f\u6210\u4efb\u52a1\u65f6\uff0cGLM\u53ef\u4ee5\u770b\u5230\u4e0a\u6587\u7684\u4fe1\u606f\u3002</li> <li>GLM\u9884\u6d4b\u7684Span\u7684\u957f\u5ea6\u662f\u4e0d\u56fa\u5b9a\u7684\u3002</li> </ul>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/#_3","title":"\u4e8c\u7ef4\u4f4d\u7f6e\u7f16\u7801","text":"<p>\u8fd9\u4e2a\u4e8c\u7ef4\u4f4d\u7f6e\u7f16\u7801\u6709\u7247\u6bb5\u95f4\u4f4d\u7f6e\u7f16\u7801\uff08intra-position encoding\uff09\u548c\u7247\u6bb5\u5185\u4f4d\u7f6e\u7f16\u7801\uff08inner-position encoding\uff09\u7ec4\u6210\u3002\u5177\u4f53\u6765\u8bf4\uff1aGLM\u5c06Part A\u548cPart B\u62fc\u63a5\u5230\u4e86\u4e00\u8d77\u3002\u5bf9\u4e8ePart B\u4e2d\u7684\u4e00\u4e2atoken\uff0c\u4ed6\u6709\u4e24\u4e2a\u4f4d\u7f6e\u4fe1\u606f\uff0c\u4e00\u4e2a\u662f\u5b83\u5728\u539f\u59cb\u6587\u672c\u4e2d\u7684\u4f4d\u7f6e\uff0c\u53e6\u5916\u4e00\u4e2a\u662f\u5b83\u5728\u6587\u672c\u7247\u6bb5\u4e2d\u7684\u4f4d\u7f6e\u3002\u4e3a\u4e86\u8868\u793a\u8fd9\u4e2a\u4fe1\u606f\uff0cGLM\u63d0\u51fa\u4e86\u4e8c\u7ef4\u4f4d\u7f6e\u7f16\u7801\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/","title":"PEFT \u5fae\u8c03\u603b\u7ed3","text":"<p>\u53c2\u8003\u8d44\u6599\uff1aLLM\u5fae\u8c03\u65b9\u6cd5\u603b\u7ed3 </p> <p>\u53c2\u8003\u8d44\u6599\uff1aHF:\u9ad8\u6548\u5fae\u8c03\u7bc7</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/#_1","title":"\u4ec0\u4e48\u65f6\u5019\u9700\u8981\u5fae\u8c03\uff1f","text":"<p>\u53c2\u8003\u8d44\u6599\uff1a\u63d0\u793a\u8bcd\u3001RAG\u3001\u5fae\u8c03\u54ea\u4e2a\u4f1a\u8ba9\u5927\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff1f</p> <p>RAG\uff08Retrieval-Augmented Generation\uff09\u80fd\u591f\u5f88\u597d\u7684\u589e\u52a0\u5927\u6a21\u578b\u7684\u77e5\u8bc6\u50a8\u5907\uff0c\u5176\u7ed3\u5408\u4e86\u68c0\u7d22\u548c\u751f\u6210\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u68c0\u7d22\u6a21\u5757\u4ece\u6587\u672c\u8bed\u6599\u5e93\u4e2d\u68c0\u7d22\u4e0e\u5f53\u524d\u8f93\u5165\u76f8\u5173\u7684\u4fe1\u606f\uff0c\u751f\u6210\u6a21\u5757\u5229\u7528\u68c0\u7d22\u5230\u7684\u4fe1\u606f\u4f5c\u4e3a\u4e0a\u4e0b\u6587\uff0c\u751f\u6210\u4e0e\u5f53\u524d\u4efb\u52a1\u76f8\u5173\u7684\u6587\u672c\u3002</p> <p>RAG\u80fd\u62d3\u5bbd\u6a21\u578b\u7684\u77e5\u8bc6\uff0cTuning\u80fd\u589e\u52a0\u6a21\u578b\u7684\u80fd\u529b\uff0cPrompt\u517c\u5177\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/#_2","title":"\u5fae\u8c03\u6982\u8ff0","text":""},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/#_3","title":"\u5fae\u8c03\u65b9\u6cd5\u5206\u7c7b","text":"<p>\u53c2\u8003\u6587\u732e\uff1aScaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning</p> <p>\u4e3b\u8981\u53ef\u4ee5\u5206\u4e3aAdditive\u3001Selective\u3001Reparametrization\u4e09\u79cd\u7c7b\u578b\uff0c\u5373\u589e\u91cf\u3001\u9009\u62e9\u3001\u91cd\u53c2\u6570\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/#_4","title":"\u5fae\u8c03\u4e2d\u7684\u5185\u5b58\u5360\u7528","text":"<p>\u5bf9\u4e8e\u6a21\u578b\u800c\u8a00\uff0c1B\u7684\u53c2\u6570\u91cf\u7ea6\u7b49\u4e8e4GB\u5185\u5b58\u5360\u7528\u3002\u800c\u7136\u9664\u4e86\u6a21\u578b\u672c\u8eab\u5360\u7528\u5185\u5b58\u4e4b\u5916\u8fd8\u6709\uff1a</p> <ul> <li>\u53c2\u6570\u7684\u68af\u5ea6\u5360\u7528\u5185\u5b58\u7ea6\u7b49\u4e8e1\u4e2a\u6a21\u578b\u672c\u8eab\u5360\u7528\u7684\u5185\u5b58</li> <li>\u4f18\u5316\u5668\u5360\u7528\u5185\u5b58\u7ea6\u7b49\u4e8e1~2\u4e2a\u6a21\u578b\u672c\u8eab\u5360\u7528\u7684\u5185\u5b58</li> </ul> <p>SGD:\u5728\u6bcf\u4e2a\u53c2\u6570\u4e0a\u7ef4\u62a4\u4e00\u4e2a\u52a8\u91cf\u5411\u91cf\uff0c\u5176\u5927\u5c0f\u4e0e\u6a21\u578b\u53c2\u6570\u76f8\u540c\u3002</p> <p>Adam:\u7ef4\u62a4\u4e00\u9636\u77e9\u4f30\u8ba1\uff08\u52a8\u91cf\u9879\uff09\u548c\u4e8c\u9636\u77e9\u4f30\u8ba1\uff08\u52a8\u91cf\u5e73\u65b9\uff09\u6bcf\u4e2a\u72b6\u6001\u90fd\u4e0e\u6a21\u578b\u53c2\u6570\u76f8\u540c\u3002</p> <p>PEFT\uff08Parameter-Efficient Fine-Tuning\uff09\u662f\u4e00\u79cd\u9488\u5bf9\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u9ad8\u6548\u5fae\u8c03\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u7684\u964d\u4f4e\u8ba1\u7b97\u8d44\u6e90\u548c\u5b58\u50a8\u7a7a\u95f4\uff0c\u901a\u5e38\u8bad\u7ec3\u7684\u53c2\u6570\u91cf\u4e0d\u8db3\u5168\u90e8\u76841%\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/#bitfit","title":"BitFit \u65b9\u6cd5","text":"<p>BitFit \u901a\u8fc7\u53ea\u8c03\u6574\u6a21\u578b\u4e2d\u7684\u504f\u7f6e\uff08bias\uff09\u53c2\u6570\uff0c\u800c\u4fdd\u6301\u6743\u91cd\uff08weights\uff09\u53c2\u6570\u4e0d\u53d8\uff0c\u4ece\u800c\u663e\u8457\u51cf\u5c11\u5fae\u8c03\u6240\u9700\u7684\u53c2\u6570\u91cf\u548c\u8ba1\u7b97\u8d44\u6e90\u3002\u8fd9\u79cd\u65b9\u6cd5\u7684\u80cc\u540e\u52a8\u673a\u662f\uff0c\u504f\u7f6e\u9879\u867d\u7136\u53c2\u6570\u91cf\u5c0f\uff0c\u4f46\u5bf9\u6a21\u578b\u7684\u8f93\u51fa\u6709\u663e\u8457\u5f71\u54cd\uff0c\u56e0\u6b64\u53ea\u8c03\u6574\u504f\u7f6e\u9879\u53ef\u4ee5\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\uff0c\u51cf\u5c11\u8bad\u7ec3\u53c2\u6570\u91cf\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/#p-tuning","title":"P-tuning \u65b9\u6cd5","text":""},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/#prefix-tuning","title":"Prefix-tuning","text":"<p>Prefix-Tuning\u7684\u601d\u60f3\uff1a\u76f8\u8f83\u4e8ePrompt-Tuning\u548cP-tuning,Prefix-Tuning\u4e0d\u518d\u5c06Prompt\u52a0\u5728\u8f93\u5165 \u7684Embedding\u5c42\uff0c\u800c\u662f\u5c06\u5176\u4f5c\u4e3a\u53ef\u5b66\u4e60\u7684\u524d\u7f00\uff0c\u653e\u7f6e\u5728Transformer\u6a21\u578b\u4e2d\u7684\u6bcf\u4e00\u5c42\u4e2d\uff0c\u5177\u4f53\u8868\u73b0\u5f62 \u5f0f\u4e3apast_key_values\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/#prompt-tuning","title":"Prompt-tuning","text":"<p>Prompt-tuning\u7ed9\u6bcf\u4e2a\u4efb\u52a1\u90fd\u5b9a\u4e49\u4e86\u81ea\u5df1\u7684Prompt\uff0c\u62fc\u63a5\u5230\u6570\u636e\u4e0a\u4f5c\u4e3a\u8f93\u51fa\uff0c\u4f46\u53ea\u5728\u8f93\u5165\u5c42\u52a0\u5165prompt tokens\uff0c\u7136\u540e\u591a\u4efb\u52a1\u6df7\u5408\u8bad\u7ec3\u3002\u8fd9\u4e2aprompt\u53ef\u4ee5\u88ab\u968f\u673a\u6216\u6307\u5b9a\u521d\u59cb\u5316\u7136\u540e\u8bad\u7ec3\u3002</p> <p>\u6548\u679c\u8868\u73b0\u975e\u5e38\u597d\uff01\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5176\u4e2d\u7684prompt design\u662f\u6307\u7ed9\u660e\u786e\u4efb\u52a1\u7684Prompt\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/#p-tuning-v1","title":"P-tuning v1","text":"<p>\u7b80\u5355\u6765\u8bf4\uff0c\u5c31\u662f\u5c06Prompt-tuning\u4e2d\u7684pre-tokens\u7ecf\u8fc7MLP\u6216LSTM\u518d\u4f20\u9012\u5230\u6a21\u578b\u4e2d\u3002</p> <p>\u8be5\u65b9\u6cd5\u7684\u6838\u5fc3\u662f\u4f7f\u7528\u53ef\u5fae\u7684virtual token\u66ff\u6362\u4e86\u539f\u6765\u7684discrete tokens\uff0c\u4e14\u4ec5\u52a0\u5165\u5230\u8f93\u5165\u5c42\uff0c\u5e76\u4f7f\u7528prompt encoder (BiLSTM+MLP) \u5bf9virtual token\u8fdb\u884c\u7f16\u7801\u5b66\u4e60\u3002\u6548\u679c\uff1a\u76f8\u540c\u53c2\u6570\u89c4\u6a21\uff0c\u5982\u679c\u8fdb\u884c\u5168\u53c2\u6570\u5fae\u8c03\uff0cBert\u5728NLU\u4efb\u52a1\u4e0a\u7684\u6548\u679c\uff0c\u8d85\u8fc7GPT\u5f88\u591a\uff1b\u4f46\u662f\u5728P.Tuning\u4e0b\uff0cGPT\u53ef\u4ee5\u53d6\u5f97\u8d85\u8d8aBert\u7684\u6548\u679c\u3002</p> <p>\u8be5\u65b9\u6cd5\u6709\u4e00\u4e9b\u4e0d\u8db3\uff0c\u6574\u7406\u5982\u4e0b\uff1a</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/#p-tuning-v2","title":"P-tuning v2","text":"<p>P-Tuning v2\u4e3b\u8981\u662f\u57fa\u4e8eP-tuning\u548cprefix-tuning\u6280\u672f\uff0c\u5f15\u5165Deep Prompt Encoding\u548cMulti-task Learning\u7b49\u7b56\u7565\u8fdb\u884c\u4f18\u5316\u3002P-Tuning v2\u662f\u4e00\u79cd\u5728\u4e0d\u540c\u89c4\u6a21\u548c\u4efb\u52a1\u4e2d\u90fd\u53ef\u4e0e\u5fae\u8c03\u76f8\u5ab2\u7f8e\u7684\u63d0\u793a\u65b9\u6cd5\uff0c\u4ece330M\u523010B\u7684\u6a21\u578b\u663e\u793a\u51fa\u4e00\u81f4\u7684\u6539\u8fdb\uff0c\u5e76\u5728\u5e8f\u5217\u6807\u6ce8\u7b49\u56f0\u96be\u7684\u5e8f\u5217\u4efb\u52a1\u4e0a\u4ee5\u5f88\u5927\u7684\u5e45\u5ea6\u8d85\u8fc7\u4e86Prompt Tuning\u548cP-Tuning\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/#deep-prompt-encoding","title":"Deep Prompt Encoding","text":""},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/#multi-task-learning","title":"Multi-task Learning","text":"<p>\u57fa\u4e8e\u591a\u4efb\u52a1\u6570\u636e\u96c6\u7684Prompt\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u518d\u9002\u914d\u5230\u4e0b\u6e38\u4efb\u52a1\u3002\u5bf9\u4e8epseudo token\u7684continous prompt,\u968f\u673a\u521d\u59cb\u5316\u6bd4\u8f83\u96be\u4ee5\u4f18\u5316\uff0c\u56e0\u6b64\u91c7\u7528multi-task\u65b9\u6cd5\u540c\u65f6\u8bad\u7ec3\u591a\u4e2a\u6570\u636e\u96c6\uff0c\u5171\u4eabcontinuous prompts:\u53bb\u8fdb\u884c\u591a\u4efb\u52a1\u9884\u8bad\u7ec3\uff0c\u53ef\u4ee5\u8ba9prompt\u6709\u6bd4\u8f83\u597d\u7684\u521d\u59cb\u5316\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/#lora","title":"LoRA \u65b9\u6cd5","text":"<p>\u601d\u60f3\u6bd4\u8f83\u7b80\u5355\uff0c\u5f15\u5165\u4f4e\u79e9\u77e9\u9635\u6765\u8fdb\u884c\u5fae\u8c03\uff0c\u8fd9\u91cc\u4e0d\u591a\u4ecb\u7ecd\uff0c\u53ef\u4ee5\u4f7f\u7528PREF\u5e93\u5b9e\u73b0\u3002</p>"},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/#qlora","title":"Qlora \u65b9\u6cd5","text":""},{"location":"%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/#ia3","title":"IA3","text":"<p>IA3\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5411\u91cf\u5bf9\u6fc0\u6d3b\u503c\u8fdb\u884c\u6291\u5236\u6216\u653e\u5927\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u4f1a\u5bf9K\u3001V\u3001FFN\u4e09\u90e8\u5206\u7684\u503c\u8fdb\u884c\u8c03\u6574\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u540c\u6837\u51bb\u7ed3\u539f\u59cb\u6a21\u578b\u7684\u6743\u91cd\uff0c\u53ea\u66f4\u65b0\u53ef\u5b66\u4e60\u7684\u90e8\u5206\u5411\u91cf\u90e8\u5206\u3002\u8bad\u7ec3\u5b8c\u6210\u540e\uff0c\u4e0eLor\u7c7b\u4f3c\uff0c\u4e5f\u53ef\u4ee5\u5c06\u5b66\u4e60\u90e8\u5206\u7684\u53c2\u6570\u4e0e\u539f\u59cb\u6743\u91cd\u5408\u5e76\uff0c\u6ca1\u6709\u989d\u5916\u63a8\u7406\u5f00\u9500\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Activation/","title":"\u6fc0\u6d3b\u51fd\u6570","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Activation/#_2","title":"\u5e38\u89c1\u6fc0\u6d3b\u51fd\u6570","text":"<p>sigmoid: $$f(x)=\\frac{1}{1+e^{-x}}$$ Swish: $$f(x)=x\\cdot sigmoid(\\beta x)$$</p> <p>Swish \u5e73\u6ed1\u4e14\u975e\u5355\u8c03\u3002\u5b83\u5728\u8d1f\u503c\u533a\u57df\u4e0d\u4f1a\u50cf ReLU \u90a3\u6837\u76f4\u63a5\u5207\u65ad\u68af\u5ea6\uff0c\u800c\u662f\u9010\u6e10\u51cf\u5c0f\u3002\u8fd9\u79cd\u5e73\u6ed1\u7279\u6027\u6709\u52a9\u4e8e\u68af\u5ea6\u6d41\u52a8\uff0c\u7279\u522b\u662f\u5728\u6df1\u5c42\u7f51\u7edc\u4e2d\uff0c\u53ef\u4ee5\u7f13\u89e3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Activation/#_3","title":"\u601d\u8003","text":"<p>\u4e3a\u4ec0\u4e48\u4f7f\u7528relu\u6fc0\u6d3b\u51fd\u6570\u800c\u4e0d\u662fsigmoid\u6fc0\u6d3b\u51fd\u6570\uff1f</p> <ol> <li>\u5728\u524d\u5411\u4f20\u64ad\u548c\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\uff0cReLU\u76f8\u6bd4\u4e8eSigmoid\u7b49\u6fc0\u6d3b\u51fd\u6570\u8ba1\u7b97\u91cf\u5c0f\uff1a</li> <li>\u5728\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\uff0cS\u5f15goid\u51fd\u6570\u5b58\u5728\u9971\u548c\u533a\uff0c\u82e5\u6fc0\u6d3b\u503c\u8fdb\u5165\u9971\u548c\u533a\uff0c\u5219\u5176\u68af\u5ea6\u66f4\u65b0\u503c\u975e\u5e38\u5c0f\uff0c\u5bfc\u81f4\u51fa\u73b0\u68af\u5ea6\u6d88\u5931\u7684\u73b0\u8c61\u3002\u800cRLU\u8bbe\u6709\u9971\u548c\u533a\uff0c\u53ef\u907f\u514d\u6b64\u95ee\u9898\uff1a</li> <li>RLU\u53ef\u4ee4\u90e8\u5206\u795e\u7ecf\u5143\u8f93\u51fa\u4e3a0\uff0c\u9020\u6210\u7f51\u7edc\u7684\u7a00\u758f\u6027\uff0c\u51cf\u5c11\u524d\u540e\u5c42\u53c2\u6570\u5bf9\u5f53\u524d\u5c42\u53c2\u6570\u7684\u5f71\u54cd\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u6027\u80fd\uff1a</li> </ol>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Datasets/","title":"Datasets","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Datasets/#_1","title":"\u4f7f\u7528\u6570\u636e\u96c6","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Datasets/#_2","title":"\u67e5\u770b\u6570\u636e\u96c6\u4fe1\u606f","text":"<p>\u53c2\u8003\u8d44\u6599\uff1aDatasetInfo</p> <ul> <li>\u67e5\u770b\u4e00\u4e9b\u901a\u7528\u4fe1\u606f</li> </ul> <pre><code>from datasets import load_dataset_builder\nds_builder = load_dataset_builder(\"rotten_tomatoes\")\n\nprint(ds_builder.info.description)     # \u63cf\u8ff0\nprint(ds_builder.info.features)        # \u7279\u5f81(X,y)\nprint(ds_builder.info.dataset_size)    # \u6570\u636e\u96c6\u5927\u5c0f\n</code></pre> <ul> <li>\u67e5\u770b\u4e00\u4e9b\u8bad\u7ec3\u4fe1\u606f</li> </ul> <pre><code>from datasets import get_dataset_split_names\nget_dataset_split_names(\"rotten_tomatoes\") # ['train', 'validation', 'test']\n</code></pre> <ul> <li>\u67e5\u770b\u4e00\u4e9b\u914d\u7f6e\u4fe1\u606f</li> </ul> <p>\u90e8\u5206\u6570\u636e\u96c6\u662f\u6709\u914d\u7f6e\u4fe1\u606f\u7684\uff0c\u5373\u8be5\u6570\u636e\u96c6\u4e0b\u9762\u6709\u4e00\u5806\u6570\u636e\u5b50\u96c6</p> <pre><code>from datasets import get_dataset_config_names\nconfigs = get_dataset_config_names(\"PolyAI/minds14\")\nprint(configs)\n# ['cs-CZ', 'de-DE', 'en-AU', 'en-GB', 'en-US', 'es-ES', 'fr-FR', 'it-IT', 'ko-KR', 'nl-NL', 'pl-PL', 'pt-PT', 'ru-RU', 'zh-CN', 'all']\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Datasets/#_3","title":"\u8bfb\u53d6\u6570\u636e\u96c6","text":"<pre><code>from datasets import load_dataset\n\ndataset = load_dataset(\"rotten_tomatoes\")\ndataset = load_dataset(\"rotten_tomatoes\", split=\"train\")\nprint(dataset)\n\n# Dataset({\n#     features: ['text', 'label'],\n#     num_rows: 8530\n# })\n\nmindsFR = load_dataset(\"PolyAI/minds14\", \"fr-FR\", split=\"train\") \n# \u6709\u914d\u7f6e\u4fe1\u606f\u7684\u4e00\u5b9a\u8981\u8f93\u5165\u914d\u7f6e\u4fe1\u606f\uff0c\u5426\u5219\u62a5\u9519\n\n</code></pre> <p>\u6709\u4e9b\u6570\u636e\u96c6\u975e\u5e38\u5e9e\u5927\uff0c\u53ef\u4ee5\u9009\u62e9\u52a0\u8f7d\u90e8\u5206\u6570\u636e</p> <pre><code>dataset = load_dataset(\"food101\", split=\"train[:100]\")\n\n</code></pre> <p>\u90e8\u5206\u6570\u636e\u96c6\u9700\u8981\u53c2\u6570\u6765\u6267\u884c\u811a\u672c\uff1atrust_remote_code=True</p> <pre><code>c4 = load_dataset(\"c4\", \"en\", split=\"train\", trust_remote_code=True)\nget_dataset_config_names(\"c4\", trust_remote_code=True)\nget_dataset_split_names(\"c4\", \"en\", trust_remote_code=True)\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Datasets/#_4","title":"\u5904\u7406\u6570\u636e\u96c6","text":"<ul> <li>\u7d22\u5f15\u548c\u5207\u7247</li> </ul> <pre><code>dataset[0][\"text\"] # \u524d\u884c\u540e\u5217\uff0c\u4e5f\u53ef\u4ee5\u5355\u72ec\u8f93\u5165\u884c\u6216\u8005\u5355\u72ec\u8f93\u5165\u5217\u6807\u7b7e\ndataset[3:6] # \u884c\u5207\u7247\n</code></pre> <ul> <li>\u9884\u5904\u7406</li> </ul> <p>\u5b98\u65b9\u53c2\u8003\u6587\u6863\uff1a\u6570\u636e\u96c6\u9884\u5904\u7406</p> <pre><code>- \u5bf9\u4e8e\u6587\u672c\uff0c\u4f7f\u7528\u5206\u8bcd\u5668(Tokenizer)\u5c06\u6587\u672c\u8f6c\u6362\u4e3a\u4e00\u7cfb\u5217\u6807\u8bb0(tokens)\uff0c\u5e76\u521b\u5efatokens\u7684\u6570\u5b57\u8868\u793a\uff0c\u5c06\u5b83\u4eec\u7ec4\u5408\u6210\u5f20\u91cf\u3002\n- \u5bf9\u4e8e\u8bed\u97f3\u548c\u97f3\u9891\uff0c\u4f7f\u7528\u7279\u5f81\u63d0\u53d6\u5668(Feature extractor)\u4ece\u97f3\u9891\u6ce2\u5f62\u4e2d\u63d0\u53d6\u987a\u5e8f\u7279\u5f81\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u5f20\u91cf\u3002\n- \u56fe\u50cf\u8f93\u5165\u4f7f\u7528\u56fe\u50cf\u5904\u7406\u5668(ImageProcessor)\u5c06\u56fe\u50cf\u8f6c\u6362\u4e3a\u5f20\u91cf\u3002\n- \u591a\u6a21\u6001\u8f93\u5165\uff0c\u4f7f\u7528\u5904\u7406\u5668(Processor)\u7ed3\u5408\u4e86Tokenizer\u548cImageProcessor\u6216Processor\u3002\n</code></pre> <p>\uff081\uff09\u97f3\u9891\u6570\u636e\u9884\u5904\u7406</p> <pre><code>from datasets import load_dataset, Audio\ndataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n\n# step1: \u91cd\u91c7\u6837\uff0c\u67e5\u770b\u97f3\u9891\u6a21\u578b\u4fe1\u606f\u51b3\u5b9a\u91c7\u6837\u91cf\n\ndataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16_000)) \ndataset[0][\"audio\"] \n# \u6bcf\u6b21\u8c03\u7528audio\u5217\u90fd\u4f1a\u81ea\u52a8\u52a0\u8f7d\u548c\u91cd\u65b0\u91c7\u6837\u97f3\u9891\u6587\u4ef6\n# {'array': array([ XXX ], dtype=float32),'path': 'XXX.wav','sampling_rate': 16000}\n\n# step2: \u7279\u5f81\u63d0\u53d6\n\nfrom transformers import AutoFeatureExtractor\nfeature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n# \u5355\u6761\u5904\u7406\naudio_input = [dataset[0][\"audio\"][\"array\"]]\nfeature_extractor(audio_input, sampling_rate=16000)\n# \u6279\u5904\u7406\naudio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\ninputs = feature_extractor(\n    audio_arrays,\n    sampling_rate=16000,\n    padding=True,\n    max_length=100000,\n    truncation=True,\n)\n</code></pre> <p>\uff082\uff09\u6587\u672c\u6570\u636e\u9884\u5904\u7406</p> <pre><code>from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n\n# \u81ea\u5b9a\u4e49\u6570\u636e\u7684\u5355\u6761\u5904\u7406\uff08\u7f16\u7801\u4e0e\u89e3\u7801\uff09\nencoded_input = tokenizer(\"Do ...\")\n# {'input_ids': [...],       # \u6bcf\u4e2atoken\u5bf9\u5e94\u7684\u7d22\u5f15\n#  'token_type_ids': [...],  # \u5b58\u5728\u591a\u4e2a\u5e8f\u5217\u65f6\u6807\u8bc6\u4e00\u4e2atoken\u5c5e\u4e8e\u54ea\u4e2a\u5e8f\u5217\n#  'attention_mask': [...]}  # \u662f\u5426\u5e94\u8be5\u5173\u6ce8\u4e00\u4e2atoken\ntokenizer.decode(encoded_input[\"input_ids\"]) \n# '[CLS] Do ... [SEP]'\n\n# \u81ea\u5b9a\u4e49\u6570\u636e\u7684\u6279\u5904\u7406\nbatch_sentences = [\n    \"But what about second breakfast?\",\n    \"Don't think he knows about second breakfast, Pip.\",\n    \"What about elevensies?\",\n]\nencoded_inputs = tokenizer(batch_sentences, \n                padding=True, truncation=True, return_tensors=\"pt\")\n\n# \u6570\u636e\u96c6\u9884\u5904\u7406\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n</code></pre> <p>\uff083\uff09\u56fe\u50cf\u6570\u636e\u9884\u5904\u7406</p> <pre><code>from transformers import AutoImageProcessor\nimage_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n\n# \u56fe\u50cf\u589e\u5f3a\n# ...\u76ee\u524d\u6ca1\u6709\u7528\u5230\uff0c\u53ef\u4ee5\u4e4b\u540e\u518d\u770b\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Diffusers/","title":"Diffusers \ud83e\udd17","text":"<p>\u53c2\u8003\u94fe\u63a5\uff1aDiffusers \u5b98\u65b9\u6587\u6863</p> <p>\u65e0\u8bba\u662f\u5728\u5bfb\u627e\u7b80\u5355\u7684\u63a8\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u8fd8\u662f\u60f3\u8bad\u7ec3\u81ea\u5df1\u7684\u6269\u6563\u6a21\u578b\uff0cDiffusers \u90fd\u662f\u4e00\u4e2a\u503c\u5f97\u9996\u9009\u7684\u6700\u5148\u8fdb\u7684\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u5e93\uff08\u751f\u6210\u56fe\u50cf\u3001\u97f3\u9891\u751a\u81f3 3D \u5206\u5b50\u7ed3\u6784\uff09\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Diffusers/#_1","title":"\u5feb\u901f\u4f7f\u7528","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Diffusers/#_2","title":"\u73af\u5883\u5b89\u88c5","text":"<pre><code># \u5148\u5b89\u88c5pytorch\uff0c\u7136\u540e\u6267\u884c\u4e0b\u9762\u7684\u6307\u4ee4\n# \u5176\u4e2d Accelerate \u5728\u63a8\u7406\u548c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a0\u901f\u6a21\u578b\u52a0\u8f7d\npip install diffusers[\"torch\"] accelerate transformers\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Diffusers/#_3","title":"\u4ee3\u7801\u793a\u4f8b","text":"<p>\u4ee3\u7801\u5176\u5b9e\u975e\u5e38\u7b80\u5355\uff0c\u6838\u5fc3\u90e8\u4ef6\u53ea\u6709\u4e24\u4e2a\uff1amodel\u548cscheduler\u3002</p> <pre><code>from diffusers import DDPMScheduler, UNet2DModel\nimport torch\nfrom PIL import Image\nimport numpy as np\n\n# \uff081\uff09\u52a0\u8f7d\u6a21\u578b\u548c\u8c03\u5ea6\u5668\nscheduler = DDPMScheduler.from_pretrained(\"google/ddpm-cat-256\")\nmodel = UNet2DModel.from_pretrained(\"google/ddpm-cat-256\", use_safetensors=True).to(\"cuda\")\n\n# \uff082\uff09\u8bbe\u7f6e\u8c03\u5ea6\u5668\u53c2\u6570\u4e4b\u6b65\u6570\nscheduler.set_timesteps(50)\nscheduler.timesteps\n\n# \uff083\uff09\u968f\u673a\u91c7\u6837\u4e00\u4e2a\u566a\u58f0\u4f5c\u4e3a\u521d\u59cb\u566a\u58f0\nsample_size = model.config.sample_size\nnoise = torch.randn((1, 3, sample_size, sample_size), device=\"cuda\")\ninput = noise\n\n# \uff084\uff09\u8fed\u4ee3\u53bb\u566a\nfor t in scheduler.timesteps:\n    with torch.no_grad():\n        noisy_residual = model(input, t).sample\n    previous_noisy_sample = scheduler.step(noisy_residual, t, input).prev_sample\n    input = previous_noisy_sample\n\n# \uff085\uff09\u5c06\u56fe\u50cf\u8fd8\u539f\nimage = (input / 2 + 0.5).clamp(0, 1).squeeze() \n# \u5c06\u50cf\u7d20\u503c\u4ece\u8303\u56f4[-1, 1]\u6620\u5c04\u5230[0, 1]\u4e4b\u95f4\nimage = (image.permute(1, 2, 0) * 255).round().to(torch.uint8).cpu().numpy()\n# \u4f7f\u5f97\u56fe\u50cf\u7684\u5f62\u72b6\u53d8\u4e3a(height, width, channels)\nimage = Image.fromarray(image)\n# \u4f7f\u7528NumPy\u6570\u7ec4\u521b\u5efa\u4e00\u4e2aPIL\u56fe\u50cf\u5bf9\u8c61\n\nimage\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Diffusers/#_4","title":"\u56db\u884c\u4ee3\u7801\u641e\u5b9a","text":"<pre><code>from diffusers import DDPMPipeline\nddpm = DDPMPipeline.from_pretrained(\"google/ddpm-cat-256\", use_safetensors=True).to(\"cuda\")\nimage = ddpm(num_inference_steps=25).images[0]\nimage\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Diffusers/#_5","title":"\u8be6\u7ec6\u4ecb\u7ecd","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Diffusers/#_6","title":"\u52a0\u8f7d\u6a21\u578b\u548c\u8c03\u5ea6\u5668","text":"<p>\u8fd9\u91cc\u5c06\u66f4\u52a0\u7ec6\u81f4\uff0cmodel\u5176\u5b9e\u5206\u4e3a\u56db\u4e2a\u90e8\u5206\uff1avae\u3001tokenizer\u3001text_encoder\u3001unet\u3002\u5b9e\u9645\u4e0a\u6211\u4eec\u53ea\u7528\u5230\u4e86vae\u7684\u89e3\u7801\u90e8\u5206\uff0c\u81f3\u4e8e\u5176\u7f16\u7801\u90e8\u5206\u662f\u7528\u4e0d\u5230\u7684\u3002</p> <pre><code>from PIL import Image\nimport torch\nfrom transformers import CLIPTextModel, CLIPTokenizer\nfrom diffusers import AutoencoderKL, UNet2DConditionModel, PNDMScheduler\nfrom diffusers import UniPCMultistepScheduler\nfrom tqdm.auto import tqdm\n\nvae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\", use_safetensors=True)\ntokenizer = CLIPTokenizer.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"tokenizer\")\ntext_encoder = CLIPTextModel.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\", subfolder=\"text_encoder\", use_safetensors=True\n)\nunet = UNet2DConditionModel.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\", subfolder=\"unet\", use_safetensors=True\n)\nscheduler = UniPCMultistepScheduler.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"scheduler\")\n\ntorch_device = \"cuda\"\nvae.to(torch_device)\ntext_encoder.to(torch_device)\nunet.to(torch_device)\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Diffusers/#_7","title":"\u751f\u6210\u63a7\u5236\u6761\u4ef6","text":"<pre><code>prompt = [\"a photograph of an astronaut riding a horse\"]\ngenerator = torch.manual_seed(0)  \n\n# \u751f\u6210\u6587\u672c\u6761\u4ef6\ntext_input = tokenizer(\n    prompt, padding=\"max_length\", max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\"\n)\nwith torch.no_grad():\n    text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[0]\n\n# \u751f\u6210\u7a7a\u6761\u4ef6\uff08\u548c\u6587\u672c\u6761\u4ef6\u7ef4\u5ea6\u4e00\u81f4\uff09\nmax_length = text_input.input_ids.shape[-1]\nbatch_size = len(prompt)\nuncond_input = tokenizer([\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\")\nuncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0]\n\n# \u6761\u4ef6\u62fc\u63a5\ntext_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Diffusers/#_8","title":"\u521d\u59cb\u5316\u566a\u58f0","text":"<pre><code>height = 512  # default height of Stable Diffusion\nwidth = 512  # default width of Stable Diffusion\ngenerator = torch.manual_seed(0)\nlatents = torch.randn(\n    (batch_size, unet.config.in_channels, height // 8, width // 8), # B C H W\n    generator=generator, # \u6307\u5b9a\u4e86\u751f\u6210\u968f\u673a\u6570\u6240\u4f7f\u7528\u7684\u968f\u673a\u6570\u751f\u6210\u5668\uff0c\u65b9\u4fbf\u590d\u73b0\n    device=torch_device,\n)\nlatents = latents * scheduler.init_noise_sigma # \u8fd9\u4e2ascheduler\u7684\u9700\u8981\u7684\u8bbe\u7f6e\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Diffusers/#_9","title":"\u8fed\u4ee3\u53bb\u566a","text":"<pre><code>\nnum_inference_steps = 25\nguidance_scale = 7.5  \nscheduler.set_timesteps(num_inference_steps)\n\nfor t in tqdm(scheduler.timesteps):\n\n    # doing classifier-free guidance to avoid doing two forward passes.\n    latent_model_input = torch.cat([latents] * 2)\n    latent_model_input = scheduler.scale_model_input(latent_model_input, timestep=t)\n\n    # predict the noise residual\n    with torch.no_grad():\n        noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n\n    # \u6761\u4ef6\u5f15\u5bfc\n    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n\n    # \u66f4\u65b0 latents: x_t -&gt; x_t-1\n    latents = scheduler.step(noise_pred, t, latents).prev_sample\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Diffusers/#_10","title":"\u5c06\u56fe\u50cf\u8fd8\u539f","text":"<pre><code># scale and decode the image latents with vae\nlatents = 1 / 0.18215 * latents\nwith torch.no_grad():\n    image = vae.decode(latents).sample\n\nimage = (image / 2 + 0.5).clamp(0, 1).squeeze()\nimage = (image.permute(1, 2, 0) * 255).to(torch.uint8).cpu().numpy()\nimage = Image.fromarray(image)\nimage\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Diffusers/#diffusion","title":"\u8bad\u7ec3\u4e00\u4e2aDiffusion\u6a21\u578b","text":"<p>\u53c2\u8003\u94fe\u63a5\uff1aTrain a diffusion model</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Normalization/","title":"Normalization","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Normalization/#_1","title":"\u6982\u8981","text":"<p>\u53c2\u8003\u8d44\u65991\uff1a\u4e94\u79cd\u5f52\u4e00\u5316\u7684\u539f\u7406\u4e0ePyTorch\u9010\u884c\u624b\u5199\u5b9e\u73b0\u8bb2\u89e3</p> <p>\u53c2\u8003\u8d44\u65992\uff1aNormalization\u5f52\u4e00\u5316</p> <p>N (Batch size)\uff1a\u6279\u91cf\u5927\u5c0f\uff0cH (Height)\uff1a\u9ad8\u5ea6\uff0cW (Width)\uff1a\u5bbd\u5ea6\uff0cC (Channels)\uff1a\u901a\u9053\u6570</p> <p>\u76f4\u89c2\u7684\u6765\u8bf4\uff0cBatch Norm: \u5728\u6bcf\u4e2a\u6279\u6b21\u5185\u5bf9\u6279\u6570\u636e\u7684\u6bcf\u4e2a\u901a\u9053\u8fdb\u884c\u5f52\u4e00\u5316\u7684\u65b9\u6cd5\u3002\u4e00\u822c\u7528\u4e8e\u56fe\u50cf\u9886\u57df\uff0c\u800c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u4e0d\u9002\u7528\uff0c\u539f\u56e0\u662f\u6bcf\u4e2a\u6837\u672c\u7684\u957f\u5ea6\u4e0d\u540c\u3002Layer Norm: \u5728\u5355\u4e2a\u6570\u636e\u6837\u672c\u7684\u6240\u6709\u901a\u9053\u4e0a\u8fdb\u884c\u64cd\u4f5c\u7684\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u6570\u636e\u6837\u672c\uff0c\u5b83\u8ba1\u7b97\u6240\u6709\u901a\u9053\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u5e76\u8fdb\u884c\u5f52\u4e00\u5316\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Normalization/#motivation","title":"Motivation","text":"<p>Internal Covariate shift\uff1a\u5728\u6df1\u5ea6\u7f51\u7edc\u4e2d\uff0c\u6bcf\u5c42\u7684\u8f93\u5165\u4f9d\u8d56\u4e8e\u524d\u4e00\u5c42\u7684\u53c2\u6570\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u7531\u4e8e\u6bcf\u5c42\u53c2\u6570\u7684\u66f4\u65b0\uff0c\u524d\u4e00\u5c42\u7684\u8f93\u51fa\uff08\u5373\u540e\u4e00\u5c42\u7684\u8f93\u5165\uff09\u5206\u5e03\u4f1a\u53d1\u751f\u53d8\u5316\u3002\u8fd9\u79cd\u73b0\u8c61\u79f0\u4e3a\u5185\u90e8\u534f\u53d8\u91cf\u504f\u79fb\uff0c\u5b83\u53ef\u80fd\u5bfc\u81f4\u7f51\u7edc\u7684\u6536\u655b\u53d8\u6162\uff0c\u56e0\u4e3a\u6bcf\u5c42\u90fd\u5fc5\u987b\u4e0d\u65ad\u9002\u5e94\u5176\u8f93\u5165\u5206\u5e03\u7684\u53d8\u5316\u3002</p> <p>\u901a\u8fc7\u5728\u6bcf\u6b21\u8bad\u7ec3\u8fed\u4ee3\u4e2d\u5bf9\u6bcf\u4e00\u5c42\u7684\u8f93\u5165\u8fdb\u884c\u5f52\u4e00\u5316\u5904\u7406\uff0c\u4f7f\u5f97\u5176\u5177\u6709\u56fa\u5b9a\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u8fd9\u6837\u53ef\u4ee5\u51cf\u5c11\u8f93\u5165\u5206\u5e03\u7684\u53d8\u5316\uff0c\u4ece\u800c\u51cf\u5c11\u5185\u90e8\u534f\u53d8\u91cf\u504f\u79fb\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Normalization/#pre-norm-post-norm","title":"Pre-Norm &amp; Post-Norm","text":"<p>Pre-Norm\u914d\u7f6e\u88ab\u53d1\u73b0\u66f4\u9002\u5408\u8bad\u7ec3\u6df1\u5c42\u7f51\u7edc\uff0c\u56e0\u4e3a\u5b83\u53ef\u4ee5\u9632\u6b62\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u4f7f\u5f97\u68af\u5ea6\u80fd\u591f\u66f4\u7a33\u5b9a\u5730\u6d41\u8fc7\u7f51\u7edc\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0cPost-Norm\u53ef\u80fd\u5bfc\u81f4\u8bad\u7ec3\u521d\u671f\u4e0d\u7a33\u5b9a\uff0c\u56e0\u4e3a\u7f51\u7edc\u9700\u8981\u9002\u5e94\u5f52\u4e00\u5316\u5c42\u5bf9\u68af\u5ea6\u7684\u5f71\u54cd\u3002\u4f46\u662f\u6548\u679cPost-Norm\u66f4\u597d\uff0c\u53ea\u662f\u8bad\u7ec3\u66f4\u96be\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Normalization/#batch-norm-layer-norm-instance-norm","title":"Batch Norm &amp; Layer Norm &amp; Instance Norm","text":"<p>\u53c2\u8003\u8d44\u6599\uff1aPytorch: BATCHNORM</p> <p>\u53c2\u8003\u8d44\u6599\uff1aPytorch: LAYERNORM</p> <p>Batch Normalization (Batch Norm): \u6279\u91cf\u5f52\u4e00\u5316\u662f\u4e00\u79cd\u5728\u6bcf\u4e2a\u6279\u6b21\u5185\u5bf9\u5c0f\u6279\u6570\u636e\u7684\u6bcf\u4e2a\u901a\u9053\u8fdb\u884c\u5f52\u4e00\u5316\u7684\u65b9\u6cd5\u3002\u5b83\u8ba1\u7b97\u4e00\u4e2a\u6279\u6b21\u4e2d\u6240\u6709\u6570\u636e\u6837\u672c\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u7136\u540e\u7528\u8fd9\u4e9b\u7edf\u8ba1\u4fe1\u606f\u6765\u5f52\u4e00\u5316\u76f8\u540c\u901a\u9053\u7684\u50cf\u7d20\u3002\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u51cf\u5c11\u5185\u90e8\u534f\u53d8\u91cf\u504f\u79fb\uff0c\u52a0\u901f\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5e76\u4f7f\u6a21\u578b\u5bf9\u521d\u59cb\u5316\u53c2\u6570\u7684\u9009\u62e9\u4e0d\u90a3\u4e48\u654f\u611f\u3002Batch Norm\u901a\u5e38\u5728\u5377\u79ef\u5c42\u4e4b\u540e\u548c\u6fc0\u6d3b\u51fd\u6570\u4e4b\u524d\u8fdb\u884c\u3002</p> <p>Layer Normalization (Layer Norm): \u5c42\u5f52\u4e00\u5316\u548c\u6279\u91cf\u5f52\u4e00\u5316\u7c7b\u4f3c\uff0c\u4f46\u5b83\u662f\u5728\u5355\u4e2a\u6570\u636e\u6837\u672c\u7684\u6240\u6709\u901a\u9053\u4e0a\u8fdb\u884c\u64cd\u4f5c\u7684\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u6570\u636e\u6837\u672c\uff0c\u5b83\u8ba1\u7b97\u6240\u6709\u901a\u9053\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u5e76\u8fdb\u884c\u5f52\u4e00\u5316\u3002\u5c42\u5f52\u4e00\u5316\u4e0e\u6279\u91cf\u5927\u5c0f\u65e0\u5173\uff0c\u9002\u7528\u4e8e\u6279\u91cf\u5927\u5c0f\u53d8\u5316\u7684\u60c5\u51b5\uff0c\u4ee5\u53ca\u4e0d\u9002\u5408\u4f7f\u7528\u6279\u91cf\u5f52\u4e00\u5316\u7684\u5faa\u73af\u7f51\u7edc\u3002</p> <p>Instance Normalization (Instance Norm): \u5b9e\u4f8b\u5f52\u4e00\u5316\u901a\u5e38\u7528\u4e8e\u98ce\u683c\u8f6c\u6362\u4efb\u52a1\u3002\u5b83\u5728\u6bcf\u4e2a\u6570\u636e\u6837\u672c\u7684\u6bcf\u4e2a\u901a\u9053\u4e0a\u72ec\u7acb\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u5373\u5bf9\u5355\u4e2a\u6570\u636e\u6837\u672c\u7684\u6bcf\u4e2a\u901a\u9053\u72ec\u7acb\u8ba1\u7b97\u5747\u503c\u548c\u65b9\u5dee\u3002\u8fd9\u79cd\u65b9\u6cd5\u9002\u7528\u4e8e\u90a3\u4e9b\u6279\u6b21\u5185\u6bcf\u4e2a\u6570\u636e\u6837\u672c\u4e4b\u95f4\u7684\u7edf\u8ba1\u4fe1\u606f\u5dee\u5f02\u8f83\u5927\u7684\u4efb\u52a1\uff0c\u5982\u56fe\u50cf\u7684\u98ce\u683c\u8f6c\u6362\u3002</p> Batch Norm Layer Norm Instance Norm \u5168\u8fde\u63a5\u5c42\u548c\u5377\u79ef\u5c42 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u548c\u9012\u5f52\u795e\u7ecf\u7f51\u7edc \u56fe\u50cf\u751f\u6210\u4efb\u52a1\uff0c\u5982\u56fe\u50cf\u98ce\u683c\u8fc1\u79fb\u3001\u8d85\u5206\u8fa8\u7387\u548c\u56fe\u50cf\u5206\u5272 <p>\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\u901a\u5e38\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u89e3\u6790\u3001\u8bed\u4e49\u5206\u6790\u7b49\u4efb\u52a1\u3002RNTN \u662f\u4e00\u79cd\u7ecf\u5178\u7684\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff0c\u7528\u4e8e\u5904\u7406\u6811\u5f62\u7ed3\u6784\u7684\u6570\u636e\u3002\u5b83\u9012\u5f52\u5730\u5e94\u7528 LSTM \u6765\u5904\u7406\u6811\u7684\u8282\u70b9\uff0c\u4ece\u800c\u8ba1\u7b97\u6574\u4e2a\u6811\u7684\u8868\u793a\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Normalization/#rmsnorm","title":"RMSNorm","text":"<p>RMSNorm\u53d1\u73b0LayerNorm\u7684\u4e2d\u5fc3\u504f\u79fb\u6ca1\u4ec0\u4e48\u7528\u3002\u5c06\u5176\u53bb\u6389\u4e4b\u540e\uff0c\u6548\u679c\u51e0\u4e4e\u4e0d\u53d8\uff0c\u4f46\u662f\u901f\u5ea6\u63d0\u5347\u4e8640%\uff0c\u6ce8\u610f\u9664\u4e86\u6ca1\u6709\u51cf\u5747\u503c\uff0c\u52a0\u504f\u7f6e\u4ee5\u5916\uff0c\u5206\u6bcd\u4e0a\u6c42\u7684RMS\u800c\u4e0d\u662f\u65b9\u5dee\u3002\u516c\u5f0f\u5982\u4e0b\u6240\u793a\uff1a</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Pytorch/","title":"Pytorch Tutorial","text":"<p>\u53c2\u8003\u8d44\u65991\uff1a\u52a8\u624b\u5b66\u4e60\u6df1\u5ea6\u5b66\u4e60</p> <p>\u53c2\u8003\u8d44\u65992\uff1a\u6df1\u5165\u6d45\u51faPytorch\u3001Pytorch\u5b9e\u7528\u6559\u7a0b2</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Pytorch/#_1","title":"\u57fa\u7840\u77e5\u8bc6","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Pytorch/#_2","title":"\u5f20\u91cf\u7684\u521b\u5efa\u4e0e\u8ba1\u7b97","text":"<p>\u5f20\u91cf(Tensor)\u5f88\u597d\u5730\u652f\u6301\u52a0\u901f\u8ba1\u7b97\u548c\u81ea\u52a8\u5fae\u5206\uff0c\u800cNumPy\u4ec5\u652f\u6301CPU\u8ba1\u7b97\u3002</p> <pre><code># \uff081\uff09\u5f97\u5230\u5f20\u91cf (\u6307\u5b9a\u3001\u968f\u673a\u3001\u51680\u6216\u51681)\ntorch.tensor([[2, 1, 4, 3], [4, 3, 2, 1]]) # .from_numpy\u65b9\u6cd5\u53ef\u4ee5\u5171\u4eab\u5185\u5b58\uff0c\u4f46torch.tensor(ndarray)\u4e0d\u4f1a\u5171\u4eab\u5185\u5b58\u3002\ntorch.tensor(inputs.to_numpy())\ntorch.rand(2,3)\ntorch.zeros_like(Y)\ntorch.zeros(2, 3, 4) \ntorch.ones(2, 3, 4)\n\n# \uff082\uff09\u67e5\u770b\u6216\u6539\u53d8\u5f20\u91cf\u5f62\u72b6\nx.shape\ny = torch.reshape(x, (3, 2)) # \u65b0\u5f20\u91cf\u4e0e\u539f\u59cb\u5f20\u91cf\u5171\u4eab\u6570\u636e\u5b58\u50a8\ny = x.view(3, 2)\n\n# \uff083\uff09\u7ec4\u5408\u5f20\u91cf\ntorch.cat((X, Y), dim=0) # \u6309\u7167\u884c\u8fdb\u884c\u62fc\u63a5\ntorch.cat((X, Y), dim=1) # \u6309\u7167\u5217\u8fdb\u884c\u62fc\u63a5\n\n# \uff084\uff09\u8f6c\u7f6e\u3001\u590d\u5236\u3001\u8303\u6570\nA.T\nB = A.clone() \ntorch.norm(A) # \u9ed8\u8ba4\u662fL2\u8303\u6570\n</code></pre> <p>\u6a21\u957f\u662f\u4e00\u4e2a\u5411\u91cf\u7684\u957f\u5ea6\u6216\u5927\u5c0f\uff0c\u901a\u5e38\u662f\u6307\u5411\u91cf\u7684\u6b27\u51e0\u91cc\u5fb7\u8303\u6570\uff0c\u5373 L2 \u8303\u6570\u3002</p> <ul> <li>L1 \u8303\u6570\uff1a\u4e5f\u79f0\u4e3a\u66fc\u54c8\u987f\u8303\u6570\uff08Manhattan Norm\uff09\uff0c\u5b83\u662f\u5411\u91cf\u4e2d\u6240\u6709\u5143\u7d20\u7684\u7edd\u5bf9\u503c\u4e4b\u548c\u3002</li> <li>L2 \u8303\u6570\uff1a\u4e5f\u79f0\u4e3a\u6b27\u51e0\u91cc\u5fb7\u8303\u6570\uff08Euclidean Norm\uff09\uff0c\u5b83\u662f\u5411\u91cf\u5143\u7d20\u7684\u5e73\u65b9\u548c\u7684\u5e73\u65b9\u6839\u3002</li> </ul>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Pytorch/#_3","title":"\u5f20\u91cf\u7684\u81ea\u52a8\u6c42\u5bfc","text":"<p>\u4e00\u4e2a\u591a\u5143\u51fd\u6570\u5bf9\u5176\u6240\u6709\u53d8\u91cf\u7684\u504f\u5bfc\u6570\uff0c\u4ee5\u5f97\u5230\u8be5\u51fd\u6570\u7684\u68af\u5ea6\uff08gradient\uff09\u5411\u91cf\u3002</p> <pre><code># \u5f00\u542f\u81ea\u52a8\u6c42\u5bfc\nx = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\ny = torch.tensor([2.0, 4.0, 6.0])\ny.requires_grad_(True)\n\n# \u6784\u5efa\u8ba1\u7b97\u56fe\nloss_function = nn.MSELoss()\noptimizer = optim.SGD([x, y], lr=0.01) # [x, y] \u8868\u793a\u8981\u66f4\u65b0\u7684\u53c2\u6570\u5217\u8868\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\n# \u524d\u5411\u4f20\u64ad \u4e0e \u53cd\u5411\u4f20\u64ad\npredictions = x * 2\nloss = loss_function(predictions, y)\nloss.backward() # \u6bcf\u6b21\u8c03\u7528\u65f6\uff0c\u68af\u5ea6\u4f1a\u7d2f\u79ef\u5230\u5f20\u91cf\u7684 .grad \u5c5e\u6027\u4e2d\n\n# \u68af\u5ea6\u66f4\u65b0 \u4e0e \u68af\u5ea6\u6e05\u96f6\noptimizer.step()\noptimizer.zero_grad()\n\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Pytorch/#_4","title":"\u8fdb\u9636\u77e5\u8bc6","text":"<ul> <li>\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236</li> </ul> <pre><code>def forward(self, x):\n    # \u62c6\u5206\u591a\u5934\n    B, N, C = x.shape\n    qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4) # \u4e00\u822c8\u4e2a\u5934\n    q, k, v = qkv[0], qkv[1], qkv[2]  \n\n    # \u6ce8\u610f\u529b\u8ba1\u7b97\n    attn = (q @ k.transpose(-2, -1)) * self.scale\n    attn = attn.softmax(dim=-1)\n    x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n\n    # ! \u6574\u5408\u591a\u5934\u4fe1\u606f\uff1a\u7ebf\u6027\u5c42\u53ef\u4ee5\u5c06\u4e0d\u540c\u5934\u7684\u8f93\u51fa\u7ec4\u5408\u5728\u4e00\u8d77\uff0c\u5b66\u4e60\u5230\u66f4\u9ad8\u7ea7\u7684\u7279\u5f81\u3002\n    x = self.proj(x) \n    x = self.proj_drop(x)\n    return x\n</code></pre> <ul> <li>Grad-CAM \u4e0e Hook</li> </ul> <p>Grad-CAM\uff08Gradient-weighted Class Activation Mapping\uff09\u662f\u4e00\u79cd\u7528\u4e8e\u7406\u89e3\u548c\u89e3\u91ca\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u51b3\u7b56\u8fc7\u7a0b\u7684\u53ef\u89c6\u5316\u6280\u672f\u3002Grad-CAM \u5229\u7528\u68af\u5ea6\u4fe1\u606f\u6765\u751f\u6210\u8f93\u5165\u56fe\u50cf\u7684\u7c7b\u6fc0\u6d3b\u6620\u5c04\uff0c\u663e\u793a\u6a21\u578b\u5728\u8fdb\u884c\u7279\u5b9a\u9884\u6d4b\u65f6\u5173\u6ce8\u7684\u533a\u57df\u3002\u8fd9\u5bf9\u4e8e\u89e3\u91ca\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u884c\u4e3a\u975e\u5e38\u6709\u7528\uff0c\u7279\u522b\u662f\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\uff0c\u5982\u56fe\u50cf\u5206\u7c7b\u548c\u7269\u4f53\u68c0\u6d4b\u3002</p> <p>\u53c2\u8003\uff1a6.4 CAM\u53ef\u89c6\u5316\u4e0ehook\u51fd\u6570\u4f7f\u7528/Grad CAM \u624b\u52a8\u5b9e\u73b0</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Pytorch/#_5","title":"\u5e76\u884c\u8ba1\u7b97","text":"<p>\u6ce8\u610f\uff0c\u5355\u5361\u548c\u591a\u5361\u7684\u4fdd\u5b58\u548c\u52a0\u8f7d\u4e5f\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u8fd9\u91cc\u4e0d\u8fc7\u591a\u4ecb\u7ecd\u3002</p> <p>\u53c2\u8003\u8d44\u6599\uff1a\u5355\u5361/\u591a\u5361\u4fdd\u5b58\u548c\u52a0\u8f7d</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Pytorch/#_6","title":"\u5feb\u901f\u5f00\u59cb","text":"<pre><code>import os\nos.environ['CUDA_VISIBLE_DEVICES'] = '0' # \u5982\u679c\u662f\u591a\u5361\u6539\u6210\u7c7b\u4f3c0,1,2\nmodel = model.cuda()  # \u5355\u5361\nmodel = torch.nn.DataParallel(model).cuda()  # \u591a\u5361\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Pytorch/#_7","title":"\u8be6\u7ec6\u4ecb\u7ecd","text":"<ul> <li>step1\uff1a\u6307\u5b9a\u53ef\u7528GPU</li> </ul> <pre><code>import os\nos.environ[\"CUDA_VISIBLE_DEVICE\"] = \"2\"\n\nmodel.cuda()\nx.cuda()\ny.cuda()\n</code></pre> <pre><code>CUDA_VISBLE_DEVICE=0,1 python train.py\n</code></pre> <ul> <li>step2\uff1a\u4f7f\u7528 DataParallel \uff08\u5355\u673a\u591a\u5361DP\uff09</li> </ul> <p>\u5b9e\u73b0\u6bd4\u8f83\u7b80\u5355\uff0c\u4e0d\u600e\u4e48\u9700\u8981\u4fee\u6539\u4ee3\u7801\uff0c\u4f46\u662f\u6027\u80fd\u4e0d\u5982DDP\u3002\u5177\u4f53\u6765\u8bf4\uff0cDP\u8fdb\u884c\u5206\u5e03\u5f0f\u591a\u5361\u8bad\u7ec3\u7684\u65b9\u5f0f\u5bb9\u6613\u9020\u6210\u8d1f\u8f7d\u4e0d\u5747\u8861\uff0c\u7b2c\u4e00\u5757GPU\u663e\u5b58\u5360\u7528\u66f4\u591a\uff0c\u56e0\u4e3a\u8f93\u51fa\u9ed8\u8ba4\u90fd\u4f1a\u88abgather\u5230\u7b2c\u4e00\u5757GPU\u4e0a\uff0c\u4e5f\u5c31\u662f\u540e\u7eed\u7684loss\u8ba1\u7b97\u53ea\u4f1a\u5728cuda:0\u4e0a\u8fdb\u884c\uff0c\u6ca1\u6cd5\u5e76\u884c\u3002</p> <pre><code># \u5355\u673a\u591a\u5361\nmodel.cuda() # \u6a21\u578b\u663e\u793a\u8f6c\u79fb\u5230CUDA\u4e0a\nif torch.cuda.device_count() &gt; 1: # \u542b\u6709\u591a\u5f20GPU\u7684\u5361\n    model = nn.DataParallel(model, device_ids=[0,1]) \n</code></pre> <ul> <li>step2\uff1a\u4f7f\u7528 DistributedDataParallel \uff08\u591a\u673a\u591a\u5361DDP\uff09</li> </ul> <p>\u7565\uff0c\u597d\u590d\u6742\uff0c\u4e0d\u5982\u7528Lightning\u548chuggingface\u81ea\u5e26\u7684\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Pytorch/#_8","title":"\u7cbe\u8bfb\u4e0e\u6027\u80fd","text":"<p>\u5728PyTorch\u4e2d\u4f7f\u7528autocast\u914d\u7f6e\u534a\u7cbe\u5ea6\u8bad\u7ec3\uff0c\u540c\u65f6\u9700\u8981\u5728\u4e0b\u9762\u4e09\u5904\u52a0\u4ee5\u8bbe\u7f6e\uff1a</p> <pre><code># \u5bfc\u5165\u6a21\u5757\uff1aimport autocast\nfrom torch.cuda.amp import autocast\n\n# \u6a21\u578b\u8bbe\u7f6e\uff1a\u7528autocast\u88c5\u9970\u6a21\u578b\u4e2d\u7684forward\u51fd\u6570\n@autocast()   \ndef forward(self, x):\n    ...\n    return x\n\n# \u8bad\u7ec3\u8fc7\u7a0b\uff1a\u53ea\u9700\u5728\u5c06\u6570\u636e\u8f93\u5165\u6a21\u578b\u53ca\u5176\u4e4b\u540e\u7684\u90e8\u5206\u653e\u5165\u201cwith autocast():\u201c\u5373\u53ef\nfor x in train_loader:\n    x = x.cuda()\n    with autocast():\n        output = model(x)\n        ...\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Pytorch/#_9","title":"\u53ef\u89c6\u5316","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Pytorch/#_10","title":"\u6a21\u578b\u53ef\u89c6\u5316","text":"<pre><code># pip install torchinfo \n\nimport torchvision.models as models\nfrom torchinfo import summary\n\nresnet18 = models.resnet18() \nsummary(resnet18, (1, 3, 224, 224)) # 1\uff1abatch_size 3:\u56fe\u7247\u7684\u901a\u9053\u6570 224: \u56fe\u7247\u7684\u9ad8\u5bbd\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Pytorch/#_11","title":"\u8bad\u7ec3\u53ef\u89c6\u5316","text":"<pre><code># \u65b9\u6cd5\u4e00\uff1apip install tensorboardX\nfrom tensorboardX import SummaryWriter\nwriter = SummaryWriter('./runs')\n\n# \u65b9\u6cd5\u4e8c\uff1a\u4f7f\u7528\u81ea\u5e26\u7684tensorboard\nfrom torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter('./runs')\n\n# \u542f\u52a8tensorboard\n# tensorboard --logdir=/path/to/logs/ --port=xxxx\n#  ssh -L 16006:127.0.0.1:6006 username@remote_server_ip\uff08\u8fdc\u7a0b\u8bbf\u95ee\uff09\n\n# \u8bad\u7ec3\u5b8c\u6210\u4e4b\u540e\u8981\u8bb0\u5f97\u91ca\u653e\u4e00\u4e0b\u8d44\u6e90\nwriter.close()\n</code></pre> <ul> <li>\u4e3e\u4f8b\u5982\u4e0b\uff1a</li> </ul> <pre><code># \u6a21\u578b\u53ef\u89c6\u5316\nmodel = Net()\nwriter.add_graph(model, input_to_model = torch.rand(1, 3, 224, 224))\n\n# \u8bad\u7ec3\u53ef\u89c6\u5316\nfor epoch in range(num_epochs):\n    model.train()\n    for i, (data, target) in enumerate(train_loader):\n        optimizer.zero_grad()\n        output = model(data)\n        loss = loss_function(output, target)\n        loss.backward()\n        optimizer.step()\n\n        # \u8bb0\u5f55\u635f\u5931\u503c\n        writer.add_scalar('Loss/train', loss.item(), epoch * len(train_loader) + i)\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Pytorch/#pytorch","title":"Pytorch\u4e00\u822c\u6846\u67b6","text":"<ul> <li>\u5b9a\u4e49\u795e\u7ecf\u7f51\u7edc\u6a21\u578b</li> </ul> <pre><code>class Net(nn.Module):\n    def __init__(self): # \u6a21\u578b\u521d\u59cb\u5316\uff0c\u53ef\u4ee5\u4f20\u5165\u5176\u4ed6\u6a21\u578b\n        super(Net, self).__init__() # \u8c03\u7528\u7236\u7c7b nn.Module \u7684\u6784\u9020\u51fd\u6570\n        self.fc1 = nn.Linear(10, 20)\n        self.fc2 = nn.Linear(20, 1)\n\n    def forward(self, x): # \u6a21\u578b\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n</code></pre> <ul> <li>\u5b9a\u4e49\u6570\u636e\u96c6\u548c\u6570\u636e\u52a0\u8f7d\u5668</li> </ul> <pre><code>class MyDataset(Dataset):\n    def __init__(self, data, labels):\n        self.data = data\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # \u5f53\u7136\u8fd9\u91cc\u8fd8\u53ef\u4ee5\u81ea\u5b9a\u4e49\u4e00\u4e9b\u6570\u636e\u5904\u7406\u64cd\u4f5c\n        return self.data[idx], self.labels[idx]\n\ndataset = MyDataset(data, labels)\nloader = DataLoader(dataset, batch_size=32, shuffle=True)\n</code></pre> <ul> <li>\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668</li> </ul> <pre><code># \u635f\u5931\u51fd\u6570\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a\u635f\u5931\u548c\u68af\u5ea6\u7684\u8ba1\u7b97\u5668\ncriterion = nn.MSELoss() \n# \u4f18\u5316\u5668\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a\u68af\u5ea6\u7684\u5904\u7406\u5668\noptimizer = optim.SGD(model.parameters(), lr=0.01) \n</code></pre> <ul> <li>\u8bad\u7ec3\u6a21\u578b</li> </ul> <pre><code>for epoch in range(num_epochs):\n    for inputs, labels in loader:\n        optimizer.zero_grad() # \u6e05\u7a7a\u4e4b\u524d\u8ba1\u7b97\u7684\u68af\u5ea6\uff0c\u4ee5\u907f\u514d\u68af\u5ea6\u7d2f\u79ef\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward() # \u81ea\u52a8\u8ba1\u7b97\u6240\u6709\u53ef\u5b66\u4e60\u53c2\u6570\u7684\u68af\u5ea6\uff08\u53cd\u5411\u4f20\u64ad\uff09\n        optimizer.step() # \u6839\u636e\u68af\u5ea6\u66f4\u65b0\u6a21\u578b\u53c2\u6570\n</code></pre> <ul> <li>\u8bc4\u4f30\u6a21\u578b</li> </ul> <pre><code>model.eval()\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        outputs = model(inputs)\n        # \u8ba1\u7b97\u8bc4\u4f30\u6307\u6807\n</code></pre> <ul> <li>\u4fdd\u5b58\u548c\u52a0\u8f7d\u6a21\u578b</li> </ul> <pre><code># \u4fdd\u5b58\u6a21\u578b\ntorch.save(model.state_dict(), 'model.pth')\n# \u52a0\u8f7d\u6a21\u578b\nmodel = Net()\nmodel.load_state_dict(torch.load('model.pth'))\n</code></pre> <ul> <li>\u51bb\u7ed3\u90e8\u5206\u53c2\u6570</li> </ul> <p>\u8bf7\u5728\u6a21\u578b\u8bad\u7ec3\u524d\u51bb\u7ed3\u53c2\u6570</p> <pre><code>for param in model.parameters():\n    if XXXX:\n        param.requires_grad = False\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Pytorch/#_12","title":"\u90e8\u7f72","text":"<p>\u901a\u5e38\u4eba\u4eec\u4f1a\u5c06\u6a21\u578b\u90e8\u7f72\u5728\u624b\u673a\u7aef\u3001\u5f00\u53d1\u677f\uff0c\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\uff0c\u4f46\u662f\u8fd9\u4e9b\u8bbe\u5907\u4e0a\u7531\u4e8e\u6846\u67b6\u7684\u89c4\u6a21\uff0c\u73af\u5883\u4f9d\u8d56\uff0c\u7b97\u529b\u7684\u9650\u5236\uff0c\u6211\u4eec\u65e0\u6cd5\u76f4\u63a5\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6743\u91cd\u8fdb\u884c\u63a8\u7406\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u5c06\u5f97\u5230\u7684\u6743\u91cd\u8fdb\u884c\u53d8\u6362\u624d\u80fd\u4f7f\u6211\u4eec\u7684\u6a21\u578b\u53ef\u4ee5\u6210\u529f\u90e8\u7f72\u5728\u4e0a\u8ff0\u8bbe\u5907\u4e0a\u3002</p> <p>\u5c06PyTorch\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8f6c\u6362\u4e3aONNX \u683c\u5f0f\uff0c\u7136\u540e\u4f7f\u7528ONNX Runtime\u8fd0\u884c\u5b83\u8fdb\u884c\u63a8\u7406\u3002</p> <p>\u53c2\u8003\u8d44\u6599\uff1a\u4f7f\u7528ONNX\u8fdb\u884c\u90e8\u7f72\u5e76\u63a8\u7406</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Transformers/","title":"Transformers","text":"<p>\u6700\u65b0\u65f6\u95f4\uff1a2024\u5e745\u670816\u65e520:35:57</p> <p>\u4e4b\u524d\u5199\u7684\u592a\u7b80\u5355\u4e86\uff0c\u8fd9\u6b21\u5c06\u5176\u62d3\u5c55\u7684\u5c3d\u91cf\u5168\u9762\u4e00\u70b9\uff0c\u53c2\u8003\uff1a\u5b98\u65b9\u6587\u6863</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Transformers/#_1","title":"\u6982\u8ff0","text":"<p>Transformers\u662f\u4e00\u4e2a\u975e\u5e38\u5927\u7684\u5e93\uff0c\u7ecf\u5e38\u548cDatasets/Accelerate/ bitsandbytes/evaluate/PEFT/Gradio\u4e00\u8d77\u4f7f\u7528\u3002\u5b83\u53ef\u4ee5\u652f\u6301\u975e\u5e38\u4fbf\u6377\u7684\u6a21\u578b\u8c03\u7528\u670d\u52a1\uff0c\u540c\u65f6\u8fd8\u53ef\u4ee5\u652f\u6301\u591a\u5361\u5e76\u884c\u3001\u91cf\u5316\u3001\u6a21\u578b\u8bad\u7ec3\u3001\u6a21\u578b\u5fae\u8c03\u3001\u6a21\u578b\u53ef\u89c6\u5316\uff0c\u53ef\u4ee5\u8bf4\u57fa\u672c\u6db5\u76d6\u6211\u4eec\u6240\u9700\u8981\u7528\u5230\u7684\u5927\u90e8\u5206\u529f\u80fd\u4e86\u3002\u6240\u4ee5\u8bf4\uff0c\u597d\u597d\u5b66\u4e60\u8fd9\u4e2a\u5e93\u771f\u7684\u5f88\u6709\u5fc5\u8981\uff01\uff01\uff01</p> <p>\u4e4b\u524d\u96f6\u96f6\u6563\u6563\u7684\u770b\u4e86\u548c\u4f7f\u7528\u4e86\u4e00\u4e9bTransformers\u7684\u529f\u80fd\uff0c\u4f46\u662f\u5076\u7136\u95f4\u53d1\u6398\u4ed6\u4eec\u5b98\u65b9\u6587\u6863\u5199\u7684\u771f\u7684\u5f88\u597d\uff0c\u6240\u4ee5\u51b3\u5b9a\u901a\u8bfb\u4e00\u4e0b\u5b98\u65b9\u6587\u6863\uff0c\u5b66\u4e60\u4e00\u4e0b\u8fd9\u4e2a\u5e93\u7684\u6574\u4f53\u529f\u80fd\u67b6\u6784\u3002\u4ee5\u4e0b\u662f\u6211\u7684\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u4e00\u4e9b\u6574\u7406\u3002</p> <p>\u67e5\u770bhuggingface\u652f\u6301\u54ea\u4e9btask\uff1f TASK\u5b98\u65b9\u6587\u6863</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Transformers/#pipeline","title":"Pipeline","text":"<p>\u66f4\u591a\u5185\u5bb9\u53ef\u4ee5\u53bb\u770b\u5b98\u65b9\u6587\u6863\uff0c\u4e0b\u9762\u662f\u6700\u5e38\u7528\u7684\u51fd\u6570\uff1a</p> <pre><code># \u591a\u5361\u5e76\u884c + 16bit (\u9700\u8981\u5b89\u88c5 Accelerate)\npipeline = pipeline(task=\"text-generation\", model=\"gpt2\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n\n# \u5355\u5361\u8fd0\u884c + 8bit (\u9700\u8981\u5b89\u88c5 bitsandbytes)\npipeline = pipeline(task=\"text-generation\", model=\"gpt2\", device=0, load_in_8bit=True)\n# load_in_4bit \u5141\u8bb8 4bit \u8fd0\u884c\n</code></pre> <p>\u4e0a\u9762\u9644\u5e26\u4ecb\u7ecd\u4e86\u4e00\u70b9\u91cf\u5316\u548c\u591a\u5361\u5e76\u884c\uff0c\u4f46\u5b9e\u9645\u4e0a\uff0c\u8fd8\u53ef\u4ee5\u52a0\u901f\uff01(\u53ef\u4ee5\u63d0\u9ad8\u591a\u8fbe30%\u7684\u901f\u5ea6!)</p> <pre><code>from transformers import AutoModelForImageClassification\n\nmodel = AutoModelForImageClassification.from_pretrained(MODEL_ID).to(\"cuda\")\n+ model = torch.compile(model) # 2.0\u53ca\u4ee5\u4e0a\u7248\u672c\u7684torch\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Transformers/#autoclass","title":"AutoClass","text":"<p>\u5bf9\u4e8e\u4e0d\u540c\u7c7b\u578b\u7684\u4efb\u52a1\u6709\u4e0d\u540c\u7684AutoClass\uff0c\u6bd4\u5982\uff1a</p> <pre><code>from transformers import AutoTokenizer # \u6587\u5b57\nfrom transformers import AutoImageProcessor # \u56fe\u7247\nfrom transformers import AutoFeatureExtractor # \u97f3\u9891\nfrom transformers import AutoProcessor # \u591a\u6a21\u6001\n\n# Model(1) : AutoModelForXXX (\u597d\u9ebb\u70e6\uff0c\u4e0d\u63a8\u8350)\nfrom transformers import AutoModelForSequenceClassification\nfrom transformers import AutoModelForTokenClassification\n\n# Model(2) : AutoModel \uff08\u5f88\u4e07\u80fd\uff0c\u63a8\u8350\uff09\nfrom transformers import AutoConfig, AutoModel\nconfig = AutoConfig.from_pretrained(\"google-bert/bert-base-cased\")\nmodel = AutoModel.from_config(config)\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Transformers/#tranier","title":"Tranier","text":"<p>\u6570\u636e\u5904\u7406\uff08tokenizer/\u5212\u5206\uff09 -&gt; \u8bad\u7ec3\u51c6\u5907\uff08\u6570\u636e\u6574\u7406\u5668/\u6a21\u578b/\u53c2\u6570/\u8bc4\u4f30\u65b9\u6cd5\uff09 -&gt; \u6a21\u578b\u8bad\u7ec3\uff08\u8bad\u7ec3\u5668/\u8bad\u7ec3\uff09 </p> <p>\u5b98\u65b9\u6587\u6863\u4e2d\u7ed9\u4e86\u4e24\u4e2a\u4e8b\u4f8b\uff0c\u8be6\u7ec6\u5185\u5bb9\u89c1\u5b98\u65b9\u6848\u4f8b\uff0c\u6570\u636e\u5904\u7406\u7684\u90e8\u5206\u53ef\u4ee5\u89c1Datasets\u5e93\u3002</p> <p>Trainer\u4f1a\u81ea\u52a8\u5229\u7528\u6240\u6709\u53ef\u7528\u7684GPU\u8fdb\u884c\u5206\u5e03\u5f0f\u8bad\u7ec3\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Transformers/#_2","title":"\u8bad\u7ec3\u51c6\u5907","text":"<p>evaluate\u53ef\u4ee5\u53c2\u8003\u5b98\u65b9\u6587\u6863\u4e86\u89e3\u66f4\u591a\uff1aevaluate\u5e93</p> <p>\u4e00\u4e2a\u975e\u5e38\u597d\u7684\u89c6\u9891\u8be6\u7ec6\u4ecb\u7ecd\u4e86evaluate\u5e93\u7684\u7528\u6cd5\uff1aB\u7ad9\u6559\u7a0b\uff1aEvaluate</p> <pre><code># \uff081\uff09\u53c2\u6570\uff08\u4ee5\u4e0b\u4f8b\u5b50\u662f\u4e71\u5199\u7684\uff0c\u65e8\u5728\u8bf4\u660e\u4e00\u4e9b\u5e38\u7528\u53c2\u6570\uff09\nfrom transformers import TrainingArguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\", \n    evaluation_strategy=\"epoch\", # \u8bc4\u4f30\u7b56\u7565 \"no\"\u3001\"steps\" \u6216 \"epoch\"\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    # \u7b49\u540c\u4e8e\uff1aoptimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.01)\n    learning_rate=2e-5,\n    weight_decay=0.01, # \u6743\u91cd\u8870\u51cf\u7cfb\u6570\uff0c\u9632\u6b62\u8bad\u7ec3\u8fc7\u62df\u5408\uff0c\u9650\u5236\u6a21\u578b\u6743\u91cd\n    fp16=True,\n)\n\n# \uff082\uff09\u8bbe\u7f6e\u8bc4\u4f30\u51fd\u6570\uff08\u5982\u679c\u4e0d\u9700\u8981\u5728\u8bad\u7ec3\u65f6\u8bc4\u4f30\u5219\u4e0d\u5fc5\u8bbe\u7f6e\uff09\nimport numpy as np\nimport evaluate\nmetric = evaluate.load(\"accuracy\")\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n\n# \uff083\uff09data_collator \u5176\u4e3b\u8981\u4f5c\u7528\u662f\u5c06\u4e00\u6279\u6570\u636e\u6837\u672c\uff08batch\uff09\u8fdb\u884c\u6574\u7406\u548c\u5904\u7406\n# \u53ef\u4ee5\u6709\u6548\u5730\u5904\u7406\u6279\u6b21\u5185\u6837\u672c\u957f\u5ea6\u4e0d\u540c\u3001\u586b\u5145\u3001\u63a9\u7801\u751f\u6210\u7b49\u95ee\u9898\nfrom transformers import DataCollatorForSeq2Seq\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Transformers/#_3","title":"\u6a21\u578b\u8bad\u7ec3","text":"<pre><code># \u8bad\u7ec3\u5668\u521d\u59cb\u5316\ntrainer = Trainer(\n    # data\n    data_collator=data_collator,\n    train_dataset=small_train_dataset,\n    eval_dataset=small_eval_dataset,\n    # model\n    model=model,\n    tokenizer=tokenizer,\n    # args\n    args=training_args,\n    compute_metrics=compute_metrics\n)\n\n# \u5f00\u59cb\u8bad\u7ec3\ntrainer.train()\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Transformers/#accelerate","title":"Accelerate","text":"<p>\u4f7f\u7528Aceelerate\uff0c\u53ef\u4ee5\u5728\u539f\u751fPyTorch\u8bad\u7ec3\u5faa\u73af\u4e2d\u542f\u7528\u5206\u5e03\u5f0f\u8bad\u7ec3\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Transformers/#_4","title":"\u4fee\u6539\u4ee3\u7801","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Transformers/#_5","title":"\u5206\u5e03\u5f0f\u8bad\u7ec3\u4ee3\u7801","text":"<pre><code>from accelerate import Accelerator\n\n# \u4e0d\u9700\u8981model.to(device)\naccelerator = Accelerator()\ntrain_dataloader, eval_dataloader, model, optimizer = \n    accelerator.prepare(train_dataloader, eval_dataloader, model, optimizer)\n\nfor epoch in range(num_epochs):\n    for batch in train_dataloader:\n\n        # \u4e0d\u9700\u8981data.to(device)\n        outputs = model(**batch)\n        loss = outputs.loss\n\n        # \u4e0d\u9700\u8981loss.backward()\n        accelerator.backward(loss)\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Transformers/#_6","title":"\u5206\u5e03\u5f0f\u8bc4\u4f30\u4ee3\u7801","text":"<pre><code>for inputs, targets in validation_dataloader:\n    predictions = model(inputs)\n\n    # Gather all predictions and targets\n    all_predictions, all_targets = accelerator.gather_for_metrics((predictions, targets))\n\n    # Example of use with a *Datasets.Metric*\n    metric.add_batch(all_predictions, all_targets)\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Transformers/#_7","title":"\u542f\u52a8\u5206\u5e03\u5f0f\u8bad\u7ec3","text":"<p>\u6839\u636e\u8bad\u7ec3\u73af\u5883\uff08torchrun\u3001DeepSpeed \u7b49\uff09\u548c\u53ef\u7528\u786c\u4ef6\uff0c\u6709\u8bb8\u591a\u65b9\u6cd5\u53ef\u4ee5\u542f\u52a8\u548c\u8fd0\u884c\u4ee3\u7801\u3002Accelerate \u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u754c\u9762\uff0c\u7528\u4e8e\u5728\u4e0d\u540c\u7684\u5206\u5e03\u5f0f\u8bbe\u7f6e\u4e0a\u542f\u52a8\u548c\u8bad\u7ec3\u3002</p> <pre><code>accelerate config # \u6309\u7167\u63d0\u793a\u4fe1\u606f\u8fdb\u884c\u914d\u7f6e\u5373\u53ef\naccelerate launch train.py --config_file config.yaml\n\n# \u6216\u8005\u53ef\u4ee5\u8f93\u5165\u5982\u4e0b\u6307\u4ee4\uff1a\naccelerate launch --multi_gpu --mixed_precision=fp16 --num_processes=2 {script_name.py} {--arg1} {--arg2} ...\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Transformers/#peft","title":"PEFT","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Transformers/#peft-adapter","title":"\u52a0\u8f7dPEFT adapter","text":"<p>\u9996\u5148\u786e\u4fddHub\u4ed3\u5e93\u6216\u672c\u5730\u76ee\u5f55\u5305\u542b\u4e00\u4e2aadapter_config.json\u6587\u4ef6\u548cadapter\u6743\u91cd</p> <pre><code>from transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_id = \"facebook/opt-350m\"\npeft_model_id = \"ybelkada/opt-350m-lora\"\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\nmodel.load_adapter(peft_model_id)\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Transformers/#peft-adapter_1","title":"\u8bad\u7ec3PEFT adapter","text":"<pre><code>from peft import LoraConfig\n\npeft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.1,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\nmodel.add_adapter(peft_config)\n\ntrainer = Trainer(model=model, ...)\ntrainer.train()\n\nmodel.save_pretrained(save_dir)\nmodel = AutoModelForCausalLM.from_pretrained(save_dir)\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Transformers/#gradio","title":"Gradio","text":"<p>\u5176\u6559\u7a0b\u975e\u5e38\u4e30\u5bcc\uff1a\u5b98\u65b9\u6559\u7a0b</p> <p>\u9700\u8981\u7528\u7684\u65f6\u5019\u770b\u770b\u5b98\u65b9\u6559\u7a0b + \u95ee\u95eeGPT\u5c31\u597d\u5566\uff01\u800c\u4e14\u8fd9\u4e2a\u6bd4Flask\u8fd8\u8981\u65b9\u4fbf\uff01</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/matplotlib/","title":"Matplotlib &amp; Seaborn","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/matplotlib/#matplotlib","title":"Matplotlib","text":"<p>Matplotlib \u662f Python \u4e2d\u5e38\u7528\u7684\u4e00\u4e2a\u7ed8\u56fe\u5e93\uff0c\u6570\u636e\u5206\u6790\u548c\u6570\u636e\u53ef\u89c6\u5316\u90fd\u9700\u8981\u7528\u5230\u3002\u4f46\u662f\u73b0\u5728\u6709GPT\u4e5f\u4e0d\u9700\u8981\u8bb0\u4f4f\u975e\u5e38\u7ec6\u8282\u7684\u8bed\u6cd5\uff0c\u53ea\u9700\u8981\u641e\u6e05\u695a\u6838\u5fc3\u51e0\u4e2a\u7528\u6cd5\u5373\u53ef\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/matplotlib/#matplotlib_1","title":"Matplotlib\u7b80\u5355\u7ed8\u56fe","text":"<pre><code>import matplotlib.pyplot as plt\n# \u7ea2\u8272\u865a\u7ebf\uff0c\u5e26\u5706\u5f62\u6807\u8bb0\nplt.plot(x, y, color='red', marker='o', linestyle='--')  \nplt.title('Styled Plot')\nplt.xlabel('X Axis')\nplt.ylabel('Y Axis')\nplt.show()\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/matplotlib/#_1","title":"\u89e3\u51b3\u4e2d\u6587\u4e71\u7801","text":"<pre><code>plt.rcParams['font.sans-serif'] = ['simHei']\nplt.rcParams['axes.unicode_minus'] = False\n</code></pre> <p>\u8fd8\u6709\u4e00\u79cd\u65b9\u6cd5\u662f\u4e0b\u8f7d\u5b57\u4f53\uff0c\u6307\u5b9a\u8def\u5f84\uff0c\u5176\u5b9e\u4e5f\u5f88\u7b80\u5355\uff0c\u4f46\u4e0a\u8ff0\u65b9\u6cd5\u66f4\u7b80\u5355</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/matplotlib/#_2","title":"\u6307\u5b9a\u5b57\u4f53","text":"<pre><code>from matplotlib.font_manager import FontProperties\nfont = FontProperties(fname='/path/to/font.ttf')\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/matplotlib/#_3","title":"\u591a\u56fe\u7ed8\u5236","text":"<pre><code>fig, axs = plt.subplots(1, 3, figsize=(15, 5))  # 1 \u884c\uff0c3 \u5217\uff0c\u603b\u5171 3 \u4e2a\u5b50\u56fe\n\naxs[0].plot(x, y1, label='sin(x)', color='blue')\naxs[0].set_title('Sine Wave')\naxs[0].legend()\n# ......\n\nfig.suptitle('Trigonometric Functions') # \u6dfb\u52a0\u6574\u4f53\u6807\u9898\nplt.tight_layout() # \u8c03\u6574\u5b50\u56fe\u4e4b\u95f4\u7684\u95f4\u8ddd\nplt.show()\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/matplotlib/#_4","title":"\u591a\u6b21\u7ed8\u5236","text":"<pre><code># \u4e00\u4e2aplot\u4e0a\u53ef\u4ee5\u7ed8\u5236\u591a\u4e2a\u5bf9\u8c61\nplt.plot(x, y, label='x^2')\nplt.plot(x, y2, label='x^3')\nplt.title('Multiple Series')\nplt.xlabel('X Axis')\nplt.ylabel('Y Axis')\nplt.legend()  \n\n# \u6709\u65f6\u9700\u8981\uff0c\u6e05\u7a7a\u753b\u5e03\nplt.clf()\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/matplotlib/#_5","title":"\u5e38\u89c1\u56fe\u50cf\u7ed8\u5236","text":"<pre><code># \u5e38\u89c1\u56fe\u5f62\u4ee3\u7801\nplt.plot(x, y) # \u6298\u7ebf\u56fe\nplt.scatter(x, y) # \u6563\u70b9\u56fe\nplt.bar(x, y) # \u67f1\u72b6\u56fe\n\ndata = np.random.normal(0, 1, size=1000)\nplt.hist(data, bins=6) # \u76f4\u65b9\u56fe\nplt.boxplot(data) # \u7bb1\u578b\u56fe\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/matplotlib/#seaborn","title":"Seaborn","text":"<p>Seaborn \u57fa\u4e8e Matplotlib \u6838\u5fc3\u5e93\u8fdb\u884c\u4e86\u66f4\u9ad8\u9636\u7684 API \u5c01\u88c5\uff0c\u53ef\u4ee5\u8ba9\u4f60\u8f7b\u677e\u5730\u753b\u51fa\u66f4\u6f02\u4eae\u7684\u56fe\u5f62\u3002Seaborn \u7684\u6f02\u4eae\u4e3b\u8981\u4f53\u73b0\u5728\u914d\u8272\u66f4\u52a0\u8212\u670d\u3001\u4ee5\u53ca\u56fe\u5f62\u5143\u7d20\u7684\u6837\u5f0f\u66f4\u52a0\u7ec6\u817b\u3002</p> <p>\u53c2\u8003\u94fe\u63a5\uff1aSeaborn \u6570\u636e\u53ef\u89c6\u5316\u57fa\u7840\u6559\u7a0b</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/matplotlib/#seaborn_1","title":"Seaborn\u7b80\u5355\u7ed8\u56fe","text":"<pre><code>\nimport seaborn as sns\n\n# \u58f0\u660e\u4f7f\u7528 Seaborn \u6837\u5f0f\nsns.set(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=False, rc=None)\n# \u4e0a\u9762\u8fd9\u884c\u7b49\u540c\u4e8e\nsns.set()\n\nplt.bar(x, y_bar)\nplt.plot(x, y_line, '-o', color='y')\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/matplotlib/#_6","title":"\u57fa\u7840\u56fe\u5f62","text":"<p>Seaborn \u7684\u7ed8\u56fe\u65b9\u6cd5\u5927\u81f4\u5206\u7c7b 6 \u7c7b\uff0c\u5206\u522b\u662f\uff1a\u5173\u8054\u56fe\u3001\u7c7b\u522b\u56fe\u3001\u5206\u5e03\u56fe\u3001\u56de\u5f52\u56fe\u3001\u77e9\u9635\u56fe\u548c\u7ec4\u5408\u56fe\u3002\u800c\u8fd9 6 \u5927\u7c7b\u4e0b\u9762\u53c8\u5305\u542b\u4e0d\u540c\u6570\u91cf\u7684\u7ed8\u56fe\u51fd\u6570\u3002</p> <ul> <li>\u5173\u8054\u56fe\u7528\u4e8e\u5c55\u793a\u53d8\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u901a\u5e38\u7528\u4e8e\u67e5\u770b\u4e24\u4e2a\u6216\u591a\u4e2a\u53d8\u91cf\u4e4b\u95f4\u5982\u4f55\u76f8\u4e92\u5f71\u54cd\u3002</li> <li>\u7c7b\u522b\u56fe\u7528\u4e8e\u5c55\u793a\u4e00\u4e2a\u6216\u591a\u4e2a\u7c7b\u522b\u53d8\u91cf\u7684\u5206\u5e03\uff0c\u53ef\u4ee5\u6bd4\u8f83\u4e0d\u540c\u7c7b\u522b\u4e4b\u95f4\u7684\u7edf\u8ba1\u6570\u636e\u3002</li> <li>\u5206\u5e03\u56fe\u7528\u4e8e\u67e5\u770b\u5355\u53d8\u91cf\u6216\u53cc\u53d8\u91cf\u5206\u5e03\uff0c\u5e2e\u52a9\u7406\u89e3\u6570\u636e\u7684\u5206\u5e03\u5f62\u6001\u3002</li> <li>\u56de\u5f52\u56fe\u7528\u4e8e\u5206\u6790\u4e24\u4e2a\u6216\u591a\u4e2a\u53d8\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u62df\u5408\u4e0d\u540c\u7c7b\u578b\u7684\u56de\u5f52\u6a21\u578b\u3002</li> <li>\u77e9\u9635\u56fe\u7528\u4e8e\u5c55\u793a\u6570\u636e\u77e9\u9635\uff08\u4f8b\u5982\u76f8\u5173\u7cfb\u6570\u77e9\u9635\uff09\u548c\u591a\u53d8\u91cf\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\u3002</li> <li>\u7ec4\u5408\u56fe\u662f Seaborn \u4e2d\u7528\u4e8e\u521b\u5efa\u5305\u542b\u591a\u4e2a\u8f74\u5b50\u56fe\u7684\u590d\u6742\u5e03\u5c40\u7684\u51fd\u6570\u3002</li> </ul> <p>\u5177\u4f53\u7684\u4f7f\u7528\u53ef\u4ee5\u95eeGPT\uff0c\u6240\u4ee5\u65e0\u9700\u7279\u522b\u8bb0\u5fc6\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pandas/","title":"Pandas &amp; Numpy","text":"<p>\u73b0\u5728\u6709GPT\u4e5f\u4e0d\u9700\u8981\u8bb0\u4f4f\u975e\u5e38\u7ec6\u8282\u7684\u8bed\u6cd5\uff0c\u53ea\u9700\u8981\u641e\u6e05\u695a\u6838\u5fc3\u51e0\u4e2a\u7528\u6cd5\u5373\u53ef\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pandas/#pandas","title":"Pandas","text":"<p>\u53c2\u8003\u8d44\u6599\uff1aPython Pandas\u5e93\u6559\u7a0b(\u8d85\u8be6\u7ec6)</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pandas/#_1","title":"\u57fa\u7840\u77e5\u8bc6","text":"<p>Pandas\u4e3b\u8981\u91c7\u7528Series\u548cDataFrame\u4e24\u79cd\u6570\u636e\u7ed3\u6784\u3002</p> <ul> <li>Series\u662f\u4e00\u79cd\u7c7b\u4f3c\u4e00\u7ef4\u6570\u636e\u7684\u6570\u636e\u7ed3\u6784\uff0c\u7531\u6570\u636e(values)\u53ca\u7d22\u5f15(indexs)\u7ec4\u6210\u3002</li> <li>DataFrame\u662f\u4e00\u4e2a\u8868\u683c\u578b\u7684\u6570\u636e\u7ed3\u6784\uff0c\u6bcf\u5217\u7684\u6570\u636e\u53ef\u4ee5\u4e3a\u4e0d\u540c\u7c7b\u578b\uff08NumPy\u6570\u636e\u7ec4\u4e2d\u6570\u636e\u8981\u6c42\u4e3a\u76f8\u540c\u7c7b\u578b\uff09\uff0c\u5b83\u65e2\u6709\u884c\u7d22\u5f15\uff08index\uff09\uff0c\u4e5f\u6709\u5217\u7d22\u5f15\uff08cloumn\uff09\u3002</li> <li>Series\u76f8\u5f53\u4e8e\u4e00\u5217DataFrame\u3002</li> </ul> <p>\u4e2a\u4eba\u8ba4\u4e3aSeries\u8fd9\u79cd\u7c7b\u578b\u6ca1\u4ec0\u4e48\u597d\u8bb2\u7684\uff0c\u800c\u4e14\u4e00\u822c\u7528\u4e0d\u5230\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pandas/#_2","title":"\u8bfb\u5165\u548c\u5199\u5165\u6570\u636e","text":"<pre><code># \u8bfb\u5165\u548c\u5199\u5165\u6570\u636e\npd.read_csv()\nDataFrame.to_csv()\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pandas/#_3","title":"\u67e5\u770b\u6570\u636e","text":"<pre><code># \u67e5\u770b\u6570\u636e\u53ca\u5176\u7edf\u8ba1\u6027\u4fe1\u606f\nDataFrame.head()\nDataFrame.describe()\n\n# \u67e5\u770b\u5c5e\u6027\ndf.index     ##\u663e\u793a\u7d22\u5f15(\u663e\u793a\u6807\u7b7e\u7d22\u5f15\u6216\u4f4d\u7f6e\u7d22\u5f15)\ndf.columns   ##\u663e\u793a\u5217\u540d\ndf.values    ##\u663e\u793a\u503c\n\n# \u67e5\u770b\u957f\u5ea6\u3001\u5f62\u72b6\u3001\u5927\u5c0f\nprint(\"Number of rows:\", len(df))\nprint(\"Shape of DataFrame:\", df.shape)\nprint(\"Total number of elements:\", df.size)\n</code></pre> <ul> <li>len(df) \u8fd4\u56de\u7684\u662f DataFrame \u4e2d\u7684\u884c\u6570\u3002</li> <li>df.shape \u8fd4\u56de\u4e00\u4e2a\u5143\u7ec4\uff0c\u5176\u5185\u5bb9\u662f\uff08\u884c\u6570\uff0c\u5217\u6570\uff09\u3002</li> <li>df.size \u8fd4\u56de\u7684\u662f DataFrame \u4e2d\u6240\u6709\u5143\u7d20\u7684\u603b\u6570\uff08\u7b49\u4e8e\u884c\u6570\u4e58\u4ee5\u5217\u6570\uff09\u3002</li> </ul>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pandas/#_4","title":"\u9009\u62e9\u6570\u636e","text":"<pre><code># \u9009\u62e9\u6570\u636e\uff08\u524d\u884c\u540e\u5217\uff09\nsubset = DataFrame.iloc[start_row:end_row, start_column:end_column]\nsubset = DataFrame.loc[start_label:end_label, ['column_name1', 'column_name2', ...]]\nDataFrame['column_name'] # \u5feb\u901f\u9009\u62e9\u5217\nDataFrame[name_list] # \u5feb\u901f\u9009\u62e9\u591a\u4e2a\u5217\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pandas/#_5","title":"\u8fc7\u6ee4\u6570\u636e","text":"<pre><code>#\uff08\u6761\u4ef6\u8fc7\u6ee4\uff09\n## \u6570\u5b57\ncondition = (DataFrame['column1'] &gt; value1) &amp; (DataFrame['column2'] &lt; value2)\ncondition = DataFrame['column_name'].isin([value1, value2, ...])\n## \u6587\u5b57\ncondition = DataFrame['column_name'].str.contains('substring')\nfiltered_data = DataFrame[condition]\n\n#\uff08\u67e5\u8be2\u8fc7\u6ee4\uff09\nfiltered_data = DataFrame.query(\"column1 &gt; value1 and column2 &lt; value2\") \n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pandas/#_6","title":"\u5206\u7ec4\u4e0e\u805a\u5408","text":"<pre><code># \u5206\u7ec4\u64cd\u4f5c\ngrouped_data = DataFrame.groupby('column_name')\n\n# \u805a\u5408\u64cd\u4f5c\nmean_result = grouped_data.mean() # count/max/min/size/first/last/describe\nagg_result = grouped_data.agg(['mean', 'sum', 'count']) # \u8fdb\u884c\u4e00\u7ec4\u805a\u5408\u64cd\u4f5c\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pandas/#_7","title":"\u6570\u636e\u5904\u7406","text":"<p>\u5728Pandas\u4e2d\uff0capply\u548cmap\u662f\u4e24\u4e2a\u975e\u5e38\u5f3a\u5927\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5bf9DataFrame\u6216Series\u4e2d\u7684\u6570\u636e\u8fdb\u884c\u8f6c\u6362\u548c\u64cd\u4f5c\u3002map\u65b9\u6cd5\u662f\u4e13\u95e8\u7528\u4e8eSeries\u7684\uff0c\u7528\u4e8e\u5c06\u4e00\u4e2a\u51fd\u6570\u5e94\u7528\u4e8eSeries\u4e2d\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\u3002</p> <pre><code>#\u5168\u5c40\u5904\u7406\uff0c\u6bcf\u4e2a\u5143\u7d20\u4e582\ndf.apply(lambda x : x * 2) \n\n#\u5217\u7ea7\u6216\u884c\u7ea7\u5904\u7406\uff0c\u6bcf\u5217\u7684\u6700\u5927\u503c\u51cf\u53bb\u6700\u5c0f\u503c\ndf.apply(lambda x : x.max() - x.min(), axis = 0) ## x\u4ee3\u8868\u4e00\u5217\ndf.apply(lambda x : x.max() - x.min(), axis = 1) ## x\u4ee3\u8868\u4e00\u884c\n\n#\u884c\u7ea7\u5904\u7406\uff0c\u7b2c\u4e8c\u884c\u7684\u6bcf\u4e2a\u5143\u7d20\u4e582\ndf.iloc[1].map(lambda x : x * 2) \n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pandas/#numpy","title":"Numpy","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pandas/#_8","title":"\u521b\u5efa","text":"<pre><code>import numpy as np \na = np.array([1,2,3])  \na = np.array([[1,  2],  [3,  4]])  \na = np.array([1, 2, 3, 4, 5], ndmin =  2)  # [[1 2 3 4 5]]\n\nrandom_array = np.random.rand(2, 3)  # \u521b\u5efa\u4e00\u4e2a 2x3 \u7684\u6570\u7ec4\uff0c\u5143\u7d20\u662f\u968f\u673a\u5206\u5e03\u7684\nnormal_array = np.random.randn(4, 2)  # \u521b\u5efa\u4e00\u4e2a 4x2 \u7684\u6570\u7ec4\uff0c\u5143\u7d20\u662f\u6b63\u6001\u5206\u5e03\u7684\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pandas/#_9","title":"\u7c7b\u578b","text":"<pre><code>import numpy as np\n\n# \u521b\u5efa\u5177\u6709\u7279\u5b9a\u6570\u636e\u7c7b\u578b\u7684\u6570\u7ec4\na = np.array([1, 2, 3], dtype=np.float64)\nb = np.array([1.0, 2.0, 3.0], dtype=np.int32)\n\n# \u67e5\u8be2\u6570\u7ec4\u7684\u6570\u636e\u7c7b\u578b\nprint(a.dtype)  # \u8f93\u51fa: float64\nprint(b.dtype)  # \u8f93\u51fa: int32\n\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/","title":"\u96f6\u788e\u77e5\u8bc6\u8865\u5145","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/#_2","title":"\u6982\u7387\u8bba","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/#_3","title":"\u4f3c\u7136\u4e0e\u6700\u5927\u4f3c\u7136\u4f30\u8ba1","text":"<p>\u5728\u7edf\u8ba1\u5b66\u4e2d\uff0c\u6982\u7387\u548c\u4f3c\u7136\u662f\u4e24\u4e2a\u4e0d\u540c\u7684\u6982\u5ff5\uff1a</p> <p>\u6982\u7387\uff1a\u5728\u7279\u5b9a\u73af\u5883\u4e0b\uff08\u53c2\u6570\u5df2\u77e5\uff09\uff0c\u67d0\u4ef6\u4e8b\u60c5\u53d1\u751f\u7684\u53ef\u80fd\u6027\uff08\u7ed3\u679c\u672a\u77e5\uff09</p> <p>\u4f3c\u7136\uff1a\u57fa\u4e8e\u4ea7\u751f\u7684\u7ed3\u679c\uff08\u7ed3\u679c\u5df2\u77e5\uff09\uff0c\u63a8\u6d4b\u4ea7\u751f\u8fd9\u4e2a\u7ed3\u679c\u7684\u53ef\u80fd\u73af\u5883\uff08\u53c2\u6570\u672a\u77e5\uff09</p> <p>\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff1a\u5229\u7528\u5df2\u77e5\u7684\u7ed3\u679c\uff0c\u53cd\u63a8\u51fa\u4f7f\u8fd9\u4e9b\u7ed3\u679c\u51fa\u73b0\u7684\u53ef\u80fd\u6027\u6700\u5927\u7684\u53c2\u6570\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/#_4","title":"\u8d1d\u53f6\u65af\u516c\u5f0f","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/#kl","title":"\u4ea4\u53c9\u71b5\u3001\u4fe1\u606f\u71b5\u3001KL\u6563\u5ea6","text":"<p>\u4fe1\u606f\u71b5\u662f\u5ea6\u91cf\u968f\u673a\u53d8\u91cf\u4e0d\u786e\u5b9a\u6027\u7684\u4e00\u4e2a\u91cd\u8981\u6982\u5ff5\u3002\u71b5\u8d8a\u5927\uff0c\u53d8\u91cf\u7684\u4e0d\u786e\u5b9a\u6027\u5c31\u8d8a\u5927\u3002</p> <p>\u4ea4\u53c9\u71b5\u7528\u4e8e\u5ea6\u91cf\u4e24\u4e2a\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u7684\u8ddd\u79bb\u3002</p> <p>KL \u6563\u5ea6\uff08\u53c8\u79f0\u4e3a\u76f8\u5bf9\u71b5\uff09\u7528\u4e8e\u5ea6\u91cf\u4e24\u4e2a\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u7684\u76f8\u5bf9\u71b5\u3002</p> <p>\u4e09\u8005\u4e4b\u95f4\u7684\u5173\u7cfb\u5982\u4e0b\u6240\u793a\uff1a</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8/","title":"\u670d\u52a1\u5668\u4f7f\u7528","text":"<ul> <li>\u8fdb\u7a0b\u76f8\u5173 (\u67e5\u770b\u3001\u7ed3\u675f\u3001\u4e00\u76f4\u8fd0\u884c)</li> </ul> <pre><code># \u67e5\u770b\u6240\u6709\u7aef\u53e3\u5360\u7528\u60c5\u51b5\uff1anetstat -nlp\n# \u67e5\u770b\u6240\u6709\u8fdb\u7a0b\u4fe1\u606f\uff1aps aux\n# \u5173\u95ed\u67d0\u8fdb\u7a0b\uff1akill XXXX\n# \u5173\u95ed\u67d0\u4e00\u7c7b\u8fdb\u7a0b\uff1akillall XXXX\n# \u4e00\u76f4\u8fd0\u884c\u67d0\u7a0b\u5e8f nohup XXXX  &gt;&gt; out.txt &amp;\n</code></pre> <ul> <li>GPU\u76f8\u5173</li> </ul> <pre><code># \u67e5\u770b\u5b9e\u65f6GPU\u4f7f\u7528\u60c5\u51b5\nwatch -n 1 nvidia-smi\n# \u67e5\u770b\u6b64\u65f6GPU\u4f7f\u7528\u60c5\u51b5\nnvidia-smi\n</code></pre> <ul> <li>jupyter\u76f8\u5173</li> </ul> <pre><code># \u5173\u95ed\u6b63\u5728\u8fd0\u884c\u7684jupyter\u5185\u6838\n# \u4f17\u6240\u5468\u77e5\uff0cjupyter\u5185\u6838\u5e76\u4e0d\u4f1a\u5728\u4f60\u53c9\u6389\u90a3\u4e2a\u6587\u4ef6\u4e4b\u540e\u91ca\u653e...\u6240\u4ee5\u9700\u8981\u4e00\u4e9b\u5f3a\u5236\u624b\u6bb5\nps -ef | grep jupyter | grep -v grep | awk '{print $2}' | xargs kill -9\n</code></pre> <ul> <li>\u5916\u90e8\u8bbf\u95ee</li> </ul> <p>vscode\u5341\u5206\u65b9\u4fbf\uff01\u5728VScode\u4e2d\u653e\u884c\u7aef\u53e3\u53ea\u9700\u8981\u5728\u7aef\u53e3\u7684\u5730\u65b9\u6dfb\u52a0\u7aef\u53e3\u5c31\u884c\u4e86\uff01</p> <p>\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u5c31\u662f\u901a\u8fc7\u5efa\u7acbSSH\u96a7\u9053\uff1a</p> <pre><code># \u5728\u672c\u673a\u4e0a\u8f93\u5165\uff1a\nssh -L [\u672c\u5730\u7aef\u53e3]:localhost:[\u8fdc\u7a0b\u7aef\u53e3] [\u8fdc\u7a0b\u7528\u6237\u540d]@[\u8fdc\u7a0bIP] -p [ssh\u8fde\u63a5\u7aef\u53e3]\n# \u7136\u540e\u8f93\u5165\u670d\u52a1\u5668\u5bc6\u7801\u5373\u53ef\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%A1%B9%E7%9B%AE%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","title":"\u9879\u76ee\u73af\u5883\u642d\u5efa","text":"<p>\u73af\u5883\u642d\u5efa\u662f\u591a\u5c11\u65b0\u624b\u7684\u75dbo(\u2565\ufe4f\u2565)o</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%A1%B9%E7%9B%AE%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/#_2","title":"\u89e3\u51b3\u4e00\u5207\u7f51\u7edc\u95ee\u9898","text":"<p>\u672c\u8d28\u95ee\u9898\uff1a\u5728\u670d\u52a1\u5668\u4e0a\u5b9e\u73b0\u79d1\u5b66\u4e0a\u7f51</p> <p>\u53c2\u8003\u8d44\u6599\uff1aLinux\uff08ubuntu\uff09\u7cfb\u7edf\u5b89\u88c5\u548c\u4f7f\u7528clash</p> <p>\u53c2\u8003\u8d44\u6599\u76f4\u63a5\u5728ubuntu\u4e2d\u64cd\u4f5c\uff0c\u800c\u6211\u662f\u7528vscode\u8fde\u63a5\u670d\u52a1\u5668\u64cd\u4f5c\u7684\uff0c\u90e8\u5206\u5730\u65b9\u6709\u4e9b\u8bb8\u4e0d\u540c</p> <ul> <li>\u7b2c\u4e00\u6b65\uff1a\u5b89\u88c5clash</li> </ul> <p>\u6587\u4ef6\u4e0b\u8f7d\u94fe\u63a5\uff1ahttps://zywang.lanzn.com/ijE2a1m7h6mb</p> <p>\u7531\u4e8e\u5b98\u65b9\u7684clash-for-linux\u5df2\u7ecf\u5220\u5e93\u8dd1\u8def\u4e86\uff0c\u6240\u4ee5\u53ea\u80fd\u4ece\u8fd9\u4e2a\u94fe\u63a5\u4e0b\u8f7d</p> <ul> <li>\u7b2c\u4e8c\u6b65\uff1a\u4fee\u6539.env</li> </ul> <p>\u5176\u4e2d\u9700\u8981\u4fee\u6539\u4e24\u4e2a\u5730\u65b9\uff1a</p> <p>\uff081\uff09\u628a<code>CLASH_URL</code>\u8bbe\u7f6e\u4e3a\u4f60\u7684Clash\u8ba2\u9605\u5730\u5740\uff1b</p> <p>\uff082\uff09\u628a<code>CLASH_SECRET</code>\u8bbe\u7f6e\u4e3a\u4f60\u7684\u5bc6\u7801</p> <ul> <li>\u7b2c\u4e09\u6b65\uff1abash start.sh</li> <li>\u7b2c\u56db\u6b65\uff1a\u653e\u884c\u7aef\u53e3 9090 \u548c 7890 \u548c7891</li> </ul> <p>\u5728VScode\u4e2d\u653e\u884c\u7aef\u53e3\u5f88\u7b80\u5355\uff0c\u53ea\u9700\u8981\u5728\u7aef\u53e3\u7684\u5730\u65b9\u6dfb\u52a0\u7aef\u53e3\u5c31\u884c\u4e86\u3002</p> <ul> <li>\u7b2c\u4e94\u6b65\uff1a\u8fdb\u5165\u7f51\u7ad9 http://127.0.0.1:9090/ui/ \u9009\u62e9\u8282\u70b9</li> </ul> <p>\uff081\uff09 API Base URL \u8bbe\u7f6e\u4e3a\u9ed8\u8ba4\u503c\uff1ahttp://127.0.0.1:9090</p> <p>\uff082\uff09 Secret \u8bbe\u7f6e\u4e3a\u4e4b\u524d\u7684<code>CLASH_SECRET</code>\u8bbe\u7f6e\u7684\u5bc6\u7801</p> <p>\uff083\uff09 \u5728 Proxies \u4e2d\u9009\u62e9\u80fd\u591f\u4f7f\u7528\u7684\u8282\u70b9</p> <ul> <li>\u7b2c\u516d\u6b65\uff1a\u5f00\u542f\u4ee3\u7406</li> </ul> <pre><code>source /etc/profile.d/clash.sh\nproxy_on\n\n# \uff01\uff01\uff01\u7406\u8bba\u4e0a\u53ea\u8981\u4e0a\u9762\u4e24\u884c\u5c31\u884c\u4e86\uff0c\u5982\u679c\u8fd8\u4e0d\u884c\u8bd5\u8bd5\u4e0b\u9762\u7684\u4e09\u4e2a\u64cd\u4f5c\u5f3a\u5236\u5f00\u542f\u4e00\u4e0b\n\n# \u542f\u52a8clash\uff1a\u3010clash\u5730\u5740\u3011 -d \u3010clash\u914d\u7f6e\u6587\u4ef6\u5939\u5730\u5740\u3011 -f\u3010yaml\u6587\u4ef6\u5939\u5730\u5740\u3011\n/root/ADV_DIFF/clash-for-linux-master/bin/clash-linux-arm64 -d /root/ADV_DIFF/clash-for-linux-master/conf -f /root/ADV_DIFF/clash-for-linux-master/conf/config.yaml\n# \u6307\u5b9a\u7cfb\u7edf\u73af\u5883\u53d8\u91cf\nexport https_proxy=http://127.0.0.1:7890\nexport https_proxy=https://127.0.0.1:7890\n</code></pre> <ul> <li>\u7b2c\u4e03\u6b65\uff1a\u6d4b\u8bd5\u4e00\u4e0b</li> </ul> <pre><code>curl https://www.google.com\n\n# \u4e00\u76f4\u6ca1\u8f93\u51fa\u5219\u5931\u8d25\uff0c\u8f93\u51fa\u4e00\u5806\u4e71\u4e03\u516b\u7cdf\u7684\u5219\u6210\u529f\uff01\n\n# \u5173\u95ed\u4ee3\u7406\uff1aproxy_off \u5f00\u542f\u4ee3\u7406\uff1aproxy_on\n# \u9700\u8981\u5173\u95edclash\uff1a bash shutdown.sh\n# \u9700\u8981\u5f00\u542fclash\uff1abash start.sh\n# \u9700\u8981\u91cd\u542fclush\uff1abash restart.sh\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%A1%B9%E7%9B%AE%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/#huggingface","title":"Huggingface \u79d1\u5b66\u4e0a\u7f51","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%A1%B9%E7%9B%AE%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/#_3","title":"\u672c\u673a\uff08\u975e\u670d\u52a1\u5668\uff09","text":"<pre><code>import os\n# \u524d\u63d0\u6761\u4ef6\uff1a\u672c\u673a\u53ef\u4ee5\u8bbf\u95ee\u4ee3\u7406\u670d\u52a1\u5668\uff0c\u5373\u53ef\u4ee5\u79d1\u5b66\u4e0a\u7f51\uff08VPN\uff09\n# \u539f\u7406\uff1a\u901a\u8fc7\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\uff0c\u5c06\u4ee3\u7406\u670d\u52a1\u5668\u5730\u5740\u8bbe\u7f6e\u5230\u4ee3\u7801\u4e2d\n# \u4ee3\u7406\u670d\u52a1\u5668\u5730\u5740\uff1a\u53ef\u4ee5\u5728 \u7f51\u7edc\u548cInternet &gt; \u4ee3\u7406 &gt; \u624b\u52a8\u8bbe\u7f6e\u4ee3\u7406 &gt; \u7f16\u8f91 \u4e2d\u67e5\u770b\n# \u7aef\u53e3\u53f7\u6839\u636e\u81ea\u5df1\u60c5\u51b5\u66f4\u6539\nos.environ['HTTP_PROXY'] = 'http://127.0.0.1:33210' \nos.environ['HTTPS_PROXY'] = 'http://127.0.0.1:33210'\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%A1%B9%E7%9B%AE%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/#_4","title":"\u670d\u52a1\u5668","text":"<p>\u65b9\u6cd5\u4e00\uff1a\u5728\u670d\u52a1\u5668\u4e0a\u914d\u7f6eVPN \uff08\u81ea\u884c\u641c\u7d22\uff0c\u5f88\u9ebb\u70e6\u5c31\u662f\uff0c\u4e0d\u63a8\u8350\uff09</p> <p>\u65b9\u6cd5\u4e8c\uff1a\u81ea\u5df1\u4e0b\u8f7d\u4f20\u5230\u670d\u52a1\u5668\u4e0a\uff08\u6bd4\u8f83\u7b80\u5355\uff0c\u4f46\u6bcf\u6b21\u8981\u6539\u5730\u5740\uff0c\u4e0d\u63a8\u8350\uff09</p> <p>\u65b9\u6cd5\u4e09\uff1a\u955c\u50cf\u7f51\u7ad9 + huggingface-cli \uff08\u5f88\u65b9\u4fbf\uff0c\u4e14\u901f\u5ea6\u5f88\u5feb\uff0c\u63a8\u8350\uff09</p> <p>\u4e4b\u524d\u81ea\u5df1\u90fd\u662f\u7528\u524d\u4e24\u79cd\u65b9\u6cd5\uff0c\u7136\u540e\u603b\u662f\u6709\u95ee\u9898\uff0c\u76f4\u5230\u6211\u77e5\u9053\u4e86\u7b2c\u4e09\u79cd\u65b9\u6cd5\uff0c\u611f\u8c22\u4e0a\u5e1d\uff01</p> <p>\u8fd9\u4e2a\u65b9\u6cd5\u4f1a\u5c06\u4e0b\u8f7d\u7684\u6a21\u578b\u548c\u6570\u636e\u96c6\u81ea\u52a8\u94fe\u63a5\u5230\u9ed8\u8ba4\u7684\u76ee\u5f55\u4e0b\uff0c\u8fd9\u6837\u6240\u6709\u4ee3\u7801\u90fd\u4e0d\u9700\u8981\u6539\u4e86\uff01</p> <pre><code># \u9996\u5148\uff0cpip\u5b89\u88c5\u4e00\u4e0b\u5e93 huggingface-cli \npip install -U huggingface_hub\n# \u7136\u540e\uff0c\u8bbe\u7f6e\u955c\u50cf\u5730\u5740\nexport HF_ENDPOINT=https://hf-mirror.com\n\n# \u5982\u679c\u8981\u4e0b\u8f7d\u6a21\u578b\uff0c\u8f93\u5165\u5982\u4e0b\u6307\u4ee4\uff08\u4ee5gpt2\u4e3a\u4f8b\uff09\nhuggingface-cli download --resume-download gpt2 --local-dir gpt2\n\n# \u5982\u679c\u8981\u4e0b\u8f7d\u6570\u636e\u96c6\uff0c\u8f93\u5165\u5982\u4e0b\u6307\u4ee4\uff08\u4ee5wikitext\u4e3a\u4f8b\uff09\nhuggingface-cli download --repo-type dataset --resume-download wikitext --local-dir wikitext\n# local-dir\u968f\u4fbf\u586b\u672c\u5730\u7684\u5730\u5740\u5373\u53ef\n</code></pre> <p>\u53ef\u4ee5\u8bf4\u8fd9\u662f\u4e07\u80fd\u65b9\u6cd5\uff0c\u65e2\u53ef\u4ee5\u7528\u5728\u670d\u52a1\u5668\u4e0a\uff0c\u4e5f\u53ef\u4ee5\u7528\u5728\u672c\u673a\u4e0a\uff0c\u975e\u5e38\u65b9\u4fbf\uff01</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%A1%B9%E7%9B%AE%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/#conda","title":"\u4f7f\u7528Conda\u73af\u5883","text":"<ul> <li>\u521b\u5efa\u3001\u5220\u9664\u3001\u663e\u793a\u73af\u5883</li> </ul> <pre><code># \u521b\u5efa\u73af\u5883\nconda create --name xxxx python==xxx\n# \u5220\u9664\u73af\u5883\nconda env remove --name xxxx\n# \u663e\u793a\u73af\u5883\nconda env list\n</code></pre> <ul> <li>pip \u52a0\u901f</li> </ul> <p>\u6709\u7684\u65f6\u5019\uff0c\u4e00\u4e9b\u670d\u52a1\u5668\u4e0a\u6ca1\u6709\u6362\u6e90\uff0c\u4f46\u662f\u8981\u5feb\u901f\u5b89\u88c5</p> <pre><code>pip install XXX -i https://pypi.tuna.tsinghua.edu.cn/simple\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%A1%B9%E7%9B%AE%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/#jupyter-notebook-lab","title":"\u4f7f\u7528 jupyter notebook / lab","text":"<p>\u53c2\u8003\u8d44\u6599\uff1aJupyter Notebook \u4f7f\u7528</p> <p>\u53c2\u8003\u8d44\u6599\uff1aJupyter Notebook\u4ecb\u7ecd\u3001\u5b89\u88c5\u53ca\u4f7f\u7528\u6559\u7a0b</p> <p>\u7b80\u5355\u6765\u8bf4 Jupyter Lab \u6bd4 Jupyter Notebook \u66f4\u5148\u8fdb\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%A1%B9%E7%9B%AE%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/#_5","title":"\u5b89\u88c5\u4e0e\u8fd0\u884c","text":"<pre><code>pip install jupyter notebook\npip install jupyterlab\n\njupyter notebook --port &lt;port_number&gt;\n</code></pre> <p>\u6216\u8005\u76f4\u63a5\u5b89\u88c5vscode\u7684\u63d2\u4ef6\uff0c\u76f4\u63a5\u5728vscode\u4e2d\u4f7f\u7528jupyter\uff01</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%A1%B9%E7%9B%AE%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/#_6","title":"\u73af\u5883\u914d\u7f6e","text":"<p>Anaconda\u5b89\u88c5\u7684\u865a\u62df\u73af\u5883\u548cJupyter Notebook\u8fd0\u884c\u9700\u8981\u7684Kernel\u5e76\u4e0d\u4e92\u901a\uff0c\u5982\u679c\u6211\u4eec\u60f3\u8981\u5207\u6362\u5185\u6838\uff08Change Kernel\uff09\uff0c\u53ef\u4ee5\u53c2\u8003\u5982\u4e0b\u6b65\u9aa4\uff1a</p> <pre><code># (1) \u5b89\u88c5 ipykernel\nconda create -n env_name python=3.8 ipykernel\npip install ipykernel # \u5982\u679c\u5df2\u7ecf\u521b\u5efa\u73af\u5883\uff0c\u5728\u73af\u5883\u4e2d\u5b89\u88c5ipykernel\n\n# (2) \u5c06\u865a\u62df\u73af\u5883\u5199\u8fdb Jupyter\npython -m ipykernel install --user --name XXX\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%A1%B9%E7%9B%AE%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/#_7","title":"\u8fdc\u7a0b\u8fde\u63a5","text":"<p>\u975e\u5e38\u8be6\u7ec6\u7684\u8d44\u6599\uff1aJupyter notebook\u8fdc\u7a0b\u8fde\u63a5\u670d\u52a1\u5668</p> <p>\u4e0a\u8ff0\u8d44\u6599\u662f\u901a\u8fc7SSH\u96a7\u9053\u6765\u8fde\u63a5Jupyter\u7684\uff0c\u4f46\u5176\u5b9e\u53ef\u4ee5\u901a\u8fc7\u53e6\u4e00\u79cd\u66f4\u52a0\u65b9\u4fbf\u4f46\u4e0d\u4e00\u5b9a\u5b89\u5168\u7684\u65b9\u5f0f\uff0c\u4ecb\u7ecd\u5982\u4e0b\uff0c\u6211\u4eec\u76f4\u63a5\u5141\u8bb8\u6240\u6709IP\u8bbf\u95ee\u7279\u5b9a\u7aef\u53e3\u5373\u53ef\u3002</p> <pre><code># \u8fdb\u884c\u914d\u7f6e\njupyter notebook --generate-config\njupyter notebook password # \u6309\u7167\u63d0\u793a\u8bbe\u7f6e\u5bc6\u7801\nvim ~/.jupyter/jupyter_notebook_config.py\n\n# \u4fee\u6539\u914d\u7f6e\u6587\u4ef6\nc.NotebookApp.ip = '0.0.0.0'  # \u5141\u8bb8\u4efb\u4f55 IP \u8bbf\u95ee\nc.NotebookApp.open_browser = False  # \u4e0d\u81ea\u52a8\u6253\u5f00\u6d4f\u89c8\u5668\nc.NotebookApp.port = 8888  # \u4f7f\u7528\u7684\u7aef\u53e3\uff0c\u53ef\u6839\u636e\u9700\u8981\u66f4\u6539\n</code></pre> <p>\u8fdc\u7a0b\u8bbf\u95ee\u65f6\u662f\u8981\u8f93\u5165\u4e4b\u524d\u8bbe\u7f6e\u7684\u5bc6\u7801\u7684\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%A1%B9%E7%9B%AE%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/#_8","title":"\u5feb\u901f\u4e0a\u624b\u4e00\u4e2a\u9879\u76ee","text":"<p>\u5f88\u591a\u9879\u76ee\uff0c\u7ecf\u5e38\u4f1a\u56e0\u4e3a\u914d\u7f6e\u73af\u5883\u800c\u60c5\u7eea\u5d29\u6e83\uff0c\u6240\u4ee5\u4e5f\u957f\u4e86\u4e00\u4e9b\u7ecf\u9a8c</p> <ol> <li>\u5b89\u88c5 transformers \u548c datasets      <code>pip install transformers datasets</code></li> <li>\u5b89\u88c5 pytorch \u7cfb\u5217\uff0c\u8bf7\u4e00\u5b9a\u4e8b\u5148\u67e5\u770bCUDA\u7248\u672c\u5e76\u53c2\u7167\u5b98\u7f51\u6307\u4ee4 <p>\u5982\u679c\u9879\u76ee\u7528\u5230\u7684\u662ftensorflow\u4ee3\u7801\uff0c\u4e00\u822c\u90fd\u6709\u5bf9\u5e94\u7684Pytorch\u7248\u672c</p> <p>tensorflow\u7248\u672c\u603b\u662f\u4f1a\u6709\u95ee\u9898\uff0c\u5efa\u8bae\u4e0d\u8981\u7528\u8fd9\u4e2a\u5e93\uff0c\u4e8b\u5b9e\u4e0a\u4e5f\u9010\u6e10\u6ca1\u4eba\u7528\u8fd9\u4e2a\u5e93\u4e86</p> </li> <li>pip install -r requirements.txt <p>\u4e8b\u5148\u628a\u91cc\u9762\u7684torch numpy\u7b49\u884c\u5220\u6389\uff0c\u56e0\u4e3a\u7b2c\u4e8c\u6b65\u5b89\u88c5\u8fc7\u4e86</p> <p>\u5982\u679c\u8fd9\u4e00\u6b65\u6709\u95ee\u9898\uff0c\u5c31\u53bb\u9879\u76ee\u76f8\u5e94\u7684issue\u91cc\u9762\u627e\u7b54\u6848</p> </li> </ol>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/VIT%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/","title":"VIT/DeiT \u4ee3\u7801\u5206\u6790","text":"<p>\u4ee3\u7801\u53c2\u8003\uff1apytorch_classification/vision_transformer</p> <p>\u539f\u7406\u53c2\u8003\uff1aDeiT\uff1a\u6ce8\u610f\u529b\u4e5f\u80fd\u84b8\u998f</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/VIT%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/#_1","title":"\u539f\u7406\u4ecb\u7ecd","text":""},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/VIT%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/#vit","title":"VIT","text":"<p>\u539f\u7406\u601d\u60f3\u6bd4\u8f83\u7b80\u5355\uff0c\u5c06\u56fe\u7247\u5206\u5757\u7136\u540e\u5c55\u5f00\uff0c\u6dfb\u52a0\u4e0a\u4f4d\u7f6e\u7f16\u7801\u8f93\u5165\u5230Transformer\u6a21\u578b\u4e2d\u3002</p> <p>\u5c31\u50cf\u8bba\u6587\u4f5c\u8005\u6240\u63d0\u5230\u7684\u90a3\u6837\u5f53\u4e0d\u4f7f\u7528 JFT-300 \u5927\u6570\u636e\u96c6\u65f6\uff0c\u6548\u679c\u4e0d\u5982CNN\u6a21\u578b\u3002\u8fd9\u8bf4\u660eTransformer\u7ed3\u6784\u82e5\u60f3\u53d6\u5f97\u7406\u60f3\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u5c31\u9700\u8981\u5f88\u5927\u7684\u6570\u636e\u96c6\u3002\u5728\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684VIT\u6548\u679c\u5c06\u4f1a\u5f88\u5dee\uff0c\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4e00\u79cd\u79f0\u4e3aDeiT\u7684\u6539\u8fdb\u65b9\u6cd5\u51fa\u73b0\u4e86\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/VIT%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/#deitdata-efficient-image-transformers","title":"DeiT\uff1aData-efficient image Transformers","text":"<p>\u672c\u8d28\u662f\u5229\u7528\u77e5\u8bc6\u84b8\u998f\u7684\u65b9\u6cd5\u8ba9\u6a21\u578b\u4e0d\u4ec5\u80fd\u5b66\u4e60\u5230\u786c\u6807\u7b7e\uff0c\u8fd8\u80fd\u5b66\u4e60\u5230\u8f6f\u6807\u7b7e\u3002</p> <p>\u786c\u6807\u7b7e\u662f\u6307\u53ea\u6709label\uff08softmax\u4e4b\u540e\u53ea\u67090\u548c1\uff09</p> <p>\u8f6f\u6807\u7b7e\u662f\u6307\u6709softmax\u7684\u5404\u4e2a\u7c7b\u7684\u9884\u6d4b\u503c\uff08\u5c31\u4e0d\u518d\u662f0\u548c1\u4e86\uff09\u3002</p> <p>\u5982\u4f55\u5b9e\u73b0\u5462\uff0c\u5176\u5b9e\u4e5f\u5f88\u7b80\u5355\uff0c\u53ea\u9700\u8981\u52a0\u4e0a\u4e00\u4e2adistillation-token\u5c31\u597d\u4e86\uff0c\u800c\u5bf9\u4e8eTransformer\u672c\u8eab\u5e94\u8be5\u4e5f\u8981\u6709\u4e00\u4e2aClass-token\uff0c\u6240\u4ee5DeiT\u5c31\u9700\u8981\u989d\u5916\u52a0\u4e24\u4e2atoken\u4e86\u3002\u8bad\u7ec3\u539f\u7406\u5982\u4e0b\uff1a</p> <p>\u6a21\u578b\u6709\u4e24\u4e2a\u635f\u5931\uff1a\u4e00\u4e2a\u662f\u76d1\u7763\u635f\u5931\uff0c\u4e00\u4e2a\u662f\u84b8\u998f\u635f\u5931\u3002\u5176\u4e2d\u84b8\u998f\u635f\u5931\u5305\u542b\u8f6f\u84b8\u998f\u635f\u5931\u548c\u786c\u84b8\u998f\u635f\u5931\u3002\u76d1\u7763\u635f\u5931\u3001\u786c\u84b8\u998f\u635f\u5931\u90fd\u662f\u7528\u5206\u7c7b\u4ea4\u53c9\u71b5\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u8f6f\u84b8\u998f\u635f\u5931\u662f\u7528KL\u6563\u5ea6\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/VIT%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/#_2","title":"\u7f16\u7801\u6a21\u5757","text":"<p>\u7f16\u7801\u6a21\u5757\u5305\u62ec\u5206\u5757\u3001\u5c55\u5f00\u3001\u6362\u4f4d\u3001\u5f15\u5165cls-token\u548cdist-token\u3001\u4f4d\u7f6e\u7f16\u7801\u7b49\u6b65\u9aa4\u3002</p> <p>transfomer\u7684\u8f93\u5165\u683c\u5f0f\u4e3a\uff1a[batch_size, seq_len, hidden_size]\uff0c\u56e0\u6b64\u5bf9\u4e8e\u56fe\u7247\u6570\u636e[B, C, H, W]\uff0c\u6211\u4eec\u4e5f\u8981\u5904\u7406\u4e3a\u7c7b\u4f3c\u7684\u7ed3\u6784\u624d\u80fd\u8f93\u5165\u5230transformer\u4e2d\u3002</p> <ul> <li>\u5206\u5757/\u5c55\u5f00/\u6362\u4f4d</li> </ul> <p>\u5206\u5757\u901a\u8fc7\u5377\u79ef\u5c31\u53ef\u4ee5\u5b9e\u73b0\uff0c\u5c55\u5f00\u53ea\u8981flatten\u5373\u53ef\u3002</p> <pre><code># \u53ea\u5c55\u793a\u6838\u5fc3\u4ee3\u7801\nclass PatchEmbed(nn.Module):\n    def __init__(self, img_size=224, patch_size=16, in_c=3, embed_dim=768, norm_layer=None):\n        super().__init__()\n        ...\n        # \u901a\u9053\u6570\u76ee\uff1ain_c = 3\n        # \u8f93\u51fa\u901a\u9053\u6570\uff08\u591a\u5c11\u4e2a\u5377\u79ef\u6838\uff09\uff1aembed_dim = 768\n        # \u5377\u79ef\u6838\u5927\u5c0f\uff1akenerl_size = 16 * 16\n        # \u6b65\u957f\uff1astride = 16 * 16\n        self.proj = nn.Conv2d(in_c, embed_dim, kernel_size=patch_size, stride=patch_size)\n\n        # \u5c42\u5f52\u4e00\u5316\uff1a\u5728\u5355\u4e2a\u6570\u636e\u6837\u672c\u7684\u6240\u6709\u901a\u9053\u4e0a\u8fdb\u884c\u64cd\u4f5c\n        # \u53ef\u4ee5\u5b66\u4e60\u8fd9\u4e2a\u6761\u4ef6\u5224\u65ad\uff0cnn.Identity()\u8868\u793a\u5565\u4e5f\u4e0d\u505a\uff01\n        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n\n    def forward(self, x):\n        B, C, H, W = x.shape\n        assert H == self.img_size[0] and W == self.img_size[1], \\\n            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n\n        # proj: [B, C, H, W] -&gt; [B, embed_dim, H, W]\n        # flatten: [B, embed_dim, H, W] -&gt; [B, embed_dim, HW]\n        # transpose: [B, embed_dim, HW] -&gt; [B, HW, embed_dim]\u7b26\u5408Transformer\u7684\u683c\u5f0f\n\n        x = self.proj(x).flatten(2).transpose(1, 2)\n        x = self.norm(x)\n        return x\n</code></pre> <ul> <li>\u5f15\u5165cls-token\u548cdist-token</li> </ul> <pre><code>...\n# cls-token\u662f\u5fc5\u987b\u8981\u52a0\u7684\u5426\u5219\u505a\u4e0d\u4e86\u84b8\u998f\ncls_token = self.cls_token.expand(x.shape[0], -1, -1)\n\n# dist-token\u662f\u53ef\u9009\u7684\uff0c\u6839\u636e\u662f\u5426\u84b8\u998f\u6765\u51b3\u5b9a\nif self.dist_token is None:\n    x = torch.cat((cls_token, x), dim=1)  # [B, 197, 768]\nelse:\n    x = torch.cat((cls_token, self.dist_token.expand(x.shape[0], -1, -1), x), dim=1)\n</code></pre> <ul> <li>\u4f4d\u7f6e\u7f16\u7801</li> </ul> <pre><code>self.num_patches = self.grid_size[0] * self.grid_size[1]\nself.pos_embed = nn.Parameter(torch.zeros(1, num_patches + self.num_tokens, embed_dim))\nself.pos_drop = nn.Dropout(p=drop_ratio)\n...\nx = self.pos_drop(x + self.pos_embed)\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/VIT%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/#transformer","title":"Transformer\u6a21\u5757","text":"<p>blocks = block * depth = block * 12</p> <p>block = attention + mlp</p> <pre><code>def forward(self, x):\n    x = x + self.drop_path(self.attn(self.norm1(x)))\n    x = x + self.drop_path(self.mlp(self.norm2(x)))\n    return x\n</code></pre> <ul> <li>drop_path</li> </ul> <p>\u672c\u6b21\u4f7f\u7528\u5230\u7684\u662fStochastic Depth\u6b63\u5219\u5316\u6280\u672f\uff0c\u4e3b\u8981\u7528\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u5c24\u5176\u662f\u5728 ResNet\uff08Residual Networks\uff09\u4e2d\u3002\u5b83\u7684\u4e3b\u8981\u601d\u60f3\u662f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u968f\u673a\u5730\u4e22\u5f03\uff08skip\uff09\u4e00\u4e9b\u6b8b\u5dee\u5757\uff08residual blocks\uff09\uff0c\u4ece\u800c\u51cf\u5c11\u7f51\u7edc\u7684\u6709\u6548\u6df1\u5ea6\u3002\u8fd9\u79cd\u65b9\u6cd5\u6709\u52a9\u4e8e\u9632\u6b62\u8fc7\u62df\u5408\uff0c\u5e76\u63d0\u9ad8\u7f51\u7edc\u7684\u6cdb\u5316\u80fd\u529b\u3002</p> <pre><code>def drop_path(x, drop_prob: float = 0., training: bool = False):\n    if drop_prob == 0. or not training:\n        return x\n    keep_prob = 1 - drop_prob\n\n    # (B,1,1,1) = (B,) + (1,1,1) =  (B,) + (1,) * (4 - 1)\n    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  \n\n    # \u968f\u673a\u6570\uff1a[0,1] + keep_prob\n    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n\n    # \u4e8c\u503c\u5316\uff0c\u8981\u4e480\u8981\u4e481\n    random_tensor.floor_()  \n\n    # \u9664\u4ee5 keep_prob\uff1a\u56e0\u4e3a\u5220\u53bb\u7684\u4e00\u4e9b\u795e\u7ecf\u5143\uff0c\u4f46\u662f\u8981\u4fdd\u8bc1\u6574\u4f53\u8f93\u51fa\u4e0d\u592a\u7f29\u5c0f\n    # \u4e58\u4ee5 random_tensor\uff1a\u968f\u673a\u5220\u9664\u4e00\u4e9b\u795e\u7ecf\u5143\n    output = x.div(keep_prob) * random_tensor\n    return output\n\n</code></pre> <ul> <li>Muti-head Attention</li> </ul> <p>\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u7684\u6838\u5fc3\u601d\u60f3\u662f\u5e76\u884c\u8ba1\u7b97\u3002\u901a\u8fc7\u5c06\u8f93\u5165\u7684\u7279\u5f81\u7ef4\u5ea6 C \u5206\u5272\u6210\u591a\u4e2a\u5934\uff0c\u6bcf\u4e2a\u5934\u72ec\u7acb\u8ba1\u7b97\u6ce8\u610f\u529b\uff0c\u8fd9\u6837\u53ef\u4ee5\u5e76\u884c\u5904\u7406\uff0c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002</p> <pre><code>def forward(self, x):\n    # [batch_size, num_patches + 1, total_embed_dim]\n    B, N, C = x.shape\n\n    # qkv(): -&gt; [batch_size, num_patches + 1, 3 * total_embed_dim]\n    # reshape: -&gt; [batch_size, num_patches + 1, 3, num_heads, embed_dim_per_head]\n    # permute: -&gt; [3, batch_size, num_heads, num_patches + 1, embed_dim_per_head]\n    qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4) # \u4e00\u822c8\u4e2a\u5934\n\n    # [batch_size, num_heads, num_patches + 1, embed_dim_per_head]\n    q, k, v = qkv[0], qkv[1], qkv[2]  \n\n    # transpose: -&gt; [batch_size, num_heads, embed_dim_per_head, num_patches + 1]\n    # @: multiply -&gt; [batch_size, num_heads, num_patches + 1, num_patches + 1]\n    attn = (q @ k.transpose(-2, -1)) * self.scale\n    attn = attn.softmax(dim=-1)\n    attn = self.attn_drop(attn)\n\n    # @: multiply -&gt; [batch_size, num_heads, num_patches + 1, embed_dim_per_head]\n    # transpose: -&gt; [batch_size, num_patches + 1, num_heads, embed_dim_per_head]\n    # reshape: -&gt; [batch_size, num_patches + 1, total_embed_dim]\n    x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n    # ! \u6574\u5408\u591a\u5934\u4fe1\u606f\uff1a\u7ebf\u6027\u5c42\u53ef\u4ee5\u5c06\u4e0d\u540c\u5934\u7684\u8f93\u51fa\u7ec4\u5408\u5728\u4e00\u8d77\uff0c\u5b66\u4e60\u5230\u66f4\u9ad8\u7ea7\u7684\u7279\u5f81\u3002\n    x = self.proj(x) \n    x = self.proj_drop(x)\n    return x\n</code></pre> <ul> <li>MLP</li> </ul> <p>GELU \u662f\u4e00\u79cd\u6fc0\u6d3b\u51fd\u6570\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\uff0c\u7279\u522b\u662f\u5728 Transformer \u67b6\u6784\u4e2d\u3002GELU \u6bd4 ReLU \u7b49\u6fc0\u6d3b\u51fd\u6570\u66f4\u52a0\u5e73\u6ed1\uff0c\u8fd9\u6709\u52a9\u4e8e\u68af\u5ea6\u6d41\u52a8\uff0c\u4ece\u800c\u53ef\u80fd\u5bfc\u81f4\u66f4\u597d\u7684\u8bad\u7ec3\u6027\u80fd\u3002</p> <pre><code>class Mlp(nn.Module):\n    \"\"\"\n    MLP as used in Vision Transformer, MLP-Mixer and related networks\n    \"\"\"\n    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.act = act_layer()\n        self.fc2 = nn.Linear(hidden_features, out_features)\n        self.drop = nn.Dropout(drop)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.drop(x)\n        return x\n</code></pre>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/YOLO%E7%B3%BB%E5%88%97/","title":"YOLO \u57fa\u7840\u77e5\u8bc6\u68b3\u7406","text":"<p>\u53c2\u8003\u8d44\u65991\uff1aYOLO\u7cfb\u5217\u6f14\u5316\u5386\u53f2</p> <p>\u53c2\u8003\u8d44\u65992\uff1a\u6df1\u5165\u6d45\u51faYolo\u7cfb\u5217\u4e4b Yolov3 &amp; Yolov4 &amp; Yolov5 &amp; Yolox9</p> <p>YOLO\u662f\u76ee\u6807\u68c0\u6d4b\u4e2d\u975e\u5e38\u7ecf\u5178\u7684\u6a21\u578b\uff0c\u4f46\u662f\u5176\u53d1\u5c55\u6f14\u5316\u975e\u5e38\u4e4b\u5feb\u8ba9\u4eba\u6709\u70b9\u6478\u4e0d\u6e05\u5176\u8109\u7edc\u3002\u8fd9\u6b21\u5185\u5bb9\u5b89\u5168\u5b9e\u9a8c\u8bfe\u9700\u8981\u7528\u5230YOLOv8\u6a21\u578b\uff0c\u6211\u987a\u4fbf\u5c06YOLO\u7cfb\u5217\u7684\u539f\u7406\u90fd\u6574\u7406\u4e00\u904d\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/YOLO%E7%B3%BB%E5%88%97/#_1","title":"\u57fa\u7840\u77e5\u8bc6","text":"<p>\u6574\u4e2aYOLO\u6a21\u578b\u7531\u4e09\u4e2a\u90e8\u5206\u7ec4\u6210\uff1a</p> <ul> <li>\"backbone\" \u6307\u7684\u662f\u9aa8\u5e72\u7f51\u7edc\uff0c\u8d1f\u8d23\u63d0\u53d6\u7279\u5f81\uff1b</li> <li>\"neck\" \u6307\u7684\u662f\u4f4d\u4e8e\u9aa8\u5e72\u7f51\u7edc\u4e4b\u540e\u7684\u6a21\u5757\uff0c\u7528\u4e8e\u8fdb\u4e00\u6b65\u5904\u7406\u7279\u5f81\uff1b</li> <li>\"head\" \u6307\u7684\u662f\u4f4d\u4e8e\u6a21\u578b\u9876\u90e8\u7684\u90e8\u5206\uff0c\u6267\u884c\u7279\u5b9a\u4efb\u52a1\u5e76\u751f\u6210\u6700\u7ec8\u7684\u9884\u6d4b\u7ed3\u679c\u3002</li> </ul>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/YOLO%E7%B3%BB%E5%88%97/#yolo-v1","title":"YOLO v1","text":"<p>YOLO v1 \u7684\u7ed3\u6784\u6bd4\u8f83\u7b80\u5355\uff0c\u53ef\u4ee5\u5206\u4e3a\u4e24\u4e2a\u90e8\u5206\u7406\u89e3\uff1a</p> <ul> <li>\u7b2c\u4e00\u4e2a\u90e8\u5206\u7528\u4e8e\u63d0\u53d6\u7279\u5f81\uff0c\u5373 backone </li> <li> <p>\u7b2c\u4e8c\u4e2a\u90e8\u5206\u7528\u4e8e\u9884\u6d4b\u76ee\u6807 \uff08 \u7ef4\u5ea6\u4fe1\u606f\u4e3a\uff1a7 * 7 * 30 \uff09\uff0c\u5373 head</p> <p>7 * 7 \u662f\u7279\u5f81\u56fe\u5927\u5c0f\uff0c30 \u662f\u9884\u6d4b\u76ee\u6807\u4fe1\u606f\u3002\u5177\u4f53\u6765\u8bf4 30 = 5 * 2 + 20 \uff0c \u5176\u4e2d\u7684 5 * 2 \u8868\u793a\uff08X\uff0cY\uff0cH\uff0cW\uff0cC\uff09* \u6846\u7684\u6570\u91cf\uff0c20 \u8868\u793a\u652f\u630120\u4e2d\u7c7b\u522b\u3002\u8fd9\u4e9b\u4fe1\u606f\u5305\u542b\u4e86\u6846\u7684\u4f4d\u7f6e\u3001\u7f6e\u4fe1\u5ea6\u548c\u7c7b\u522b\u3002</p> </li> </ul> <p>\u8fd9\u6837\u53ef\u4ee5\u8bbe\u8ba1\u51fa\u5176\u635f\u5931\u51fd\u6570\uff0c\u4e3b\u8981\u5206\u4e3a\uff1a\u5750\u6807\u635f\u5931\u3001\u7f6e\u4fe1\u5ea6\u635f\u5931\u3001\u7c7b\u522b\u635f\u5931\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/YOLO%E7%B3%BB%E5%88%97/#yolo-v2","title":"YOLO v2","text":"<p>YOLO v2 \u5728\u7b2c\u4e00\u7248\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u5f88\u591a\u6539\u8fdb\uff1a</p> <p>\u91cd\u70b9\u5206\u6790\u4e0b\u9762\u7684\u51e0\u4e2a\u6539\u8fdb\uff1a</p> <ul> <li>Batch Normalization\uff1a\u53ef\u4ee5\u63d0\u5347\u6a21\u578b\u6536\u655b\u901f\u5ea6\uff0c\u8d77\u5230\u6b63\u5219\u5316\u7684\u4f5c\u7528\uff0c\u964d\u4f4e\u6a21\u578b\u8fc7\u62df\u5408\uff0c\u8bad\u7ec3\u66f4\u7a33\u5b9a</li> <li>Backbone\u6a21\u5757\uff0c\u4f7f\u7528DarkNet-19\uff0c\u964d\u4f4e\u4e86\u8ba1\u7b97\u91cf</li> <li>Neck\u6a21\u5757\uff0c\u5c06\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u8fdb\u884c\u878d\u5408\uff08Fine-Grained Features\uff09\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b</li> <li>Head\u6a21\u5757\uff0c\u7528\u5377\u79ef\u66ff\u6362\u5168\u8fde\u63a5\uff0c\u56e0\u6b64\u53ef\u4ee5\u4f7f\u7528\u5404\u79cd\u5c3a\u5ea6\uff0832\u7684\u500d\u6570\uff09\u7684\u56fe\u50cf\u8fdb\u884c\u8bad\u7ec3</li> <li>Anchor Box\uff1a\u4f7f\u7528\u805a\u7c7b\uff08Dimension Clusters\uff09\u5f97\u5230\u9884\u8bbe\u6846\u7684\u5c3a\u5bf8\uff0c\u63d0\u9ad8\u76ee\u6807\u7684\u5b9a\u4f4d\u51c6\u786e\u7387\u3002</li> </ul>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/YOLO%E7%B3%BB%E5%88%97/#yolo-v3","title":"YOLO v3","text":"<p>What\u2019s new in YOLO v3? \u56fe\u4e0a\u975e\u5e38\u6e05\u695a\u4e86\uff0c\u611f\u89c9\u633a\u597d\u7406\u89e3\u7684\uff0c\u548cv2\u975e\u5e38\u50cf\uff0c\u5c31\u878d\u5165\u4e86\u4e00\u4e9b\u5c0f\u6280\u5de7\u3002\u4e0d\u8fc7\u548cv2\u56fe\u753b\u7684\u4e0d\u4e00\u6837\uff0c\u5bb9\u6613\u8ba9\u4eba\u8bef\u89e3\u6700\u540eprediction\u6709\u4e09\u4e2a\uff0c\u5176\u5b9e\u6700\u540e\u4f1aconcat\uff0c\u6240\u4ee5\u8fd8\u662f\u548cv2\u4e00\u6837\u3002 Backbone\u6362\u6210\u4e86DarkNet-53\uff0cv3 \u6700\u663e\u7740\u7684\u7279\u70b9\u662f\u5b83\u4ee5\u4e09\u79cd\u4e0d\u540c\u7684\u5c3a\u5ea6\u8fdb\u884c\u68c0\u6d4b\u3002</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/YOLO%E7%B3%BB%E5%88%97/#yolo-v4","title":"YOLO v4","text":"<ul> <li>\u8f93\u5165\u7aef\uff1a\u4e3b\u8981\u5305\u62ecMosaic\u6570\u636e\u589e\u5f3a\u3001cmBN\u3001SAT\u81ea\u5bf9\u6297\u8bad\u7ec3</li> <li>BackBone\uff1a\u5c06\u5404\u79cd\u65b0\u7684\u65b9\u5f0f\u7ed3\u5408\u8d77\u6765\uff0c\u5305\u62ec\uff1aCSPDarknet53\u3001Mish\u6fc0\u6d3b\u51fd\u6570\u3001Dropblock\uff08\u968f\u673a\u5220\u9664\u51cf\u5c11\u795e\u7ecf\u5143\u7684\u6570\u91cf\uff0c\u4f7f\u7f51\u7edc\u53d8\u5f97\u66f4\u7b80\u5355\uff0cDropout\u5728\u5377\u79ef\u5c42\u4e0a\u6548\u679c\u5e76\u4e0d\u597d\uff09</li> <li>Neck\uff1a\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u5728BackBone\u548c\u6700\u540e\u7684\u8f93\u51fa\u5c42\u4e4b\u95f4\u4f1a\u63d2\u5165\u4e00\u4e9b\u5c42\uff0c\u6bd4\u5982SPP\u6a21\u5757\u3001FPN+PAN\u7ed3\u6784</li> </ul> <p>FPN\u5c42\u81ea\u9876\u5411\u4e0b\u4f20\u8fbe\u5f3a\u8bed\u4e49\u7279\u5f81\uff0c\u800c\u7279\u5f81\u91d1\u5b57\u5854(PAN)\u5219\u81ea\u5e95\u5411\u4e0a\u4f20\u8fbe\u5f3a\u5b9a\u4f4d\u7279\u5f81</p> <ul> <li>Head\uff1a\u8bad\u7ec3\u65f6\u7684\u635f\u5931\u51fd\u6570CIOU_Loss\uff0c\u4ee5\u53ca\u9884\u6d4b\u6846\u7b5b\u9009\u7684nms\u53d8\u4e3aDIOU_nms <p>CIOU_Loss \uff1a \u91cd\u53e0\u9762\u79ef\u3001\u4e2d\u5fc3\u70b9\u8ddd\u79bb\uff0c\u957f\u5bbd\u6bd4\u90fd\u8003\u8651\u4e86\u8fdb\u6765</p> </li> </ul>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/YOLO%E7%B3%BB%E5%88%97/#yolo-v5","title":"YOLO v5","text":"<p>\u6574\u4f53\u53d8\u5316\u4e0d\u5927\uff0cYOLO v5\uff0c\u4f5c\u8005\u6ca1\u6709\u53d1\u8bba\u6587</p> <ul> <li>Focus\u7ed3\u6784\uff0cYolov3&amp;Yolov4\u4e2d\u5e76\u6ca1\u6709\u8fd9\u4e2a\u7ed3\u6784\uff0c\u5176\u4e2d\u6bd4\u8f83\u5173\u952e\u7684\u662f\u5207\u7247\u64cd\u4f5c</li> </ul> <ul> <li>\u81ea\u9002\u5e94\u56fe\u7247\u7f29\u653e\uff0c\u5373\u6839\u636e\u957f\u5bbd\u6bd4\u5bf9\u56fe\u50cf\u8fdb\u884c\u7f29\u653e\uff0c\u6dfb\u52a0\u6700\u5c11\u7684\u9ed1\u8fb9\uff0c\u51cf\u5c11\u8ba1\u7b97\u91cf</li> </ul>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/YOLO%E7%B3%BB%E5%88%97/#yolo-v6","title":"YOLO v6","text":"<p>\u5b98\u65b9\u53c2\u8003\u6587\u6863 \uff1a\u7f8e\u56e2 YOLOv6</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/YOLO%E7%B3%BB%E5%88%97/#yolo-v7","title":"YOLO v7","text":"<p>github\u5b98\u65b9\u6587\u6863 : YOLOv7</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/YOLO%E7%B3%BB%E5%88%97/#yolo-v8","title":"YOLO v8","text":"<p>\u5b98\u65b9\u53c2\u8003\u6587\u6863 : YOLOv8</p> <ul> <li>YOLOv8\u53c2\u8003\u4e86YOLOX\u548cYOLOV6\uff0c\u4f7f\u7528\u4e86Decoupled-Head\uff0c\u5373\u4f7f\u7528\u4e24\u4e2a\u5377\u79ef\u5206\u522b\u505a\u5206\u7c7b\u548c\u56de\u5f52</li> <li>\u4e3a\u4e86\u8f7b\u91cf\u5316\uff0cv8\u8bbe\u8ba1\u4e86c2f\u7ed3\u6784\uff0c\u4e0ec3\u76f8\u6bd4\u5c11\u4e86\u4e00\u5c42conv\uff0c\u91c7\u7528split\u5c06\u7279\u5f81\u5206\u5c42\u800c\u4e0d\u662fconv</li> </ul> <p>\u540e\u9762\u7684YOLO\u611f\u89c9\u90fd\u53ea\u662f\u5c0f\u4fee\u5c0f\u6539\uff0c\u878d\u5165\u4e00\u4e9b\u65b0\u7684\u6280\u672f\u548c\u7406\u5ff5...\u5c31\u4e0d\u591a\u8d58\u8ff0\u4e86</p>"},{"location":"%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%96%AF%E5%9D%A6%E7%A6%8F%E7%BD%91%E8%AF%BE/","title":"CS231n","text":""}]}